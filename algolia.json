[{"permalink":"/tech/use-openresty-ghaction-remote-deploy.html","title":"Openresty+Github Action实现远程自动部署","content":"近期频发的收到云厂商关于服务器资源到期的提醒，当初为了躲避云厂商所谓的注册域名 IP 检测监控，无奈之下借着“新”用户的优惠政策，采购了一款最最实惠的云服务，周期为 1 年时间，如今也已是到了“寿终正寝”的时候啦， 因此不得已又要考虑给博客空间找新的部署服务器啦。后来得到热心朋友的资助，在其现有的云服务器上开辟了小空间提供给鄙人博客访问，真是感激万分呀！\n通常情况下云服务器上的安全策略都会管理的比较严格，为此原来想通过 SSH 远程执行部署站点方案便不太可行啦，其中主要的影响因素就是 Github Action 所提供的 CI/CD 服务，其执行时机器是完全随机分配的，那几乎就是等同于动态 IP， 而云服务器上面的安全组策略根本无法支持这么庞大的 IP 段设置，而且也不想劳烦朋友去调整这系统级别的安全设置，于是便想到通过 Nginx 来调用本地脚本进行远程部署的方案。\n方案的初步设想如下：\ngraph LR; node1([fa:fa-play 开始 ])--\u003enode2[/撰写文章/]--\u003e |fa:fa-upload Git提交\u0026推送| node3[[fa:fa-blog Github Action构建构静态文件]] --\u003enode4[/推送 Gitee 仓库/]--\u003enode5[fa:fa-link curl远程调用] --\u003enode6([fa:fa-stop 结束 ]); node5--\u003enode7[[fa:fa-hdd 云服务器部署]]; subgraph http-client node4--\u003e |fa:fa-download Git拉取更新| node7; end; style node7 fill:#f96; 中间增加了 Gitee 仓库的同步机制，部署的时间上可能会增加延迟，但部署成功率会更高些。\n注：考虑到国内访问 Github 经常会不稳定，所以干脆就做个仓库同步，将部署文件先推送到 Gitee ，再让云服务器去 Gitee 上面拉取部署代码，这样部署的稳定性会比较好。 在经过一番资料的查找后，最终确认方案是具备可行性的，技术上将选择 Openresty 增强版本的 Nginx 服务，通过 lua 代码来调用本地的脚本执行（特别感谢 @二花 网友帮忙调试lua代码 👊） 需要在 Nginx 配置文件上加入如下的代码：\n1 2 3 4 5 6 7 8 9 location /auto-deploy { auth_basic \u0026#34;Administrator’s Area\u0026#34;; auth_basic_user_file /etc/xxx/.htpasswd; content_by_lua_block { local status, out, err = os.execute(\u0026#34;/bin/bash /www/blog/deploy.sh\u0026#34;) ngx.header.content_type = \u0026#34;text/plain\u0026#34; ngx.say(\u0026#34;Result: \\n\u0026#34; .. out) } } 如上述配置代码所示，其中增加了 Basic Auth 授权来保障访问的安全。再通过 curl 命令对该路径进行访问便能实现自动化部署，最后的 Github Action 定义代码参考如下：\n1 2 3 4 5 6 7 8 9 # Git pull new things from Gitee. deploy-cloud: needs: sync-2-gitee runs-on: ubuntu-latest steps: - name: Deploy Cloud Server run: | curl ipinfo.io curl -i -u ${{ secrets.GACTION_CU }}:${{ secrets.GACTION_CP }} ${{ secrets.DEPLOY_URL }} 注： 切记要将站代码部署的文件夹和执行部署的脚本，其访问的权限给到 Nginx 运行用户，避免出现操作无权限的问题。 最后怀揣着“激动”的心情，写下此篇文章并提交至Github进行测试验证，当看到那个绿色的 ✅ 状态显现时，用事实证明一切皆有可能，后续就专心写作发表便是啦。 🔋 🔋 🔋\n附上参考资料：\nnginx-如何在每个请求上运行shell脚本？ 在CENTOS6.0上通过NGINX远程执行SHELL Openresty安装 Restricting Access with HTTP Basic Authentication curl命令获取外网ip ","date":"2022-09-17T19:13:39+08:00","updated":"2022-09-17T19:13:39+08:00"},{"permalink":"/blog/use-custom-domain-active-vercel-waline.html","title":"使用自定义域名激活Vercel部署的Waline服务","content":"近期对于部分 Waline 评论插件的用户来说，或许是非常的困扰时期。先是服务商 LeanCloud 发布国内提供的服务，从8月份起需要绑定自有案例域名才能正常运行。而这两天 Vercel (Waline 官方提供的免费部署方案，也是大部用户的选择)旗下的 vercel.app 域名又遭受 DNS 污染攻击，在国内无法直接访问此域名，导致众多 Waline 用户的服务直接陷入“宕机”状态，真可谓是雪上加霜。\n有句话说的好：“只要思想不滑坡，办法总比困难多”。接下来就是给大家分享下，如何通过自定义域名的方式来解决上面遇到的2个问题，此方法仅供各位网友参考参考。 😄\n确定方案 由于 vercel.app 域名已经被 DNS 污染，那么国内网络应该都是无法进行访问的，所以原本想直接通过已有域名 DNS 的 CNAME 对vercel.app域名转发的想法是不能实现的。通过多次验证后，确认如下 2 套方案：\n方案1： 有备案可用域名，直接转发Vercel DNS Server地址 方案2： 申请免费域名，配置 Vercel 提供的 DNS 服务器 方案1 DNS Server转发 在自有域名的 DNS 服务中添加一条记录，选择 CNAME 类型转发，记录值填写为：cname.vercel-dns.com，参考如下：\n然后在 Vercel 中找到 Waline 后端服务的项目，点击Settings标签卡，跳转页面后点击左侧的Domains菜单项，输入你自己定义的域名点击Add`按钮即可。\n方案2 申请免费域名 可以参考之前发布的文章： 创建属于你自己的org永久域名 ，不过这里不需要借助 DNSPOD 提供的解析服务，所以在申请域名时可以直接填写 Vercel 提供的 DNS 服务，默认地址为：\nns1.vercel-dns.com ns2.vercel-dns.com 域名申请下来后，访问 Vercel 的域名控制面板 Domains Dashboard 点击右上角的Add按钮选择你的 Waline 项目点击Continue按钮，再输入申请好的域名确认即可。\n评论搬迁 除了域名访问的问题外，还需要注意当使用 LeanCloud 国内版作为存储时需要有自定义的备案域名，要是没有的话就只好选择国际版本。那么就要对于已有的数据进行迁移，但 Waline 自带的导入导出功能还是有些问题 #1148 ，建议最好还是使用 LeanCloud 自带的导入导出功能，不过需要进行手动的调整。\n第一步是对数据进行导出，这里只需选取Counter、Comment和Users三个 Schema 文件，参考如下：\n第二步是对数据进行调整，需要在 Date 类型的字段中都加上 _type 标识，避免导入后 Waline 无法插入新的评论数据，为此写了个 Python 脚本进行批量的修改，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def append_date_type(source, target): \u0026#34;\u0026#34;\u0026#34;修改waline date 类型 :param source: 原始文件 :param target: 目标文件 \u0026#34;\u0026#34;\u0026#34; with open(source, \u0026#34;wb+\u0026#34;) as tf: with open(target, \u0026#34;rb+\u0026#34;) as sf: print(\u0026#34;Current File: %s\u0026#34; % os.path.basename(sf.name)) while True: try: line = sf.readline() line_splits = line.decode().splitlines() if len(line_splits) \u0026lt;= 0: break; line_str = line_splits[0].strip(\u0026#39;,\u0026#39;) if \u0026#39;createdAt\u0026#39; in line_str: new_ca = \u0026#39;\u0026#34;createdAt\u0026#34;: {\u0026#34;__type\u0026#34;:\u0026#34;Date\u0026#34;,\u0026#34;iso\u0026#34;:\u0026#39;+line_str.split(\u0026#39;: \u0026#39;)[1]+\u0026#39;},\\r\\n\u0026#39; tf.write(new_ca.encode()) elif \u0026#39;insertedAt\u0026#39; in line_str: new_ia = \u0026#39;\u0026#34;insertedAt\u0026#34;: {\u0026#34;__type\u0026#34;:\u0026#34;Date\u0026#34;,\u0026#34;iso\u0026#34;:\u0026#39;+line_str.split(\u0026#39;: \u0026#39;)[1]+\u0026#39;},\\r\\n\u0026#39; tf.write(new_ia.encode()) elif \u0026#39;updatedAt\u0026#39; in line_str: new_ua = \u0026#39;\u0026#34;updatedAt\u0026#34;: {\u0026#34;__type\u0026#34;:\u0026#34;Date\u0026#34;,\u0026#34;iso\u0026#34;:\u0026#39;+line_str.split(\u0026#39;: \u0026#39;)[1]+\u0026#39;},\\r\\n\u0026#39; tf.write(new_ua.encode()) else: tf.write(line) except: print(\u0026#39;Somethings wrong!!!\u0026#39;) traceback.print_exc() break 把修改好的 json 数据，使用 LeandCloud 的导入功能重新导入，然后在 Waline 后台管理界面就能看到数据，前端也能正常的提交新评论。\n吐槽感言 相信经过上述的折腾后，此时此刻的你，应该对那句“免费的东西总是最贵的”话语有种深刻的体验了吧。但是这番的折腾也还算是值得的，学习到不少的新知识，又一次锤炼的了自己的技术，也正是验证开头说的那句话“办法总比困难多”，对吧！😁\n","date":"2022-09-01T21:23:03+08:00","updated":"2022-09-01T21:23:03+08:00"},{"permalink":"/tech/github-action-ssh-key-invalid.html","title":"Github Action执行时遇到SSH key invalid format错误","content":"Github Action是款非常不错的CI/CD工具，自从它问世以来发展的速度真可谓是快，在 Github 的官方市场中几乎能找到所有你想要使用的Action脚本进行引用。本博客也是基于Github Action进行远程部署的，与常规的Github Pages服务不同，本站的静态文件是部署在国内某云厂商的静态服务器上面的，通过 tzzs/server-shell Action 集成，实现远程执行服务端的命令，来拉取最新生成的静态文件。\n具体的Github Action脚本用法参考如下：\n1 2 3 4 5 6 7 8 9 10 11 deploy-cloud: runs-on: ubuntu-latest steps: - name: Deploy Remote Cloud uses: tzzs/server-shell@v3 with: IP: ${{ secrets.REMOTE_HOST }} USERNAME: ${{ secrets.REMOTE_USER }} PRIVATE_KEY: ${{ secrets.REMOTE_PRIVATE_KEY }} SHELL: \u0026#34;sh /home/develop/myblog-deploy.sh\u0026#34; 这看上去也没有任何的问题，将代码推送到Github仓库也能正常运行。但诡异的事情在大概运行 1 周时间后便出现。在没有调整过 Action 脚本及 SSH 私钥的情况下，上面的部署步骤竟然执行失败，报出如下的错误信息：\n1 2 3 4 5 6 7 /usr/bin/ssh server sh /home/***/myblog-deploy.sh Warning: Permanently added \u0026#39;***\u0026#39; (ECDSA) to the list of known hosts. Load key \u0026#34;/home/runner/.ssh/deploy.key\u0026#34;: invalid format Permission denied, please try again. Permission denied, please try again. ***@***: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). Error: Error: The process \u0026#39;/usr/bin/ssh\u0026#39; failed with exit code 255 持着怀疑的态度再次检查了下最新仓库代码，确定只是发布了新文章并没调整过配置文件。然后又直接执行ssh -i命令测试了下 SSH 私钥，也是能正常的连接远程服务，这就有点纳闷的啦，到底是哪里出问题呢？\n经过一番网络大战（借助搜索引擎查找资料）后，发现有人提到说检查下 SSH 私钥的类型是否为 RSA 格式，打开的本地生成的id_rsa文件查看内容，果然不是RAS类型，参考如下：\n1 2 3 -----BEGIN OPENSSH PRIVATE KEY----- xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx -----END OPENSSH PRIVATE KEY----- 大概是早期生成SSH key没有留意直接使用了默认规则，然后使用如下的命令对私钥进行转换：\n1 ssh-keygen -m PEM -t rsa -f ~/.ssh/id_rsa 将新生成的私钥进行重新分发，再重新re-load失败的 Action， 果然任务就能正常执行成功。\n问题到此是解决了，不过对其的产生还是有些困惑，之前为何就没有这样的情况出现？又仔细过了一遍远程部署的脚本代码，发现执行时需要指定服务器操作系统版本 runs-on: ubuntu-latest ，而这里写的是使用最新版本，估计问题就是在此产生的，猜测可能是最新版本服务器操作系统的OPENSSH是版本较高不兼容所导致的，但没有做进一步的验证。\n总结一点，就是生成SSH私钥时还是尽量按照服务方的要求进行操作，如果没有，那么建议还是使用PEM格式的RSA类型较为通用，能够避免未知的风险。 😄\n","date":"2022-08-11T21:21:59+08:00","updated":"2022-08-11T21:21:59+08:00"},{"permalink":"/blog/upgrade-blog-use-new-theme.html","title":"博客站点升级使用 Hugo NexT 最新主题","content":"时隔 2 年的时间后，如今又再一次开始折腾自己的博客站点，看来是自己有点太躁动啦😂。在上海疫情期间也真有点压抑的，为了消除这份不安的情绪，决定参考 Hexo NexT 从零开始全面重构 NexT 主题，也在独自奋斗的2个多月断断续续时间里完成主体功能所有移植工作（其实一直想有人参与进来共建，直接跑到人家 Hexo NexT 用户群“呼喊”，但也是没有浪花泛起，只好是自己继续独立前行）。 这不乘着周末的时间，把自己的站点也是升级到最新开发的主题，同时也是为后续想升级旧版本 Hugo NexT 的用户打个样吧。\n注意： 以下的操作记录，如果你已经熟悉 Hugo 使用，了解 Hugo NexT 主题相关配置，那么效果会更加好。 不熟悉也没有关系，你可以克隆 hugo-next-docs 项目进行参考，相信你会有所收获！ ✊ 😄 配置更新 首先声明一下配置文件已经和旧版本完全不兼容，因此在配置主题时无须参考原来的配置，只须根据新版本主题提供 示例配置文件 里面的注释说明调整自己站点信息即可，如站点名称，标题，头像，菜单，评论等个性化设置。\n主题默认提供的是单一配置文件的经典模式，可能很多人都会比较喜欢这样的简便风格，但个人还是更喜欢 Hugo 那种按目录进行分类管理的形式，不仅方便于环境的切换（默认使用develpment环境，直接执行hugo server命令即可），而且在本地开发时能有效的屏蔽某些配置参数泄漏，比如搜索引擎的KEY信息，整体的目录结构参考如下：\n1 2 3 4 5 6 config ├── _default # 默认生产发布的配置文件 │ ├── config.yaml # Hugo 引擎配置参数 │ ├── menus.yaml # 站点菜单项 │ └── params.yaml # 各类效果，组件参数配置 └── development # 本地开发预览的配置文件（不上传到代码仓库） 当在本地运行 hugo server 命令预览站点时，会读取 development 文件夹里的参数配置。而当运行 hugo 命令生成全站静态文件时，会默认读取 _default 文件夹里的参数配置，这便实现开发环境与部署环境相互隔离，互不影响的完美效果！\n注： 如果是从 Hexo 迁移过来的用户，那么本主题的配置文件兼容性可达 90% 以上 👍 。 文章拷贝 文章内容这块的默认情况下是无须任何的调整，新版本的主题文章头部参数设置与旧版主题是保持向下兼容的，包括之前是应用其他主题的文章也可以兼容（因为用的是标准的 FrontMatter 参数），因此一般情况下只要拷贝到 content 目录下相同的位置即可。\n不过自己又稍微折腾了一下，原因是之前的文章都是在 content\\posts 一个目录中并没有做好分类管理，想通过此次的升级重新整理下文章的分类，而且新版本的主题中已经可以支持多个自定义目录。另外之前的文章链接中都是带有日期想进一步缩短链接长度，而且也发现 Hugo 中有 aliases 功能特别的强大，无需担心之前 SEO 的链接无法正常访问，语法参考如下：\n1 2 3 4 5 6 title: \u0026#34;让 Nginx 将 HTTP 请求转发到 HTTPS 安全模式\u0026#34; # 新的链接地址 url: blog/make-nginx-support-http-ssl-request.html # 旧的链接地址 aliases: - /2022/05/05/make-nginx-support-http-ssl-request.html 因此也用 Python 写了个小脚本进行自动生成新的链接地址，代码参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def append_alias_fm(source, target): \u0026#34;\u0026#34;\u0026#34;在原来的博客文章中添加新的 aliases 变量 :param source: 原始目录 :param target: 目标目录 \u0026#34;\u0026#34;\u0026#34; for root,dirs,files in os.walk(source): folders = root.split(\u0026#39;\\\\\u0026#39;); t_sub_folder = \u0026#39;\u0026#39; if len(dirs) == 0 and len(folders)\u0026gt;0: t_sub_folder = folders[1] t_sub_folder_path = os.path.join(target, t_sub_folder) if not os.path.exists(t_sub_folder_path): os.makedirs(t_sub_folder_path) print(\u0026#34;Current Folder: %s\u0026#34; % t_sub_folder) for file in files: with open(os.path.join(target, t_sub_folder, file), \u0026#34;wb+\u0026#34;) as tf: with open(os.path.join(root, file), \u0026#34;rb+\u0026#34;) as sf: print(\u0026#34;Current File: %s\u0026#34; % os.path.basename(sf.name)) while True: try: line = sf.readline() line_splits = line.decode().splitlines() if len(line_splits) \u0026lt;= 0: break; line_str = line_splits[0] if \u0026#39;url\u0026#39; in line_str: old_url = line_str.split(\u0026#39;: \u0026#39;)[1] new_url = old_url.split(\u0026#39;/\u0026#39;)[3] if \u0026#39;\u0026#34;\u0026#39; in old_url: old_url = old_url.strip(\u0026#39;\u0026#34;\u0026#39;) new_url = new_url.strip(\u0026#39;\u0026#34;\u0026#39;) tf.write((\u0026#39;url: blog/\u0026#39;+ new_url + \u0026#39;\\r\\n\u0026#39;).encode()) tf.write((\u0026#39;aliases: \\r\\n - /\u0026#39;+ old_url + \u0026#39;\\r\\n\u0026#39;).encode()) tf.write(sf.read()) break else: tf.write(line) except: print(\u0026#39;Somethings wrong!!!\u0026#39;) traceback.print_exc() break 修改后的文章经过测试都能正常的访问，发布上线后，通过搜索引擎检索到的旧链接地址都能正常的访问，并成功跳转到新的链接地址，不过为了 SEO 更加友好，还是同步把新的 sitemap.xml 文件重新提交给各个搜索引擎。\n评论迁移 相比文章拷贝来说评论迁移就比较繁琐些，本博客一直使用的都是 Waline 评论插件，它提供了一个导入导出的功能，原以为只是将原文章地址进行替换后导入就可以。但结果是草率了，修改后的文件导入居然失败了，然后尝试换成了 LeanCloud 官方的导入功能便成功，本以为迁移工作到此就结束了，结果又来了如下问题：\n真是无语至极呀，还好之前也处理过类似的情况，接着就又对数据一阵“魔改”，终于是搞定好了天下太平，评论功能也总算是恢复正常，自己发个板凳留念下。\n在线搜索 新版本的主题支持 Alogia 在线搜索引擎，观察过不少站点（特别是一些文档类的网站都在使用），开发主题时也体验了下它的功能，觉得还是蛮不错的，搜索和响应速度也挺快的。 开发好后集成也是相对比较简单，只是多了个注册和上传索引文件的操作。原以为索引是自动根据站点路径生成，还好 Github 提供了 CI 支持，可以省去上传这步操作，直接实现流程的全自动化。 这里使用的是 Github Action 功能，脚本参考如下：\n1 2 3 4 5 6 7 8 9 - name: Upload Algolia Indexes env: ALGOLIA_APPID: ${{ secrets.ALGOLIA_APPID }} ALGOLIA_ADMINKEY: ${{ secrets.ALGOLIA_ADMINKEY }} ALGOLIA_INDEXNAME: ${{ secrets.ALGOLIA_INDEXNAME }} ALGOLIA_INDEXFILE: \u0026#34;./public/algolia.json\u0026#34; run: | npm install --location=global @algolia/cli algolia import -s $ALGOLIA_INDEXFILE -a $ALGOLIA_APPID -k $ALGOLIA_ADMINKEY -n $ALGOLIA_INDEXNAME 相比较于本地搜索功能，Algolia 还提供搜索分析的数据报告，能更好的帮你观测自己的站点和用户搜索行为。 发布测试 一切准备就绪那么接下来就发布上线，同样的原则能够自动化的坚决不手动，利用 Github Action 提供的功能，实现站点静态文件自动编译，发布等操作。还有一步重要的同步备份流程不能忘呀，也算是安全意识的一部分吧，便于后续不时之需，所以个有习惯把代码都同步到 Gitee 仓库，而且有网友开发 Gitee Pages 的刷新功能，又再次避免手动操作的麻烦，相当于是一次同时发布了 2 个站点，参考脚本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # 同步到 Gitee 代码仓库备份 sync-2-gitee: needs: deploy-site runs-on: ubuntu-latest steps: - name: Sync Site Source uses: wearerequired/git-mirror-action@master env: SSH_PRIVATE_KEY: ${{ secrets.RSA_PRIVATE_KEY }} with: source-repo: git@github.com:elkan1788/myblog-sources.git destination-repo: git@gitee.com:lisenhui/myblog-sources.git - name: Sync Site Build uses: wearerequired/git-mirror-action@master env: SSH_PRIVATE_KEY: ${{ secrets.RSA_PRIVATE_KEY }} with: source-repo: git@github.com:elkan1788/elkan1788.github.io.git destination-repo: git@gitee.com:lisenhui/lisenhui.git # 刷新 Gitee Page 服务（备份站点） reload-pages: needs: sync-2-gitee runs-on: ubuntu-latest steps: - name: Build Gitee Pages by GitAction uses: yanglbme/gitee-pages-action@main with: gitee-username: ${{ secrets.GITEE_USERNAME }} gitee-password: ${{ secrets.GITEE_PASSWORD }} gitee-repo: lisenhui/lisenhui branch: main 后续计划 对比了下旧版本主题的编译速度，迁移至新主题后效率直接提升 4 倍以上，再配合 Hugo 引擎的性能表现，本博客现有的 270 个页面生成只需要 600ms ，结果就是一个字 “快”，也呼吁大家尽早迁移到新版本的主题上使用，不仅能享用新功能，还可以体验下那“快感”😄。 后面也会持续做好站点生成速度的优化，尽可能的提升到极限😁。\n也希望能够吸引到更多的小伙伴们，一起参与进来共同建设 Hugo NexT 主题。\n除了主题的开发工作外，也会做好博客内容的打造。 在此也感谢 杜老师 的“引荐”，才知道原来还有个叫做 十年之约 的博客友人们组织。 自己现也是 入会十年之约 ，算是给自己立的 🚩，也相信自己能在博客运营上面一直地坚持下去。🎉\n","date":"2022-08-07T20:55:56+08:00","updated":"2022-08-10T22:36:26+08:00"},{"permalink":"/tech/create-your-forever-org-domain.html","title":"创建属于你自己的org永久域名","content":"或许你也和曾想拥有一个属于自己的域名，但又苦于囊中羞涩无力购买，亦或是在国内域名生效前都要实名备案。那么今天就给你带来一个好消息，你可以申请注册一个属于自己的 org 域名，而且不需要花费任何的费用，也不用进行备案就能使用（仅限国外服务器），就问你心动了有没有 😆\n注意： 这里注册的并不是一级域名，而是属于二级域名，要是介意不用往下细看了。 方案 本篇接下来要介绍的方案是通过 eu.org + 腾讯云DSNPod 组合方案来打造属于你自己的个性域名，虽然注册的是个二级域名，但是其主域名长度比较短，且初看上去有点像是 edu 域名，所以不仅好记也有点像高等学府的味道。\neu.org 是欧盟组织下面的域名，EU代表欧盟，Paul Mockapetris在1996年创建了此域名的DNS服务器，计划是专门给无力承担费用的一些组织使用的。所以它对个人和组织是免费注册的，目前已经被谷歌，cf等一些大公司认可为顶级域名。 当然重点还是免费注册，大部分个人或组织都可以开心的白P，不过也担心 eu.org 的DNS能否负载的过来哟！ 😆\n注册用户 填写信息 点击 https://nic.eu.org/arf/en/contact/create/ 链接地址进入到注册环节，个人信息填写部分除电子邮箱是要真实的以外，其他信息可通过 地址生成器 模拟出来并填写，参考如下：\nName：全名（注意中间用空格隔开，不然检测会失败） E-mail：自己真实的邮箱（比如QQ邮箱），用于收取验证链接之类的 “I have read and I accept the domain policy”需要勾选起来 “Password”填写的是你的登录密码； “Confirm Password”是确认密码，这个等下就会用到的，请务必记下来 验证注册 提交好注册信息后，大约等个3~5分钟左右，你的邮箱就会收到一封如下图所示的验证链接邮件，若是没有收到邮件提醒，那么可以检查下是否在垃圾邮箱，或者直接搜索下邮件标题中包含 new EU.org contact 的邮件。\n如邮件内容提示的那样，需要访问其中的激活链接才能正式使用。 不过比较遗憾的是，该激活链接并不能直接点击，需要手动拷贝到浏览器的地址栏或是选中后使用鼠标右键跳转。\n在打开页面中，点击名称为 Validate 的浅蓝色按钮，便完成了激活。\n申请域名 需要注意一下的是，登录用户名并不是你在注册自定义的，而是系统自动分配的带有 -FREE 后缀的账户名称，也就是邮件中 nic-hdl: 后面的字符串，所以建议把这个账户信息保存好，不然哪天不小心忘记账户名，那域名信息也就无法更新啦。\n提交域名 登录后跳转的页面上有个显著的 New Domain 字样按钮，点击后跳转到域名申请提交页面，基本信息会自动从之前的注册信息中同步过来，这里只要填写想要申请的域名，及DNS服务器信息。参考如下：\n注：如果自己没有 DNS 服务器，那么可以到 dnspod.cn 申请个免费的账户，刚上面提交信息时用的 DNS 服务就是 DSNPOD 提供的，其默认的服务地址为：\ndark.dnspod.net pith.dnspod.net 域名的申请过程时间周期不定，所以请留意你的注册邮箱通知，稍微耐心的等待。\nDNS 解析 当申请的域名审核通过后，便可以在你的 DNS 服务中配置对应的域名解析啦，接下来还是以 DNSPOD 提供的免费 DNS 服务为参考示例：\n添加域名解析，输入新申请的域名地址： 添加解析记录，输入你需要指向的服务器 IP 地址： 绑定 接下就是在你的 WEB 服务中绑定上述的申请好的域名，比如在 Nginx 配置中添加域名绑定，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 server { listen 443 ssl; server_name lisenhui.cn; root /webapp/blog; ssl_certificate /etc/nginx/ssl_certificates/lisenhui.cn_bundle.pem; ssl_certificate_key /etc/nginx/ssl_certificates/lisenhui.cn.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { index index.html; } error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } 一般 DNS 解析能在 1 分钟左右生效，也就是说当你完成 Nginx 配置后，便可以看到效果。\n注： 修改完 Nginx 配置后，千万别忘记下面 2 个重要的命令，使新配置生效：\nnginx -t nginx -s reload 总结 eu.org 提供的免费域名申请流程并不复杂，而且审核通过率还是比高的（当然这里不要尝试去挑战申请特定的短域名，准备个符合自己个性化的就好）。不过该域名暂不符合国内备案的要求，所以无法通过公安机关的审核，只能当作是个人平时的爱好使用啦。\n","date":"2022-06-18T20:39:58+08:00","updated":"2022-06-18T20:39:58+08:00"},{"permalink":"/blog/make-nginx-support-http-ssl-request.html","title":"让 Nginx 将 HTTP 请求转发到 HTTPS 安全模式","content":"在某次博主的交流讨论时，忽然间发现自己站点原定让 HTTP 转发 HTTPS 的支持功能，实际上并不没有生效。如果是直接输入域名访问的话，那么会出现 400 的错误页面。当初为了让全站支持 HTTPS 也是耗费了不少精力，没想到却是这个结果。\n然后便是首先检查了下 Nginx 的配置，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server { listen 80 default_server; listen [::]:80 default_server; server_name lisenhui.cn; root /usr/share/nginx/blog; # SSL ssl on; #ssl off; ssl_certificate 1_lisenhui.cn_bundle.crt; ssl_certificate_key 2_lisenhui.cn.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { index index.htm index.html; } } 参考网上的说法，这里是要关闭 SSL 的配置让 HTTP 请求走非 SSL 模式，但又不符合自己的预期，也尝试通过 302 状态转发同样未成功。\n后来找到个资料上提示可使用 497 错误代码来转发，增加如下代码：\n1 error_page 497 https://$host:$server_port$request_uri; 497 代码是发送到 HTTPS 端口的 HTTP 请求 $host 是保留变量，代表正在运行 Nginx 的主机名 $server_port 是保留变量，表示在服务器部分中声明的侦听端口 $request_uri 是 reserverd 变量，代表完整的原始请求 URI（带有参数） 亲测，在 location 前面增加那段引用后，站点的 HTTP 请求就可以自动转发到 HTTPS 模式确保访问的安全性。\n参考：\nnginx-原始HTTP请求已发送到HTTPS端口 ","date":"2022-05-30T15:55:03+08:00","updated":"2022-05-30T15:55:03+08:00"},{"permalink":"/blog/repleace-jsdelivr-with-unpkg-as-cdn-vender.html","title":"用unpkg替换jsdelivr作为本站CDN提供者","content":"前几天就有看到网友在讨论 jsdelivr 服务被墙的消息，可能是刚开始的缘故吧，当时发现自己的站点倒还算是正常的，只也没坚挺几天也面临加载 jsdelivr 资源的失败问题。一番排查下来，发现受影响的部分还是比较小的，至少当时站点的 CSS 文件没有托管到 CDN 上，只要更换受影响部分的 CDN 链接引用便是。\n只不过是更换到哪个 CDN 会更有保障些呢？这还真是个苦恼的问题，自己并不太懂前端的技术，起初建站的时也就是想着将公有部分的 JS 和 CSS 资源通过 CDN 来引用效率会更高而已，也未曾想过会有今天这个遭遇。然后碰巧看到评论插件 waline （之前也是使用 jsdelivr） 使用了 UNPKG 作为 CDN 提供者，便决定跟随大众的路线走吧。\n但接着又出现了个苦恼的问题，就是 UNPKG 并没有提供直接查询资源的引擎，对于自己这个前端小白来说真是有苦恼呀。经过一番尝试后，总算是找到一个解决办法，步骤大致如下：\n1.访问 npmjs 站点检索 点击打开 npm 公司的站点： npmjs ，在搜索框中输入需要使用的资源名称，比如jquery，然后点击右边的版本号标签卡，参考如下图所示的3步操作。\n此时便会在地址栏中得到个相应的访问地址，类似： https://www.npmjs.com/package/jquery/v/3.6.0 2.切换到 unpkg 浏览资源 将上一步得到地址中的 package 后面的字符截取下，便成类似 jquery@3.6.0 这样的组件名称 + 版本号，把它加到下面这个地址后面：\n1 https://unpkg.com/browse/jquery@3.6.0/ 注： 切记最那个 / 字符一定要加上，不然就会找不到资源。\n此时便可以浏览对应组件的资源，如下图所示，也能按需切换版本号查看。\n确定需要使用的资源后，点击文件链接进入查看内容，此时页面右上角会有个按钮，拷贝那个按钮上的链接就是资源的 CDN 访问地址，参考如下：\n1 https://unpkg.com/jquery@3.6.0/dist/jquery.js 将它更换到你所需要使用的位置即可。\n上述就是本站替换的 jsdelivr 服务的方法，但后面对比发现，其实 jsdelivr 和 unpkg 的路径相对还是比较规范的，而且两者之间的资源也是相差无异，所以一般情况下不需要前面这么麻烦的操作，直接在 IDE 里面批量替换下就好，遇到有问题时再参考前面的方法进行修复。\n1 2 3 4 \u0026lt;!-- jsdelivr 资源路径 --\u0026gt; https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.js \u0026lt;!-- unpkg 资源路径 --\u0026gt; https://unpkg.com/jquery@3.6.0/dist/jquery.js 仅以此文先记录下来，后续在新版本的主题中再结合着看如何进一步优化调整有关于 CDN 的设置参数，免得下回还得因 CDN 等服务不稳定而“大动干戈”。\n","date":"2022-05-20T19:03:27+08:00","updated":"2022-05-20T19:03:27+08:00"},{"permalink":"/tech/virtualbox6-cup-clock-not-started.html","title":"VirtualBox6.x版本CPU时钟Bug导致虚拟机无法开机","content":"下午在启动平时常用的虚拟环境时，发现进度条卡在中间老半天都不会动，情况不太正常，以前启动时间最多也就是 10 几分钟就能看到桌面。点击键盘的方向键看打印的日志，一直在重复如下图所示的 Bug 信息，即使后面等待了半个多小时进入系统后，这个日志信息也不断的在终端界面上输出。\n见此觉得很是纳闷呀，也没有对虚拟机的设置和里面的系统做过任何参数调整，为何突然就这样不可使用啦。然后尝试了下其他的虚拟机环境，但是都正常成功的启动，这下子就更加郁闷无语啦。先是测试了重新导入新的镜像文件现象依然存在，然后又试了下网上的各种方法，如修改启动脚本，调整CPU分配，关闭开机服务等都没有效果。后来找做运维的朋友咨询了下，建议可以尝试下使用 VMWare 能否正常启动，于是乎便开始下载软件，安装，配置等各种折腾起来。最后导入到了 VMWare 环境中，点击虚拟机启动，成功的进入到了系统，各项功能也能正常运转。真是神奇！！！\n难道后续要切换使用 VMWare 环境使用虚拟机，但在尝试导入 Windows 平台虚拟机时失败了。那看来还是得想下办法能否修复上面遇到的问题，便又在网络上开始漫游希望能否找到解决办法。在寻找的过程中突然想到，为何不去 VitualBox 官方网站试试，然后在官网中输入 CPU 作为关键字，还真找到了篇类似的问题，总结下来就是这是 VirtualBox 6.x 版本的 BUG 影响，建议回退到之前的旧版本。然后在官方的归档库中找到了 5.x 的最新版本测试了下，之前遇到的问题果真就不存在。\n至此问题算是解决了，但真的不明白为何会突然这样，之前也是使用 6.x 版本也没有出现过该问题，莫非说是特定的时间触发的 Bug 产生，真有点丈二和尚摸不着头脑，只能是写文记于此吧。\n参考：\nNested virtualization BUG: soft lockup - CPU#4 stuck for 22s! ","date":"2022-04-21T18:39:47+08:00","updated":"2022-04-21T18:39:47+08:00"},{"permalink":"/tech/sshlogin-localvm-slowly-mobaxterm.html","title":"使用Mobaxterm登录本地虚拟机很慢","content":"近期因本地虚拟机有问题但重新搭建了个新环境，结果在使用 MobaXterm 工具登录终端时发现每次都要等待个 4 ~ 5 秒才可以进入，操作检验不是很好，不明白为何本地环境连接会是这么的慢，所以还是得想办法分析下。\n看有些网友也有类似的困惑，提示说可能是 SSH 登录时要通过 DNS 来寻址的原因。参考文章上说法找到 /etc/ssh/sshd_config 把里面的 UseDNS 配置项设置为 no，但是发现其已经是关闭的状态。那会是什么原因引起呢？\n提到 DNS 突然想到不会是本地 Host 文件的问题吧（个人习惯使用 hostname 连接服务器），于是尝试直接把 MobaXterm 的连接地址换成服务器 IP 地址，满怀希望的点击登录按钮，可惜结果还是要等待一会才能进入，真是有点抓狂啦。\n稍微“冷静”下来想下，发现现在还是没有确定问题的发生原因，究竟是 MobaXterm 工具还是服务器配置的问题呢？于是使用最简单的 SSH 命令，结果非常惊喜，无论是通过 IP 还是 hostname 方式连接都无须等待，可立马就进入终端操作。那么已经可确认就是 MobaXterm 工具原因。\n于是检查 MobaXterm 的登录配置，个人习惯使用已经配置好的用户名登录，但似乎也是没有问题呀。\n然后点击下旁边的 Passwords 标签卡发现里面也是存储 2 个密码，难道说就是这个原因？\n果断的删除了 Passwords 里的这两 2 个密码记录，再次登录虚拟机的服务器，终于得到自己想到的结局。 🙊\n结论 不知为何产生这个现象，就是 Passwords 中的那 2 条密码记录，暂时还是没有了解清楚，后续要也是遇到类似的情况，可以参考上述的方法，或许能够帮助到你。\n","date":"2022-04-04T11:53:34+08:00","updated":"2022-04-04T11:53:34+08:00"},{"permalink":"/tech/use-travisci-remote-deploy-site.html","title":"TravisCI 远程部署站点服务","content":"背景 之前一直都是将自己的博客站点托管在 Github Pages 服务上面，但无奈国内的访问速度确实是让人堪忧，时不时还会出现打不开现象，确实影响到访问查看的体验。另外近期腾讯云的 ICP 备案又开始各种检查“臊”操作，一旦发现域名解析 IP 地址不是其云服务的话就会终止 ICP 备案，那后果可想而知肯定是域名会被终止访问引起一连串的不可预知问题（毕竟重走 ICP 审批流程也是非常的烦恼）。于是便只好订阅了腾讯云的轻服务产品，把站点静态内容托管在其上面。\n问题 于是乎便又重新搭建新环境的各种折腾，先是安装各类基础软件，如： Hugo、Git、Nginx等等，此处的细节就不在展开了，大家在网上都能找到相关环境的指导文章。 然后便考虑如何在这个环境下根据文章发布时的推送，自动生成新的静态站点内容。后来还是选择了 Travis CI 平台来实现自动化部署（可参考之前写的教程 Travis CI自动部署教程 ）。\n顺便说下，个人使用下来觉得 Travis CI 比 Github Action 要更加稳定些，至少在个人仓库的使用中。\n基本流程是如下：\n其中在使用 SSH 命令远程执行操作时会涉及到私钥的加密保护，之前一直接使用 Windows 生成加密文件操作都没有问题，不知道为何此次使用 Travis CI 的新版本后，生成的加密文件在解密过程中一直出现如下的错误：\n问题 1：\n1 2 3 4 $ openssl aes-256-cbc -K $encrypted_39c1b18630f7_key -iv $encrypted_39c1b18630f7_iv -in .travis/id_rsa.enc -out id_rsa -d iv undefined The command \u0026#34;openssl aes-256-cbc -K $encrypted_39c1b18630f7_key -iv $encrypted_39c1b18630f7_iv -in .travis/id_rsa.enc -out id_rsa -d\u0026#34; failed and exited with 1 during . Your build has been stopped. 另外在腾讯云的服务器上执行 git pull 命令时，也会出现如下的告警及错误信息：\n问题 2：\n1 2 3 $ tail -f ~/deploy.log warning: 不建议在没有为偏离分支指定合并策略时执行 pull 操作。 /home/lighthouse/deploy.sh: hugo: 未找到命令 方案 对于问题 1 找了很多的官方文档也并没发现操作流程和步骤存在问题，于是便尝试了下在线发起工单支持，没想到官方的答复还是很快速的，经过一讨论和验证官方也觉得是 Windows 平台的加密有问题，建议切换到 Linux 平台下使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Hey there, Thank you for your reply. It seems you are using a Windows machine to generate an SSH key and encrypt the file. Since decryption happens in Linux VM which I believe could be the reason for the bad decrypt error for the build. Would it be feasible for you to use a Linux machine and follow the steps I mentioned earlier, i.e. cd into repository Run travis login --pro --github-token GITHUB_TOKEN Run ssh-keygen -t rsa -b 4096 -C \u0026#34;TravisCIKey\u0026#34; Run travis encrypt-file --pro ~/.ssh/test_key --add Run git add . \u0026amp;\u0026amp; git commit -m \u0026#34;encrypt-file\u0026#34; \u0026amp;\u0026amp; git push Please let us know if you run into any issues. Best, -- Qasim Your Friends @Travis CI Test and Deploy with Confidence. www.travis-ci.com 然后又重新在 Linux 平台下搭建个 Travis CI 命令行的环境，参考上面的给出的步骤重新生成私钥并加密上传，结果还是真的就没有问题。\n顺便提下，在 Linux 平台下搭建 Travis CI 命令行环境比 Windows 平台简单多，只需要一条 yarn 命令敲下回车键就好。\n而对于问题2的警告原图，主要是 Git 的合并策略所引发的，原因是本地有做过修改需要进行拉取和合并，建议可以使用 git pull --no-rebase 命令避免冲突的调整。而另外一个错误的原因是 Hugo 安装时只是添加到 PATH 变量中，但对于远程执行命令调用来说，默认是调用 .bashrc 文件中的环境变量，于是只要在执行分布命令用户的 .bashrc 文件中添加 Hugo 的可执行命令路径即可。\n总结 此次遇到的问题都是和服务器环境有关系，建议在涉像文章提到的密钥生成及管理，第三方命令（主要是不提供安装包形式），环境变量等操作，有可能的话还是在 Linux 或 macOS 系统下进行调试，能够避免不必要问题的发生，节省更多时间出来。\n","date":"2022-03-22T22:13:43+08:00","updated":"2022-03-22T22:13:43+08:00"},{"permalink":"/tech/use-sublime-txt-build-hugo-site.html","title":"使用Sublime Text搭建Hugo使用环境","content":"自从捣鼓 Hugo 建站以来也有好长一段时间啦，但是之前的使用环境比较的 “松散” ，比如编辑博客文章用的是 Sublime Text 文本工具，再通过 CMD 命令行工具调用 Hugo执行本地预览，最后再 使用 Git Extension 图形工具将博客文章发布到 Github Pages 供网友们浏览。 从整个操作流程上来看还是可以的，只是在过程中要切换不同的工具操作，而恰好看到 Hugo 官网上有个 Sublime Text 的 插件 ，于是乎有了重新整合 Hugo 使用环境的想法，哈。\n安装插件 根据上面所说的操作流程，整理需要在 Sublime Text 上安装的插件有如下4款：\nGit MarkdownEditing Hugo Snippets Hugofy 直接在 Sublime Text 使用 Ctrl+Shift+P 快捷键输入 pci 选择第一项，逐一输入上述插件名称安装。\n快捷键设置 这里 Git 和 Hugo Snippets 是没有快捷键可使用的，只能通过 Ctrl+Shift+P 快捷键 + 关键字来执行相关的命令，参考如下：\nCtrl+Shift+P + git(关键字)： 会显示出 Git 的命令，如add, commit, push等常用操作功能； Ctrl+Shift+P + snippet hugo(关键字)： 会显示出 Hugo 的语法，移动上下键选择便可插入代码块； 而 MarkdownEditing 在文档编辑过程中，除自动识别语法字符外，比如当输入 _ 字符会自动补全可直接写文档。另外也提供了一些快捷输入的组合按键，参考如下：\n功能说明 组合键 标题 Ctrl+1~n 粗体 Alt+B 斜体 Alt+I 插入图片 Win+Shift+V 链接 Ctrl+Alt+V 引用 Ctrl+Shift+. 取消引用 Ctrl+Shift+, 注释 Ctrl+Shift+/ 代码块 mdc+Tab 注： 除引用较为特殊外，其他组合键都是可以连按两次进行取消的,很遗憾没有表格快捷方式。\n最后就是要创建 Hugofy 启动站点服务的快捷方式，不过在此之前需先配置下站点路径等参数，打开 Preferences -\u0026gt; Package Settings -\u0026gt; Hugofy -\u0026gt; Settings - Users 选项，参考如下配置调整自身实际情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { // 站点根目录的上一级 \u0026#34;Directory\u0026#34;: \u0026#34;C:\\\\Users\\\\senhui.li\\\\Documents\\\\GitRepos\u0026#34;, \u0026#34;Server\u0026#34;: { // 生成草稿 \u0026#34;DRAFTS_FLAG\u0026#34;: true, // 服务端口 \u0026#34;PORT\u0026#34;: 1313, // 不需要添加主题参数 \u0026#34;THEME_FLAG\u0026#34;: false }, // 站点存放的目录名称 \u0026#34;Sitename\u0026#34;: \u0026#34;elkan1788.github.io\u0026#34; } 接着打开 Preferences -\u0026gt; Key Bindings 选项，加入你想设置的快捷键，参考如下：\n1 2 3 4 { \u0026#34;keys\u0026#34;: [\u0026#34;ctrl+alt+h\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;hugoserver\u0026#34; } 那么此时只要按下 Ctrl+Alt+H 组合键，后台就会启动 Hugo 站点服务，打开浏览器即可访问站点。\n总结 自此以后便可以在 Sublime Text 的全家桶中“畅游”，喜欢就快来加入吧，给众多网友分享下你的宝贵经验。\n","date":"2022-02-12T16:32:10+08:00","updated":"2022-02-12T16:32:10+08:00"},{"permalink":"/tech/use-sublime-txt-build-hugo-site.html","title":"Sublime Text安装插件失败","content":"近期因公司之前分配的电脑出了点毛病，无奈只能重新换个新电脑，所以环境也得从头进行搭建。而一直使用的 Sublime Text 是绿色版本，直接拷贝过来后启动，编辑等操作都是正常的，但在尝试安装新的插件时就遇了如下的问题。\n错误信息：There are no packages available for installation\n然后检查安装目录下的 channel_v3.json 文件是正常的，只好尝试打印系统日志来看追踪下问题，使用 Ctrl + ~ 快捷键打开终端，输入如下的代码开启：\n1 sublime.log_commands(True) 注： 千万记得在调试完成后关闭日志输出\n再次尝试安装插件时，便发现提示系统找不到指定的路径异常，一看那个路径才恍然大悟，然后来是之前电脑的安装位置，那只要更新下配置文件路径就好啦。\n打开 Preferences -\u0026gt; Package Settings -\u0026gt; Package Control -\u0026gt; Settings 选项修改 channels 的参数值，保存后便可以成功安装插件啦。\n1 2 3 4 5 6 7 { \u0026#34;bootstrapped\u0026#34;: true, \u0026#34;channels\u0026#34;: [ \u0026#34;C:/xxxx/channel_v3.json\u0026#34; ] } 最后发现 channel_v3.json 文件也好久没有更新了，便顺道访问官方文件 channel_v3.json 拷贝进行更新。\n参考：\n官方文件地址： https://packagecontrol.io/ ","date":"2022-02-08T12:31:13+08:00","updated":"2022-02-08T12:31:13+08:00"},{"permalink":"/blog/make-next-theme-pithy2.html","title":"优化Hugo Next主题的过程2","content":"1.背景 自上次优化NexT主题并分享到Github仓库中 hugo-theme-next 后，也是受到了不少NexT主题喜爱者的使用和邮件反馈。于是决定还是要花点心思来维护它，便把自己之前一些想法也重新加入到NexT主题中，同时对部分插件的功能做了更新。\n此次优化后发布的版本代号为3.x，原因是整体结构和之前的变化较为大（主要是在配置方面的体现），为此也重写主题的相关介绍等信息，目前正在申请加入官方的主题列表中( 点击预览 )，欢迎大家的使用和反馈。\n2.中英文切换 或许大家觉得这个功能有点软肋，原因就是个人博客的流量并不会很大。但流量小并不是意味着没有流量，所以我们还是可以增加个中英切换的功能，来助力我们推广自己的博客空间。而且Hugo引擎在多语言化这块的开发也比较简单，不过现在是手动模式，也就意味着你在发表文章写两份。增加中英文切换功能后的效果参考如下：（就是在左上角添加了切换入口）\n后续考虑是否可能引入自动翻译的模式来加载，可以减少写文章耗费的时间。\n3.重构配置 结合上面的中英双语切换功能，对于主题的配置内容管理来说就会变的比较混乱，个人不喜欢在一个文件中写满太多的配置参数。而这块的想法正好Hugo引擎的设计不谋而合，它天然就支持按分类的管理方式来独立配置不同的参数。\n同时也对本主题中使用的各服务组件配置做了分类，这样显示更加清楚明了，也便于后续参数的调整及优化。\n4.addthis分享 主题中原来使用的BShare插件，但在某一天突然就发现其无法正常引用。真是感叹在继百度分享插件后，又一国内分享插件的落幕。所以后来就找到了国外一款比较流行的插件addthis，通过一番倒腾研究终于成功集成，用于替换原来的BShare插件。\n在主题中启用也比较简单，分如下2步：\n到addthis官方网站上去注册个账号（ 点击注册 ），然后获取到个人的ID号，类似这样的：ra-6049e46e9ee54287； 在配置文件中找到Share配置项，设置Enable = true和AddthisId = \u0026quot;Your AddthisPubid\u0026quot;两个参数； 实现的效果如下：\n5.本地搜索优化 之前本地搜索生成的索引文件是覆写到robots.txt，但在中英双语的情况下便无法支持两种不同中英文索引，所以需要改造原来的生成索引方式。而这也是再一次感受到Hugo引擎的强大之处，它完全可以支持自定输出文件，只需要如下的几行配置：\n1 2 3 4 5 6 7 8 9 [outputFormats] [outputFormats.SearchIndex] mediaType = \u0026#34;application/xml\u0026#34; baseName = \u0026#34;searchindex\u0026#34; isPlainText = true notAlternative = true [outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;SearchIndex\u0026#34;] 6.支持数学公式 有网友反馈本主题无法支持数学公式的渲染，后来分析了下发现是之前优化文件引用中把MathJax文件给移除所造成的。于是重新修复了此功能，使用时只需要在文章的页面参数中加入math: true配置即可，效果如下：\n7.Waline评论 原来主题中使用一款Valine的评论插件，但网上关于此未评论插件的安全问题也是讨论的“血雨腥风”，但过多的讨论咱就不参合啦。在此背景下便有人衍生出Waline插件，通过服务端的部署来解决安全隐患。个人还是比较喜欢它的评论管理功能（可以有效屏蔽一此恶意灌水），于是又展开了一番研究，成功在Vercel上面部署自己的评论后台服务，也在博客中升级并引用此评论插件功能。\n这款评论插件的部署相对来说还是要有些“成本”，不过官方的文档很完善，社区回答也很活跃，大家可以放心快速使用。具体参考： 指南 然后在配置参数中找到Comment配置项，填写如下的信息，就可以在博客页面看到评论框。\n1 2 3 4 [Comment] Enable = true Module = \u0026#34;Waline\u0026#34; WalineSerURL = \u0026#34;Your WalineSerURL\u0026#34; 8.Gitee图床 写博客中或多或少都是会使用到图片的，以前那些可免费使用的服务，随着岁月的流逝“薅羊毛”的福利也不再有啦。中间也倒腾过不同的服务商，现在还是选择放弃啦，把图片都统一上传到仓库吧。考虑到访问用户都在国内居多，于是就是使用了Gitee的Pages服务作为图床。\n还好当初写博客时对图片的分类管理比较清晰，更换图床也没有太痛苦，只是一键更换个访问域名。论架构设计的得要性呀！！！\n9.其它优化 剩下就是有关于显示样式，不同设备间适配的问题。虽然看起来似乎很简单，但真的切入进去才发现调试真的很痛苦。修复过程中还特地到Hexo引擎版本的NexT主题上去“偷师”几把，在移动设备上显示上增加了些效果动画，增强操作的体验。\n10.总结 个人就是比较喜欢NexT的简单清爽，所做的这些改造和优化工作，是为了主题更加完善和好用，并不会去改变NexT主题的设计初心，希望NexT主题能在Hugo引擎下继续发光发热。\n后续会逐步优化使用手册和主题的其他问题，也欢迎更多爱好NexT的网友一起参与进来，共同建设，期待。\n","date":"2021-07-09T17:53:06+08:00","updated":"2021-07-09T17:53:06+08:00"},{"permalink":"/tech/replace-files-in-springboot.html","title":"替换SpringBoot里的文件","content":"现在使用Spring Boot架构的应用开发来说是非常的普遍，统一化的打包部署确实带来不少便利，但当遇到问题时也是会比较棘手。或许你会觉得很惊讶，但如果说这是产品部署运维过程中遇到的难题需要修改Spring Boot应用程序，你就会觉得困难也是不奇怪的。本文就来分享下如何使用jar命令应对线上部署产品时，要临时替换Spring Boot应用中的Jar包的操作。\n在测试环境部署某个产品应用时，在最后启动时遇到失败，查看并分析启动日志，发现了如下的堆栈日志信息：\n看到此MySQL驱动的类名，当时心中已经有了答案，估计肯定是因为高版本的MySQL驱动程序不兼容低版本的MySQL Server所引起的。接下来使用如下的 jar 命令进一步确认下便是：\n1 2 $ jar -tvf semxxx.jar | grep mysql mysql-connector-java-8.0.12.jar 当前测试环境使用的 VM 集成镜像，里面很多组件版本相对比较低，但一直使用都没有问题也未曾再升级。\n从上面错误的堆栈日志中有看到DruidDataSource字样，猜测此开发使用了Druid数据库连接池，那还是很有希望的，因为Druid数据库连接池有个自动适配数据库驱动程序类的能力特性，但愿开发在写代码时没有使用硬编码的形式。\n网上搜索了一些关于 jar 命令如何打包有主运行程序的JAR包后，便着手开始替换MySQL程序的工作。相关步骤如下：\n解压产品打包好的spring-boot应用程序 1 $ jar xf semantic-xxxx.jar -C tmp/ 删除lib目录下的MySQL高版本驱动 1 2 $ cd ./tmp/BOOT-INF/lib/ $ rm -rf mysql-connector-java-8.0.16.jar 添加低版本的MySQL驱动包 1 2 $ cd ./tmp $ cp ~/mysql-connector-java-5.1.34-bin.jar ./BOOT-INF/lib/ 修改classpath.idx文件中的JAR列表 1 2 3 $ cd ./tmp/BOOT-INF/ $ vim classpath.idx $ # 把那个高版本驱动程序JAR名称修改成低版本的名称即可 重新打包Jar 1 2 $ cd ./tmp $ jar cfM0 semantic-xxxx.jar . 最后就是重新启动应用程序，“万幸”我们的程序员们没有写硬编码，启动成功，如愿进入到了产品的操作界面，功能使用也一切正常。\n参考文章：\njar命令修改 springBoot打包成的jar 直接替换Springboot jar包中的文件 springboot项目jar包发布的，如何线上修改jar包 ","date":"2021-04-14T17:43:20+08:00","updated":"2021-04-14T17:43:20+08:00"},{"permalink":"/tech/join-istio-translation-org.html","title":"加入Istio官方翻译组织的历程记录","content":"作为曾经的程序猿，自己也一直“享受”着来自开源社区的那些无私分享。这些开源项目对自己的影响和启发还是很大的，之前就有想过如何去回馈开源社区，也开贡献过自己的一些项目，参与过一些开源项目，但都还是仅限国内的项目。不久前正好看到 Jimmy Song 在微信朋友圈发布 《Istio 官网翻译工作组成立暨志愿者招募》 的动态，没有任何的犹豫，下班后便联系 Jimmy 申请加入翻译工作，并在随后的时间完成自己的首次翻译，也成功被合并到了 Istio 官方仓库的主分支当中。如果你也有和我一样的想法，那么欢迎您也来一起加入，期待。\n接下来给大家一起分享下，加入Istio官方翻译组织的历程，为后续想加入（或是参与其他开源项目）的小伙伴们做个引路参考，如有不明白之处，可以在文章下的评论区，发表你的建议或意见，谢谢。\n翻译的全流程概览如下：\n1. 准备工作 俗话说： “磨刀不误砍柴功。” 在正式参与项目合作之前，还是有不少的准备工作需要做的。 当然如果您是资深的开源玩家，那么这些对您来说都是轻车熟路，可以直接跳过本篇文章，参与到实际的项目合作中去。\n1.1 科学上网 在技术方面，谷歌可以说是一直都在领导者位置，只是可惜国内情况，并不能让我们愉快的使用这份“珍贵”的资源，所以你得学会如何使用VPN进行访问谷歌站点，因为后续的任务登记在Google docs中。 不过这个能力需要您自给自足，您可以通过网络寻找到很多不错的资源。\n1.2 Github账号 作为全球知名的 Git 代码仓库管理与共享平台，相信您早已注册有账号，如没有账号也没有关系，现在您就可以通过 Github 在线注册快速获取，开启您的“新世界”大门。\n1.3 Git环境与工具 Git安装还是比较简单的，可直接到官方网站 Git Downloads 下载与您电脑系统对应平台版本安装。同时也可以安装个图形化的客户端，个人一直使用的是 Git Extensions 工具，它集成Git的命令操作与相关概念，可以帮您提高 Git 使用效率。当然如果您是一名 Geeker，那仍然可以追求命令行的速度，两种方式任君选取。\n关于 Git 和 Github 的更多详细使用，初学者可以参考下 Github新手详细教程 这篇文章。\n1.4 Hugo运行环境 Hugo （基于Go语言）是当下主流的静态站点生成引擎之一，Istio 的官方站点便是基于此引擎构建的，因此您也需要熟悉下对它的基本使用。放心非常的简单（对此 Istio 翻译项目而言，只需了解一个运行命令即可），相信经过此次翻译工作之后，您也会深深“爱”上它的。\n首先在 Hugo 官方仓库的发布中，找到并下载与您电脑系统对应平台的版本 Hugo Downloads ，然后把下载文件解压到适合的位置，并为之配置系统环境变量，最后终端工具上使用 hugo version 或 hugo env 命令来检测 Hugo 安装是否成功，正常情况下是会输出如下的版本信息：\n1 2 \u0026gt; hugo version Hugo Static Site Generator v0.80.0-792EF0F4 windows/amd64 BuildDate: 2020-12-31T13:37:57Z 至此，您的 Hugo 环境便已经准备好了，可以在本地运行 Istio 的文档预览效果。当然您也可以稍微多些了解下 hugo server 命令相关的参数，或许某些时刻您会用的上，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 hugo server # --bind=\u0026#34;127.0.0.1\u0026#34; 服务监听IP地址； # -p, --port=1313 服务监听端口； # -w, --watch[=true] 监听站点目录，发现文件变更自动编译； # -D, --buildDrafts 包括被标记为draft的文章； # -E, --buildExpired 包括已过期的文章； # -F, --buildFuture 包括将在未来发布的文章； # -b, --baseURL=\u0026#34;localhost\u0026#34; 服务监听域名； # --log[=false]: 开启日志； # --logFile=\u0026#34;/var/log/hugo.log\u0026#34;: log输出路径； # -t, --theme=\u0026#34;\u0026#34; 指定主题； # -v, --verbose[=false]: 输出详细信息 若您是一名程序猿，相信它会改变您对网站开发的模式，毫不夸张的说，结合当下云生态的无服务化编程，静态站点的开发是个全新的世界。\n1.5 MD文件编辑工具 Istio 的站点文档均是采用MD格式的文件，所以我们需要一款自己熟悉的MD文档编辑工具。在此推荐使用比较广泛且功能强大的 Sublime Text 文本编辑器，加上 Markdown Editing 插件的加持，让你的MD文档编辑非常的顺滑。\n1.6 翻译工具 英文毕竟不是我们的母语，在翻译过程中或多或少还是需要借助下翻译工具的支持，个人使用的网易有道词典桌面版本，在大部分情况下翻译效果还是比较满意的。\n2. 加入组织 接下来就是开始“寻找”组织，并加入其中成为一员。\n2.1 加入沟通群 已知是有个微信的沟通群，方便大家相互交流翻译过程中的问题。之前此群是可公开加入，但由于广告党的入侵，已经调整策略，只能由管理员来拉人，感兴趣的小伙伴们可以给 rootsongjc@gmail.com 或是 kebe.liu@daocloud.io 两位管理员申请加入。\n2.2 登记个人信息 为了让大家相互彼此了解及翻译过程中的合作，需要你在 Google Docs（点击加入） 上面填写些个人信息，如Github账户名称，邮箱地址，姓名等基础信息。\n2.3 克隆Istio仓库 因为当前我们还不是 Istion 的正式 Commiter，所以我们只能通过 Pull Request (简称PR)方式提交我们的修改内容，这就需要先把 Istio 的官方文档仓库克隆到我们自己的仓库列表中。访问 Istio 仓库的地址： https://github.com/istio/istio.io（点击打开） ，点击右上角的 Fork 按钮，稍等一会便可以在自己的仓库中看到同名的仓库，然后将此仓库克隆到本地电脑中用于后续的翻译编辑。\n3. 翻译流程 上述准备工作都已经完成好后，便可以开始我们的 Istio 翻译之旅啦。\n3.1 登记任务 如同上面登记个人信息一样，正式开始翻译前，需要在文档中登记下您要认领的任务。（多人协作的协同方式，不然大家都窜到一块去就不好啦）任务文档中标记了各个任务的优先级别，可按照这个次序由高到低开始认领，记得要登记认领人和状态等信息。\n3.2 翻译工作 开始翻译之前，建议先快速浏览下所认领的任务，看是否有合适归并在一起的类型。一般情况之下，是建议每翻译一篇文章都独立创建个分支开展，但如果调整内容比较少的话，可以考虑归并到一起，减轻Reviewer的工作量。\n另外建议每次翻译前，先对比下 Istio 官方仓库，并进行同步更新到本地，操作流程请参考下面 《4.1 如何同步官方仓库更新》 的章节。\n接下再给大家分享下，在翻译中使用小技巧：\n设置好编辑器的换行显示，避免编辑时要左右拖动滚动条； 开启左右两个窗口模式，可以使用Windows自带分屏功能或是编辑器的窗口功能，推荐使用后者切换时比较方便； 使用 Crtl+P 快捷键打开 Sublime Text 的搜索功能，拷贝领取任务中的文章路径，分别打开 en 和 zh 目录下对应的文件，如下图所示： 翻译工作确实会比较枯燥一些，要逐行逐句进行理解和提炼，非常考验您的耐心，哈\n在完成翻译工作后，建议启用本地的 Hugo 服务预览验证下，确保排版，图片，标点符号等显示都没有问题。\n3.3 PR提交与评审 完成翻译和自我检查工作后，便可以使用 Git 命令或工具提交您的贡献，记得不仅要提交在本地，还要推送到 Github 远程仓库上呢。\n推送成功后切换到您 Github 下的 Istio 仓库主页，就可以在代码上方看到一个明显的 PR 提示，点击绿色按钮就可以快速创建并提交给 Istio 官方，静静等待其他人的评审。\n3.4 更新任务状态 记得提交完 PR 后及时在登记的任务栏中添加 PR 记录，并更新状态，同时也要留意自己的邮箱或是查看 Github 上的消息通知（如下图所示），关注最新的变化。可能在其他评审后需要您进行修改（按评审建议调整对应内容，重新提交即可），如没有问题一般都是直接被合并的。\n至此，整个翻译的流程便已经完整走通，在等待 PR 的日子里\n4. 常见问题 4.1 如何同步官方仓库更新 翻译工作一般都是比较被动的，加上大家工作的时间差异，可以在翻译前参考如下步骤同步当前官方最新文档状态：\n在自己的仓库中，创建个新的PR请求，如下图所示： 参考下面的图片数字顺序，调整对应仓库名称与分支（左边是自己的仓库，右边是官方的仓库），点击右边的绿色按钮，填写相关的评审信息（主要是自己能理解的就好，没有标准） 然后会自动跳转到那个PR，在下方找到 Merge pull request 按钮点击并确认即可； 使用 git pull 命令或是 Git Extensions 工具拉取最新文件到本地； 4.2 本地运行时缺失JS和CCS文件 Istio 的静态资源采用了sass方式进行开发，所以本地运行时可能无法编译这些文件，导致您在本地预览时无法正常显示（比较错乱），可以找群里的其他小伙伴分享一下（或是点击下载 istio.io-generated-files.tgz ），然后把 css, js, img 里的资源放到本地的 static 对应目录下面，重新启动 Hugo 服务后就可以正常的显示。\n注意： 提交翻译文件时，不要把这些资源文件提并上去，需要把它们过滤下。 在 Windows 平台下有个操作小技巧，不要关闭 static 的文件窗口，然后提交前直接按 Ctrl+Z 组合键就可以快速撤销。\n4.3 提交PR进遇到 google-cla 检查失败 在 Istio 的自动化检查过程中，有个环节是需要谷歌的 CLA 支持的，首次提交 PR 时可能会遇到如下的问题，那么只要去 comment 里的那个链接地址注册一下就好，但要注意名称与要您的 Github 账号名称保证一致，不然无法通过检验。\n4.2 如何查找过时移除文档记录 翻译过程中，您可能会遇到一些文档因过时而被移除的情况，那么这时您不是只简单的同步删除过时文档，建议还是要在 commit 信息中把对应的删除 PR 找出来。 这里可以借助 git log 命令帮您定位，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # see the changes of a file, works even # if the file was deleted git log -- [file_path] # limit the output of Git log to the # last commit, i.e. the commit which delete the file # -1 to see only the last commit # use 2 to see the last 2 commits etc git log -1 -- [file_path] # include stat parameter to see # some statics, e.g., how many files were # deleted git log -1 --stat -- [file_path] # see the change content detail git show commit_id 复制找到的 commit_id 信息，切换到 Istio 官方的 PR 记录中，通过搜索可以快速定位到是哪个 PR 提交的，然后把 PR 链接和描述信息一并附上，这样 Reviewer 就可以清楚的知道缘由，快速帮忙你评审。\n5. 总结 在参与 Istio 的翻译过程中，还算是比较顺利的，不仅让自己学习到了不少 Hugo 的建站用法，而且也提升了个人的翻译能力。\n最后希望本文能对您有所帮忙，也期待您能一起加入进来，大家共同努力争取早日完成这份 “大业” 。\n","date":"2021-03-20T11:48:53+08:00","updated":"2021-03-20T11:48:53+08:00"},{"permalink":"/tech/add-sync-gitee-action.html","title":"使用Github Action自动同步仓库到Gitee","content":"1.背景 作为程序员出生的你，肯定知道备份的重要性。再说现在大环境背景下，美国的政治关系还是比较混乱的，而对于存放在Github上面的项目，也不再是技术自由的国度啦。所以说我们的代码还是有必要进行“双”备份的，接下来就是介绍下，如何使用Github上面的Action功能，将Github上面的代码同步备份到国内的Gitee仓库站点。\n2.准备工作 在一次无意间浏览到了yanglbme的贡献的一个 Git Page Action 代码，经过简单的尝试验证，感觉还是挺好用的，便在自己的博客项目中加入相应的Github Action。大部分的步骤在上面那个站点都有介绍，在此就大概小结一下要注意的点。\n2.1 准备SSH密钥 在你的本地使用ssh-keygen命令生成用密钥时，千万不要使用密码，在执行ssh-keygen -t rsa -C \u0026quot;youremail@example.com\u0026quot;命令时，直接不断敲下回车键即可。\n2.2 Gitee相关 建议Github和Gitee使用同一个密钥，他们的设置方法如下：\n1.Github: Settings -\u0026gt; SSH and GPG keys 2.Gitee: 安全设置 -\u0026gt; SSH 公钥 另外还有一个重点就是，一定要关注Gitee的公众号： giteecom，不然后面Github workflow执行就会失败的。\n2.3 Github加密设置 切换到Github，然后在当前项目下「​Settings -\u0026gt; Secrets」中进行添加[Repository secrets]，分别为:\nGITEE_PASSWORD: Gitee登录的密码 GITEE_RSA_PRIVATE_KEY: 前面生成的SSH密钥的私钥\n2.4 Git workflow准备 在你的Github的仓库中，添加个.github/workflows/目录结构，创建个名称为sync-2-gitee.yml文件，填充如下的文件内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 name: Sync on: push: branches: [main, hugo] jobs: sync-2-gitee: runs-on: ubuntu-latest steps: - name: Sync to Gitee uses: wearerequired/git-mirror-action@master env: # 注意在 Settings-\u0026gt;Secrets 配置 GITEE_RSA_PRIVATE_KEY SSH_PRIVATE_KEY: ${{ secrets.GITEE_RSA_PRIVATE_KEY }} with: # 注意替换为你的 GitHub 源仓库地址 source-repo: git@github.com:doocs/advanced-java.git # 注意替换为你的 Gitee 目标仓库地址 destination-repo: git@gitee.com:Doocs/advanced-java.git reload-pages: needs: sync-2-gitee runs-on: ubuntu-latest steps: - name: Build Gitee Pages uses: yanglbme/gitee-pages-action@main with: # 注意替换为你的 Gitee 用户名 gitee-username: yanglbme # 注意在 Settings-\u0026gt;Secrets 配置 GITEE_PASSWORD gitee-password: ${{ secrets.GITEE_PASSWORD }} # 注意替换为你的 Gitee 仓库，仓库名严格区分大小写，请准确填写，否则会出错 gitee-repo: doocs/advanced-java # 要部署的分支，默认是 master，若是其他分支，则需要指定（指定的分支必须存在） branch: main 注： 这里对原版本做了个小修改，分成2个job，体现一个workflow的效果。\n2.4 运行效果 那后续在给Github仓库推送代码时，便会有自动同步代码到Gitee仓库，同时也会重新reload静态页面服务，省去手动干预的流程。\n3.小结 整个方案执行起来还是比较简单的，唯一个可能存在的风险，便是那个密码流程的流程。不过本只是个CI过程，日志中也有脱敏操作，这样也就安全多啦，而且像个人的账户也不会受到特别的关注。\n这是首次体验到Github Action的魅力，后续可以持续关注下，这个功能对于一些开源小项目的自动化测试还是有很大的帮助。\n##　４.参考\n1. gitee-pages-action 2. getting-started-with-github-actions 3. 使用Github Actions实现代码推送Github自动同步到Gitee镜像仓库！ 4. 基于GITHUB ACTION的定时任务，真香！ ","date":"2021-02-25T12:52:25+08:00","updated":"2021-02-25T12:52:25+08:00"},{"permalink":"/tech/git-extensions-push-fail.html","title":"GitExtensions推送Github失败记录","content":"问题现身 555~，今天体验了一把安装最新程序的“快感”！！！\n在使用Git Extensisons推送最新写的文章到Github时，遇到了个SSH KEY认证无效的莫名错误。事情的发生是这样的：今天在首次打开Git Extensions软件时，它非常友好的弹出更新提示窗口，然后就手不自觉的点击了下确认按钮。结果更新好后，在推送文章到Github时就发生了如下面一样神奇的错误阻拦：\n1 2 3 4 5 6 FATAL ERROR: No supported authentication methods available (server sent: publickey) fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 看到这个错误真是一脸的发楞呀，没有修改过任何SSH KEY相关的配置，咋就没有相应的权限进行操作了呢？\n开始脑子里想到的是，难道是本地的SSH KEY被清理了？但检查了文件后发现一切正常，而且使用git push命令操作也是正常的。真是百思不得其解，暂时只能参考报错的提示出来尝试操作修复。\n初步解决办法 根据报错窗口的提示，使用Putty工具把本地的SSH KEY生成Private模式，操作如下：\n然后把这个Private KEY加载到推送的流程中，再次点击推送按钮就会看到操作成功提示信息。\n问题定位 虽然解决完这个推送的问题，但还觉得事情有点奇怪和蹊跷。于是想到了Git Extensions的配置是否有变化，经过一番查找测试后，确认是由于官方当前默认在Windows使用Putty作为客户端，把它调整为OpenSSH方式，问题便不再出现。\n总结 在非必要的情况下，还是不太建议升级软件版本，稳定的环境比用不到的新功能更具价值。\n","date":"2021-02-22T15:42:39+08:00","updated":"2021-02-22T15:42:39+08:00"},{"permalink":"/tech/github-personal-profile-card.html","title":"Github个人信息卡片","content":"Github上总是会有一些新奇的东西出现，这不无意间又发现了个有趣的玩法，可以用它来作为你的个人开发者名信片展现。具体展现效果如下：\n操作起来也不繁琐，类似以前的pages服务那样，只准备个特定的仓库就可以，具体操作如下：\n1. 申请公开仓库 在Github上面申请个与你用户名同名的公开仓库，然后你就会发现收到来自Github的“赞美”提示信息，如下：\n仓库创建好后，会默认准备好一个README.md文件，后续你在这上面写相关的信息即可。\n２. 个人介绍信息 接下来就是你在README.md上面添加个人信息，写法上支持标准的markdown语法编辑，同时也是支持各种表情图标，可以按你个人的意愿添加任意内容。顺便提下，可以使用Github API展现你自己仓库相关的代码提交，质量，打分等信息，效果见开篇的介绍。\n3. 示例 自己简单的编写下，仅供各位看观参考，哈。\n1 2 3 4 5 6 7 8 \u0026lt;img align=\u0026#34;right\u0026#34; src=\u0026#34;https://github-readme-stats.vercel.app/api?username=elkan1788\u0026amp;show_icons=true\u0026amp;icon_color=CE1D2D\u0026amp;text_color=718096\u0026amp;bg_color=ffffff\u0026amp;hide_title=true\u0026#34; /\u0026gt; ### Hello, World! 🎉🎉🎉 - 🏗️ Working at @Kyligence - 🏡 Living at Shanghai - 📙 [《Apache Kylin权威指南（第2版）》](https://item.m.jd.com/product/12566389.html) - 🧐 Try to find it out. 喜欢的话，那就赶紧行动起来吧。\n","date":"2021-01-24T12:21:10+08:00","updated":"2021-01-24T12:21:10+08:00"},{"permalink":"/blog/make-next-theme-pithy.html","title":"优化Hugo Next主题的过程","content":"1. 背景 经过一番考虑还是把个人博客从Hexo引擎迁移到Hugo引擎，博客主题依旧还是沿用NexT。其实本来还担心又要折腾弄个全新的博客主题，后来Github上看到兰陵子分享的 NexT 主题，就直接拿过来引用。但在部署后发现还是有些地方需要改善，在此记录下改造优化的过程。如果正好你也喜欢这个主题，那么欢迎拿去使用，也欢迎交流反馈。\n2. 评论功能 评论功能是博客空间一项较为重要的功能，作为博主与读者交流的重要桥梁，那自然是不可或缺。之前一直使用的是LiveRe，最近发现访问不太稳定，另外还不支持游客评论模式，于是乎考虑使用Valine来做评论支持，不过最后还是把两个都实现了。\n2.1 LiveRe LiveRe (来必力)是韩国最大第三方社交评论系统，自打多说评论下线后一直都是使用它做博客的评论框。个人开发者可以到官网网站注册个City免费版本即可，它的集成也是很简单，直接在博客的JavaScript页面中加载如下的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 {{ if and (.IsPage) (isset .Site.Params \u0026#34;comment\u0026#34;) (eq .Site.Params.Comment \u0026#34;LiveRe\u0026#34;) }} \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; (function(d, s) { var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === \u0026#39;function\u0026#39;) { return; } j = d.createElement(s); j.src = \u0026#39;//cdn-city.livere.com/js/embed.dist.js\u0026#39;; j.async = true; e.parentNode.insertBefore(j, e); })(document, \u0026#39;script\u0026#39;); \u0026lt;/script\u0026gt; {{ end }} 然后在想出现评论框的位置，定义个Div元素，参考如下：\n1 2 3 {{ if and (isset .Site.Params \u0026#34;comment\u0026#34;) (eq .Site.Params.Comment \u0026#34;LiveRe\u0026#34;) }} \u0026lt;div id=\u0026#34;lv-container\u0026#34; data-id=\u0026#34;city\u0026#34; data-uid=\u0026#34;{{ .Site.Params.LiveReId }}\u0026#34;\u0026gt; {{ end }} 最后的效果如下：\n2.2 Valine Valine ,是一款基于LeanCloud的快速、简洁且高效的无后端评论系统。官方的文档非常详细，这里就不再赘述，最后实现的效果如下：\n需要注意一下，由于Valine里面集成了LeanCloud的SDK引用，所以自己再使用LearnCloud功能就不需要再引用相关的SDK，不然后就会发生冲突。\n3. 访问统计 作为博客站长，肯定是会比较关注自己空间的访问状况和相关的数据，比如PU和UV流量，可以借助一些现有平台帮助我们收集。\n3.1 博客空间访问统计 像CNZZ，百度，谷歌(可能被墙)，GrowingIO等（你也可以集成自己熟悉的平台）都可以实现对博客空间访问的统计与相关数据收集，另外这些平台的埋点脚本也是支持一起集成使用。 此次主要是集成了CNZZ, 百度和谷歌，但是这些平台的数据只有站长才有权限查看，所以另外引入不蒜子计数器，把网站PU和UV数据公开展示，效果如下：\n3.2 文章访问统计 除了空间访问数据以外，文章的热度也可以进行统计，之前NexT上也是使用LearnCloud作为后台计数的，此次可借助上面Valine评论插件自带的文章计数器功能。 但同时考虑到要是引用LiveRe评论插件的可能，于是移植原有Hexo上面的相关代码，并更新最新LearnCloud SDK代码，最终实现不管是在引用哪个评论插件，均可以实现文章热度的统计。\n增加此项统计功能时，把原有文章相关的ICON图标进行修复。\n4. SEO优化 为了博客空间能够引流更好，不仅需要写出更多的原创作品，而且也需要一定的站点SEO优化支持。\n4.1 sitemap.xml生成 sitemap文件生成有利于站点收录平台，Hugo生成sitemap文件时要注意一下文件头部的生成，整体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {{ printf \u0026#34;\u0026lt;?xml version=\\\u0026#34;1.0\\\u0026#34; encoding=\\\u0026#34;utf-8\\\u0026#34; standalone=\\\u0026#34;yes\\\u0026#34; ?\u0026gt;\u0026#34; | safeHTML }} \u0026lt;urlset xmlns=\u0026#34;http://www.sitemaps.org/schemas/sitemap/0.9\u0026#34;\u0026gt; {{ range .Data.Pages }} \u0026lt;url\u0026gt; \u0026lt;loc\u0026gt;{{ .Permalink }}\u0026lt;/loc\u0026gt; \u0026lt;lastmod\u0026gt;{{ safeHTML ( .Date.Format \u0026#34;2006-01-02T15:04:05-07:00\u0026#34; ) }}\u0026lt;/lastmod\u0026gt; {{ with .Sitemap.ChangeFreq }} \u0026lt;changefreq\u0026gt;{{ . }}\u0026lt;/changefreq\u0026gt; {{ end }} {{ if ge .Sitemap.Priority 0.0 }} \u0026lt;priority\u0026gt;{{ .Sitemap.Priority }}\u0026lt;/priority\u0026gt; {{ end }} \u0026lt;/url\u0026gt; {{ end }} \u0026lt;/urlset\u0026gt; 最后把这个文件路径提交到对应的收录平台即可，比如下面的：\n百度: 收录入口 谷歌: 收录入口 4.2 bshare分享 另外通过站点自带的分享功能，可以快速将文章分享给不同的读者或者是其他平台。此次采用的是BShare插件，可以快速生成不同平台的分享链接，读者只需要一键点击便可快速分享，效果如下：\n目前关于BShare的HTTPS引用问题已通过Meta标签解决，但其内部有好几个引用是无效的，会在控制台输出一些报错信息，但不会影响整个页面的渲染。此问题已经提交BShare反馈，期待后续有升级修复。\n5. 自我介绍 原有的NexT主题里并没有带自我介绍的页面，参考原来Hexo主题里面的个人介绍页面，增加一些shortcode的代码，实现一个有别于文章的个人信息介绍页面，效果如下：\n6. 本地搜索 本地搜索可通过文章标题或内容关键字快速检索出相关的内容，原理也比较简单，就是把文章标题和内容先抽取到一个XML文本中记录，然后通过JavaScript脚本读取解析。原来主题中的实现是通过sitemap.xml来解析，但这样会与真正的sitemap.xml文件产品冲突，后来改用robots.txt文件进行存储，同时修正相正相关的弹出框等相关样式和图标，最终效果呈现如下：\n7. 公益404 引入腾讯的404公益页面，虽然本站点没有什么流量，但也希望通过这种方式让更多的失散儿童能够早日回家。\n8. 在线聊天 评论功能可以实现与读者的交流，只不过实时不是很强，那么在线交流正好是不错的方式。 DaoVoice 是款不错的在线聊天产品，同时也供了免费使用版本机会，集成也是相当的简单, 只要在Script引用地方加入如下的代码即可：\n1 2 3 4 5 6 7 8 daovoice(\u0026#39;init\u0026#39;, { app_id: \u0026#34;xxxxx\u0026#34; }); daovoice(\u0026#39;update\u0026#39;); \u0026lt;script\u0026gt;(function(i,s,o,g,r,a,m){i[\u0026#34;DaoVoiceObject\u0026#34;]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=\u0026#34;utf-8\u0026#34;;m.parentNode.insertBefore(a,m)})(window,document,\u0026#34;script\u0026#34;,(\u0026#39;https:\u0026#39; == document.location.protocol ? \u0026#39;https:\u0026#39;:\u0026#39;http:\u0026#39;) + \u0026#34;//widget.daovoice.io/widget/xxxxx.js\u0026#34;,\u0026#34;daovoice\u0026#34;)\u0026lt;/script\u0026gt; 最后实现的效果如下：\n9. 图片浏览功能 通过在文章里面直接引用的图片都会是被压缩，或是缩小，无法查看原图的清晰明了。之前NextT自带的图片浏览插件并不好用，所以替换成了ImageViewer来实现对文章内的图片浏览，会有类似幻灯片的效果，如下：\n10. 其它优化 考虑到HTTPS流量计费原因，所以把所有页面中无关的因素全都进行剔除，把各种JavaScript类库和CSS样式用CDN链接进行替换，同时开启压缩模式让网页体积更小。\n另外还增加了标签云、3D访问显示，打赏功能，修复显示问题等小细节的处理，让整个博客站点功能看起来更加完整。\n最后整站的效果就如你现在看的那样，依然保持了NexT主题清爽的界面风格。\n","date":"2020-10-02T10:32:51+00:00","updated":"2020-10-02T10:32:51+00:00"},{"permalink":"/tech/install-cdh-issues-notes.html","title":"安装CDH6过程中几个入坑记录","content":"其实CDH环境部署安装并非是什么难事，正所谓是熟能生巧嘛。但正好不巧的就是太久没有操作过，便是会遇到一些“奇奇怪怪”的问题，而后花费些功夫才能解决好，事后也就顺道把它们记录下来，避免以后再犯。\n1. CDH的元数据库初始化脚本 想必安装过CDH环境的人员都知道，在CM安装完成后，有个脚本名称为：scm_prepare_database.sh，按官方说法是用于初始化CDH元数据库的，所以大家肯定是都会按步就搬的执行。但不知道大家有没试过想它背后是否真的有产生过什么工作？换句话说就是不执行此脚本会有什么问题？\n在过往安装CDH环境的经验中，一般都是会把CM和MySQL数据库安装在同一台机器上（非生产环境）。但这次恰好是在云上环境搭建，所以MySQL直接使用的是云上服务，结果在安装好CM，执行好scm_prepare_database.sh脚本后，启动CM并没有出现预期的成功消息。查看启动日志发现如下错误：\n提示scm.cm_version表不存在，难道是之前执行scm_prepare_database.sh脚本有问题？于是乎又重新执行一次该脚本，确定输出结果是成功的，但CM启动仍然是失败的。当时就真是纳闷了，这个CM的元数据库是在哪一步初始化的呢？\n经过一番尝试和验证后，确认scm_prepare_database.sh脚本并不会初始化CM的元数据库，只是生成db.properties文件，同时会创建一个指定名称的数据库，而真正初始化的操作是在CM首次启动时执行的。\n结论： 安装完成CM并不一定需要执行scm_prepare_database.sh脚本，可以手动创建数据库及配置db.properties文件。\n2. MySQL5.7+版本问题 前面第1步中遇到的问题，其实在后来分析日志时发现，根本原因是CM在执行数据库初始化时，有些DDL语法不支持导致初始化工作并未完成。部分错误日志如下：\n但是CM的提示信息并不友好，并未告知CM元数据库初始化是否完成，导致定位问题有点难度挑战，后来是手动调整DDL语法才得以完成初始化工作。\n这里总结出一个经验，就是正常情况下CM元数据库会生成54张表，可以以此为判断CM初始化工作是否完成。\n另外就是MySQL GTID的问题，导致建表一直失败：\n1 2 错误代码： 1786 Statement violates GTID consistency: CREATE TABLE ... SELECT. 参考： MYSQL Statement violates GTID consistency: CREATE TABLE \u0026hellip; SELECT. 错误代码： 1786 问题 说是要关闭2个参数配置，但是由于使用的云上数据库组件，并未支持系统配置参数修改。最后只好是在本地搭建个MySQL服务，待CM初始化工作完成好，再把表结构和数据同步到云上数据库，问题得以解决。\n3. Hosts配置文件失误 安装Yarn服务组件时一直报出上传Mapreduce的JAR包失败，查看日志信息提示说是无法创建HDFS目录，告知是没有权限执行。于是乎就去临时调整目录权限，但失望的是安装仍然是失败的，还是报出相同的错误。\n再重新分析日志时发觉，貌似是HostName书写有问题，于是对比了下Hosts文件和机器的HostName，结果还真是不一样的。由于当时准备Hadoop节点机器时，使用的是云上同步创建功能，会自动在HostName后面添加对应的序号，只是没想到这个序号会是4位数字，但在Hosts文件里填写时只写了3位。 真可谓是：“差之毫厘，谬以千里”。重新调整Hosts文件配置后，所有安装与启动便成功。\n未完待更新\u0026hellip;\n","date":"2020-09-28T17:02:33+00:00","updated":"2020-09-28T17:02:33+00:00"},{"permalink":"/blog/stop-use-chinese-domain-notice.html","title":"停止使用原中文域名公告","content":"从今天起正式启用lisenhui.cn作为本博客空间唯一域名。\n早上的时候收到了域名服务商的通知短信，提示域名需要续费。才发现不知不觉中，原来工作后注册的第一个域名，已经陪伴自己走过了7个年头啦。当时也就是觉得中文域名比较特别，然后就自己的名字注册了李森辉.cn的域名。\n不过现在还是决定弃用这个中文域名，因为考虑到中文域名其实也还不成熟，在这些年使用的过程就总是遇到各种问题，虽然后来都找到办法绕过去解决，但是终究不太方便。\n因此带来的影响，只能说是后续再慢慢修正吧。（不过本站的流量也是一般啦）\n","date":"2020-09-17T22:42:12+00:00","updated":"2020-09-17T22:42:12+00:00"},{"permalink":"/blog/move-site-2-hugo-plan.html","title":"博客引擎迁移至Hugo计划","content":"近期发现自己的个人博客空间突然之间不能访问，一番查证后发现原来是之前使用的page服务商已经停止提供服务。无奈只好重新迁移回到Github Pages。但这就是又得到重新准备Hexo的相关开发环境，还得辛苦的调试才能成功。而恰好这时在网上有看到过Hugo静态站点引擎的文章，一款基于Go语言开发的极速框架，开发环境部署也简便快速。另外近期原有的域名也快到期了，正好就一起把博客空间整理整理吧。\n访问Hugo官方网站，翻看了下官方的文档，确实是使用比较容易简单。但发浏览已有主题时，并没有找到自己博客空间现正在用的NexT主题，那是不是意味着又得重新来倒腾一回！\n不过还好最后在Github找到有人已经移植了Hexo NexT主题： hugo-theme-next ，所以后续的迁移计划便是基于此展开，整体的思路和计划如下：\n考虑到都是使用业余时间来完成，所以时间线拉的比较长一些，也不知道当中遇到的问题能否顺利解决。先不管这么多啦，凡事都是得先有个Flag嘛，后续努力的把Flag实现就好啦。\n","date":"2020-08-15T10:22:09+00:00","updated":"2020-08-15T10:22:09+00:00"},{"permalink":"/tech/install-linux-chinese-fonts.html","title":"在Linux上安装中文字体","content":"背景 平时一般都很少在Linux服务机器上使用UI桌面，但也还是有机会遇到，这不今天便遇到Linux版本的火狐浏览器显示中文乱码。无论怎么调试浏览器的相关设置，都没有办法凑效，甚是有点郁闷。\n安装字体 在前面调试浏览器设置，在字体设置那栏就发现没有适合中文显示的字体库，那就是意味着安装个字体就可以解决问题啦。从Windows系统中找了个微软雅黑字体库（msyh.ttc,msyhl.ttc,msyhbd.ttc），并上传到Linux服务器的指定目录下： /usr/share/fonts\n注：可以在此目录下创建个文件夹存放微软雅黑的3个字体库文件，方便管理\n然后再通过yum命令安装字体管理工具，如下：\n1 yum install -y fontconfig mkfontscale 最后验证一下字体安装是否成功，命令如下：\n1 2 3 4 5 6 7 [root@quickstart fonts]# fc-list :lang=zh Microsoft YaHei,微软雅黑:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei UI,Microsoft YaHei UI Light:style=Light,Regular Microsoft YaHei UI:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei,微软雅黑,Microsoft YaHei Light,微软雅黑 Light:style=Light,Regular Microsoft YaHei UI:style=Bold,Negreta,tu?né,fed,Fett,?ντονα,Negrita,Lihavoitu,Gras,Félk?vér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kal?n,Krepko,Lodia Microsoft YaHei,微软雅黑:style=Bold,Negreta,tu?né,fed,Fett,?ντονα,Negrita,Lihavoitu,Gras,Félk?vér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kal?n,Krepko,Lodia 如能显示出来微软雅黑字样，那就表示显示成功，再到火狐浏览器的高级设置中把字体选项调整为微软雅黑即可，效果如下：\n总结 遇到乱码问题，除了查找lang设置之外，还需要关心一下字体库。\n换个位置思考！！！\n","date":"2019-10-21T19:04:51+00:00","updated":"2019-10-21T19:04:51+00:00"},{"permalink":"/tech/unable-create-tmp-file-in-hdfs-nodes.html","title":"不能在HDFS Data节点上创建临时文件","content":"在新创建的Hadoop边缘节点上，尝试通过Hive CLI模式进行数据插入操作，结果没有出现意想中的成功信息，反倒是捕获到如下的异常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FAILED: SemanticException [Error 10293]: Unable to create temp file for insert values File /tmp/hive/kylin/9c84de0a-fca2-4d3c-8f72-47436a4adb83/_tmp_space.db/Values__Tmp__Table__1/data_file could only be replicated to 0 nodes instead of minReplication (=1). There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1720) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3440) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:686) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:217) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:506) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2226) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2222) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2220) ERROR: Current user has no permission to create Hive table in working directory: /user/kylin 从异常提示信息上来面，初步判定为对/user/kylin目录没有权限（有点奇怪明明就是kylin用户为何会没有权限操作），简单直接的把其权限降低到777后，错误仍然是存在。接着尝试切换到Hive的Beeline连接方式，重复上原来的插入语句，操作成功了！那上面的错误是何原因引起的呢？\n借助强大的Google搜索查找了一番，结果各说纷纭：有说是HDFS存储空间不足，有的说是集群节点的防火墙未关闭，有的说是DataNode服务异常 等等。网上的方案都尝试过了，问题仍然是没有解决。由前的防火墙联想到会不会是IP引起的问题 。\n因为集群是本地虚拟机搭建的，而恰巧又配置了双网卡，而边缘节点连接的是集静态IP地址。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 eth0 Link encap:Ethernet HWaddr 08:00:27:B2:38:58 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:797 errors:0 dropped:0 overruns:0 frame:0 TX packets:944 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:98791 (96.4 KiB) TX bytes:84770 (82.7 KiB) eth1 Link encap:Ethernet HWaddr 08:00:27:B5:9D:6A inet addr:192.168.56.104 Bcast:192.168.56.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:3523935 errors:0 dropped:0 overruns:0 frame:0 TX packets:443589 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:5073146719 (4.7 GiB) TX bytes:163351146 (155.7 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:342031 errors:0 dropped:0 overruns:0 frame:0 TX packets:342031 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:405110832 (386.3 MiB) TX bytes:405110832 (386.3 MiB) 接着检查了下/etc/hosts的文件配置，结果真是默认设置10.0.2.15地址为集群IP，将其修改为静态IP地址并重启Hadoop集群的所有服务，再次通过Hive CLI模式连接Hive，执行之前的插入语句一切正常。\n总结 配置Hadoop集群要特别注意IP地址的分配，建议还是通过HostName形式来避免IP地址问题。另外当已有案例不能协助解决问题时，可仔细检查环境的配置情况。\n","date":"2019-03-21T19:04:51+00:00","updated":"2019-03-21T19:04:51+00:00"},{"permalink":"/about.html","title":"关于我","content":" 希望是无所谓有，无所谓无的，这正如地上的路。\n其实地上本没有路，走的人多了，也便成了路。\n鲁迅\n绰号\n凡梦星尘(elkan1788)\n留言箱： elkan1788@139.com 历史正文\nCSDN Blog ITEye Blog1 ITEye Blog2 GitHub Page 啰嗦几句\n奔波于大都市中求生的一枚攻城狮/码农，完美是对代码的基本要求。 (曾经)\n文静的外表下藏有颗\u0026quot;叛逆\u0026ldquo;的心，不怕世俗之见敢于突破束缚，喜欢去追求真正的自由路。\n心中怀揣着的梦想，希望有一天能够把它实现。\n感谢支持！\n","date":"2019-02-05T20:12:52+08:00","updated":"2019-02-05T20:12:52+08:00"},{"permalink":"/tech/win10-quick-operations.html","title":"Win10常用的快捷操作方式","content":"常言道“工欲善其事，必先利其器。”\n不过从Mac再过渡回来到Windows确实是有诸多的不习惯，但仍是要学会克服，无它，工作是生存的根本技能。于是从网络上扒了下关于Win10快捷键的分布，还是挺有趣的。记录也下部分常用快捷键，如下：\n操作手势 1.双指单击触摸板，模拟鼠标右键，即弹出菜单\n2.三指单击触摸板，弹出搜索框\n3.四指单击触摸板，弹出操作中心，即模拟Win+A\n4.三指同时上划，弹出多任务界面，即模拟Win+Tab\n5.三指同时下划，将所有窗口最小化，即模拟显示桌面\n6.三指同时向左/右划，快速切换任务，即模拟Alt+Tab\n7.双指同时向左/右划，切换上一个/下一个项目，用于浏览图片或“开始”等横向排版程序的滚动\n快捷键 1.创建新的虚拟桌面：Win + Ctrl + D\n2.关闭当前虚拟桌面：Win + Ctrl + F4\n4.多桌面切换：Win + Ctrl + 左/右\n5.快速打开搜索：Win + Q\n6.快速打开Win10设置栏: Win + I\n7.临时查看桌面： Win+，\n8.最小化所有窗口：Win+M\n9.打开位于任务栏指定位置程序的新实例：Win+Shift+数字键\n10.最大化窗口(传统桌面)：Win + 向上键\n11.最小化窗口(传统桌面)：Win + 向下键\n12.将窗口最大化到屏幕的左侧(传统桌面)：·Win + 向左键\n13.将窗口最大化到屏幕的右侧(传统桌面)：Win + 向右键\n14.前进：Alt + 向右键\n15.后退：Alt + 向左键\n16.截图（保存到内存）：Win + Shift + S 以上快捷操作都是亲自验证后可用，仅供参考，后续的有新发现会持续更新，欢迎关注，谢谢。\n","date":"2018-08-08T12:54:53+00:00","updated":"2018-08-08T12:54:53+00:00"},{"permalink":"/tech/axure-lightbox-shade.html","title":"Axure教程：动态面板内容超出界线显示","content":"问题 随着用户需求的不断更新，产品原型的设计也在不断迭代升级，那么是必会让整体的设计复杂增加，各中组件相互影响的因素就更多。这不现在就遇到在动态面板上显示一个隐藏的元件时，结果下拉的组件显示不完全了，真的好是郁闷，如下图所示：\n从问题的表象可以分析出主要的关键点如下：\n隐藏的元件图层位置，并不是最顶层，导致显示位置不对 动态面板的大小，限制了隐藏元件显示的区域 解决方案 尝试过多次解决方案后，找到了个最优的办法，只要2个步骤即可，具体操作如下：\n顶层设置 定位到显示隐藏元件的点击事件，在显示的时候同时将其至为顶层，如下图所示：\n面板自适应 定位到隐藏元件所在的面板，在面板的属性上，将自动调整为内容尺寸打勾，如下图所示：\n效果预览 操作完以上2步后，即可查看到如下的效果：\nOK，至此已经实现我们想要解决的问题，遇过问题可以多点点Axure的各种设置，会有预想不到的效果，哈~。\n","date":"2018-03-12T10:11:53+00:00","updated":"2018-03-12T10:11:53+00:00"},{"permalink":"/tech/axure-datalist-table.html","title":"Axure教程：实现表格数据展示","content":"通常在系统管理后台中，使用列表（表格）形式展示数据是最为常见的方式。而在使用Axure设计产品原型时想实现这个数据列表却不太容易，或许常见的做法就是使用矩形拼凑起来，还有就是直接使用表格控件来布局。但是这都不太方便，首先就是布局麻烦，其次就是数据修改比较麻烦。接下来给大家介绍下如何使用表格+中继器控件实现数据列表。\n其实在实际的原型设计过程中，都会在表格+中继器的基础上增加个矩形框一起使用。这也是迫于无奈，在Axure上面表格无法实现单元格的合并。因此通常表格只能把表格做为数据列表中的表头，然后再利用中继器的数据填充功能来展示数据部分。当遇到一些需要合并的单元格时，矩形框便发挥了它的强大作用。下面就着重来讲下中继器如何来显示数据：\n创建中继器，双击进入中继器删除里面的初始内容\n创建与表格相同列数的矩形框，高度可自定义，宽度保持与表格对应列相同，给每个元件起个名字（配备自己喜欢的风格，后续数据就会复制当前的样式）\n选择中继器，在属性(Properties)中找到Repeater，创建与表格列数相同的列并起名（建议保持与上一步的名称相同），最后填充示例数据 注：可以直接在Excel中编辑数据，然后直接拷贝到中继器里面\n选择中继器，添加个Case用于绑定数据与矩形框的关系 设置隔行换色效果，选择中继器，在Style中找到Item Background勾选Alternating然后配对奇偶行的前景色 注：如果在中继器里面使用矩形框，一定要把其背景色设置为无，不然隔行换色就不起效果，这个教训惨痛的。\n这些便是关于在Axure中实现表格数据实现，如遇到一些复杂的要求，可以以此为参考，自由的发挥想象。\n整体的效果如下：\nPS:\n示例源文件下载： 数据表格.rp ","date":"2017-12-29T18:45:03+00:00","updated":"2017-12-29T18:45:03+00:00"},{"permalink":"/tech/axure-lightbox-shade.html","title":"Axure教程：实现动态的遮罩层","content":"今天在做产品原型设计时，遇到了个关于动态显现遮罩层的难点。\u0026ldquo;无奈\u0026quot;为追求高保真的效果，还是花了点心思做个原型实现。待做好回过头来看看的话，其实这个效果的难度也不大，只是看个人意愿是否想做而已。Axure本身就提供了模板的功能，也就是说只要实现一次但可以一劳永逸。下面就一起来看看这个遮罩层实现过程和效果吧。\n做前端开发的同学都知道，在HTML实现一个遮罩层，只需要添加个浮动的DIV即可轻松实现。那么在Axure中如何去实现它呢？\n如上图所示，可以将这个遮罩层的实现分为如下2部分：\n主体内容，即遮罩层要盖住的部分 遮罩层组件，即遮罩层+其它装饰部分（在Demo中只是增加了个Loading的动画图片来区分） 所以遮罩层的实现思路就清晰啦步骤如下：\n准备一个与你所想要遮盖内容大小相同的矩形框，注意要减去边框的大小，示例：主体内容大小为600x400，边框宽度为1px，那么遮罩层的大小为598*398且是无边框的\n设置遮罩层的填充色，还有相对的透明度\n加强遮罩层显示的动画效果（Axure上所支持的效果并不多，如不能够满足，可以采用文字描述阐明效果要求）\n接着用3个按钮来做不同效果的展示：\n打开遮罩层 关闭遮罩层 自动演示 那么现在来看看最终的实现效果如下，请看下面的大屏幕 在线查看 ：\n如果想要做全屏的遮罩层就更加的简单啦，只在要显示组件上增加个灯箱的效果即可。\nPS:\n示例源文件下载： 遮罩层效果.rp ","date":"2017-12-15T20:22:43+00:00","updated":"2017-12-15T20:22:43+00:00"},{"permalink":"/tech/nifi-windows-local-cluster.html","title":"Apache Nifi在Windows环境下搭建伪群集及证书登录","content":"前些时间做了关于Apache Nifi分布式集群的搭建分享，但很多时候要搭建分布式集群机器资源是个问题，而现在的单机的配置还是相当不错的，故现在就做个关于Windows上搭建个伪分布式集群的分享，同时通过另外一种方式实现Apache Nifi的授权认证。\n系统环境及软件版本 Windows8.1\nJDK1.8.0_131\nNifi-1.4.0\nNifi安装目录 WEB端口 xxx\\nifi-ncm 9443 xxx\\nifi-cluster01 9444 xxx\\nifi-cluster02 9445 (其它版本可参考此篇文章) 另在测试中发个问题，使用Apache Nifi内嵌的Zookeeper搭建伪集群里启动总是提示端口占用的问题，故放弃只采用了单结点启动。\nNifi的服务证书 生成本地Nifi服务证书 解压nifi-toolkit-1.4.0-bin.tar.gz文件后，通过CMD进入bin目录，执行以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 D:\\DevelopTools\\nifi-toolkit-1.4.0\\bin\u0026gt;tls-toolkit.bat standalone -n \u0026#34;localhost( 3)\u0026#34; -C \u0026#34;CN=Admin, OU=ApacheNIFI\u0026#34; -o \u0026#34;..\\target\u0026#34; 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandaloneCommandLine: No nifiPropertiesFile specified, using embedded one. 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: Running standalone certificate generation with output directory ..\\ target ****************************************************************************** 2017/10/26 18:21:34 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: Successfully generated client certificate ..\\target\\CN=Admin_OU=Apa cheNIFI.p12 2017/10/26 18:21:34 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: tls-toolkit standalone completed successfully 生成后的目录结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Folder PATH listing for volume senhui.li Volume serial number is 000000F0 FA46:A0EB D:. │ CN=Admin_OU=ApacheNIFI.p12 │ CN=Admin_OU=ApacheNIFI.password │ nifi-cert.pem │ nifi-key.key │ ├─localhost │ keystore.jks │ nifi.properties │ truststore.jks │ ├─localhost_2 │ keystore.jks │ nifi.properties │ truststore.jks │ └─localhost_3 keystore.jks nifi.properties truststore.jks 特意注意： -C \u0026ldquo;CN=Admin, OU=ApacheNIFI\u0026rdquo; 中间的空格必须保留\n拷贝Nifi服务证书 将localhost目录下的文件拷贝到nifi-ncm目录下替换所有的文件 将localhost_2目录下的文件拷贝到nifi-cluster01目录下替换所有的文件 将localhost_3目录下的文件拷贝到nifi-cluster02目录下替换所有的文件 将CN=Admin_OU=ApacheNIFI.p12和CN=Admin_OU=ApacheNIFI.password拷贝到桌面备用，后续登录需要使用 配置单点Zookeeper相关 创建目录及id 进入nifi-ncm的目录，创建woker目录，并把server id写到文件中，命令如下：\n1 2 D:\\DevelopTools\\nifi-ncm\u0026gt;mkdir -p state\\zookeeper D:\\DevelopTools\\nifi-ncm\u0026gt;echo -n \u0026#39;1\u0026#39; \u0026gt; state/zookeeper/myid 更新ZK配置 进入nifi-ncm的conf目录，打开zookeeper.properties文件，内容更新参考如下：\nclientPort=2181 initLimit=10 autopurge.purgeInterval=24 syncLimit=5 tickTime=2000 dataDir=./state/zookeeper autopurge.snapRetainCount=30 # 只需要配置端口服务 server.1=localhost:2181 更新Nifi配置 进入nifi-ncm的conf目录，打开nifi.properties文件，更新如下的配置属性：\nnifi.state.management.embedded.zookeeper.start=true # zookeeper properties, used for cluster management # # 另外两个节点，只要编辑此字段即可 nifi.zookeeper.connect.string=localhost:2181 更新State配置 进入nifi-ncm的conf目录，打开state-management.xml文件，更新zookeeper配置，如下：\n1 2 3 4 5 6 7 8 9 \u0026lt;cluster-provider\u0026gt; \u0026lt;id\u0026gt;zk-provider\u0026lt;/id\u0026gt; \u0026lt;class\u0026gt;org.apache.nifi.controller.state.providers.zookeeper.ZooKeeperStateProvider\u0026lt;/class\u0026gt; \u0026lt;property name=\u0026#34;Connect String\u0026#34;\u0026gt;localhost:2181\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Root Node\u0026#34;\u0026gt;/nifi\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Session Timeout\u0026#34;\u0026gt;10 seconds\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Access Control\u0026#34;\u0026gt;Open\u0026lt;/property\u0026gt; \u0026lt;/cluster-provider\u0026gt; 然后把此文件拷贝到nifi-cluster01和nifi-cluster02相同的目录下\n配置Nifi Admin 添加Admin用户 进入nifi-ncm的conf目录，打开authorizers.xml文件，找到file-provider添加如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;authorizer\u0026gt; \u0026lt;identifier\u0026gt;file-provider\u0026lt;/identifier\u0026gt; \u0026lt;class\u0026gt;org.apache.nifi.authorization.FileAuthorizer\u0026lt;/class\u0026gt; \u0026lt;property name=\u0026#34;Authorizations File\u0026#34;\u0026gt;./conf/authorizations.xml\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Users File\u0026#34;\u0026gt;./conf/users.xml\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Initial Admin Identity\u0026#34;\u0026gt;CN=Admin, OU=ApacheNifi\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Legacy Authorized Users File\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Node Identity 1\u0026#34;\u0026gt;CN=localhost, OU=NIFI\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Node Identity 2\u0026#34;\u0026gt;CN=localhost_2, OU=NIFI\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Node Identity 3\u0026#34;\u0026gt;CN=localhost_3, OU=NIFI\u0026lt;/property\u0026gt; \u0026lt;/authorizer\u0026gt; 然后把此文件同时拷贝到别外两个节点目录。\n注： 在Node Identity x中的OU要写成NIFI，尝试过用别的名称好像不成功，具体的原因未知，感兴趣的可以自行探究一二。\n安装证书 打开谷歌浏览器，在设置中找到安全选项中找到管理证书，点击Import开始导入上面生成的证书：CN=Admin_OU=ApacheNIFI.p12，密码在后缀名为.password的文件中，如下图所示： 启动Nifi服务 进入到Nifi安装目录，然后在bin目录中找到run-nifi.bat文件并双击运行，注意启动的顺序： nifi-ncm\u0026ndash;\u0026gt;nifi-cluster01/2，等待片刻后（可能会有点久，需要一个选举的过程）打开浏览器输入\u0026quot;https://localhost:9443/nifi\u0026quot;，选择刚刚导入的证书，如看到下面的画面表示启动成功： 用户策略 刚登录NIFI页面时，你会发现图标都是灰色的，需要赋予相应的权限才可以开始编辑权限才可以开始编辑。点击页面左侧面板上的钥匙图标，会弹出访问策略的窗口，如下图所示：\n在此会看到用户列表为空，那么就要给相应的行为添加用户，点击Create链接即可开始添加，如下图所示： 待所有的权限添加完成后，便可看到NIFI页面的按钮已经点亮，可以开始创建流程。\n示例演示 模板上传 下载 DEMO 压缩包，解压出来有个WordCountDemo.xml文件。然后打开浏览器输入NIFI访问地址： https://localhost:9443/nifi/，点击左侧面板中的上传按钮上传模板，如下图所示： 创建流程 拖动NIFI页面顶部的模板按钮到画板空白处，点击ADD按钮即可，然后双击打开WordCountDemo组找到PutFile组件，修改目录地址为你机器的实际可访问路径，如下图所示：\n启动流程 点击NIFI页面左下角的NiFi Flow链接返回到主面板，点击WordCountDemo组，然后点击左侧面板中的开始按钮启动流程，如下图所示：\n如无异常那么此时你可在目录下找到名为telltale_heart_wordcount的文件，打开便可看到如下图的统计内容：\n至此在本地搭建NIFI伪集群就完成了，有问题欢迎留言。\n","date":"2017-10-26T17:50:52+00:00","updated":"2017-10-26T17:50:52+00:00"},{"permalink":"/tech/ninfi-cluster-deploy-with-kerberos.html","title":"Apache Nifi集群搭建及用kerberos实现用户认证","content":"最近这段时间在接触数据流式处理方面的事宜，用到了Apache NIFI现把安装配置中学习的一些经验分享下。此篇文章主要是针对集群及用户权限方面，关于 Apache NIFI 的介绍就不做过多的说明，直接引用官方的首页的说明如下图所示：\nApahce NIFI的单机运行是相当的简单，易用，完全就是傻瓜式的。下载解压，进行bin目录执行nifi.sh start 打开浏览器输入http://127.0.0.1:8080/nifi即可看到一个简洁漂亮的WEB UI。那么接下来我们要配置的是它的集群模式，官方说明NIFI采用的是0主节点模式，集群中的每个节点在数据集上执行相同的任务，但是每个节点都在不同的数据集上运行（详细的说明请查看 官方文档 ），并且内置了Zookeeper服务，如下图所示：\n系统环境及软件版本 CentOS7\nJDK1.8.0_91\nNifi-1.4.0\nKerberos5\n(其它版本可参考此篇文章)\nHostName IP Services centos7-master 192.168.56.100 Kerberos5 Server, Nifi Cluster Manager centos7-cluster01 192.168.56.101 Kerberos5 Client, Nifi Cluster 搭建Kerberos5服务 安装KDC服务及配置 进入到Master机器，执行以下命令安装KDC服务：\n1 yum -y install krb5-server krb5-libs krb5-workstation 注：测试中发现krb5-auth-dialo组件是不可用的，也无需安装\n修改KDC默认配置 进入/etc目录找到/etc/krb5.conf文件打开并修改，参考如下：\n# Configuration snippets may be placed in this directory as well includedir /etc/krb5.conf.d/ [logging] default = FILE:/var/log/krb5libs.log kdc = FILE:/var/log/krb5kdc.log admin_server = FILE:/var/log/kadmind.log [libdefaults] dns_lookup_realm = false ticket_lifetime = 24h renew_lifetime = 7d forwardable = true rdns = false # 这个注释需要开启，并填写默认的域 default_realm = CENTOS7-MASTER.COM default_ccache_name = KEYRING:persistent:%{uid} [realms] # 把此处的EXAMPLE.COM修改成自己的域 CENTOS7-MASTER.COM = { kdc = centos7-master admin_server = centos7-master # 添加默认的域 default_domain = CENTOS7-MASTER.COM } [domain_realm] # 把此处的EXAMPLE.COM修改成自己的域名 .centos7-master.com = CENTOS7-MASTER.COM centos7-master.com = CENTOS7-MASTER.COM 修改KRB5KDC配置文件 进入/etc目录找到/var/kerberos/krb5kdc/kdc.conf文件打开，参考如下修改：\n[kdcdefaults] kdc_ports = 88 kdc_tcp_ports = 88 [realms] # 修改此处的EXAMPLE.COM域名 CENTOS7-MASTER.COM = { #master_key_type = aes256-cts acl_file = /var/kerberos/krb5kdc/kadm5.acl dict_file = /usr/share/dict/words admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal kdc_ports = 88 kadmind_port = 749 } 初始化数据库 1 2 3 4 5 6 7 8 [root@centos7-master ~]# kdb5_util create -s Loading random data Initializing database \u0026#39;/var/kerberos/principal\u0026#39; for realm \u0026#39;CENTOS7-MASTER.COM\u0026#39;, master key name \u0026#39;K/M@CENTOS7-MASTER.COM\u0026#39; You will be prompted for the database Master Password. It is important that you NOT FORGET this password. Enter KDC database master key: Re-enter KDC database master key to verify: 修改数据库权限 找到/var/kerberos/krb5kdc/kadm5.acl配置文件，给数据库管理员添加ACL权限，*代表全部权限，操作如下：\n1 2 [root@centos7-master ~]# vi /var/kerberos/krb5kdc/kadm5.acl */admin@CENTOS7-MASTER.COM * 启动KDC服务 1 2 service krb5kdc start service kadmin start 创建数据库管理员 参考如下命令创建管理员用户，保存好创建时设置的密码(如果忘记后期可以使用cpw命令更新)，并导出keytab\n1 2 3 4 5 6 7 8 9 10 [root@centos7-master ~]# kadmin.local -q \u0026#34;addprinc root/admin\u0026#34; Authenticating as principal root/admin@CENTOS7-MASTER.COM with password. WARNING: no policy specified for root/admin@CENTOS7-MASTER.COM; defaulting to no policy Enter password for principal \u0026#34;root/admin@CENTOS7-MASTER.COM\u0026#34;: Re-enter password for principal \u0026#34;root/admin@CENTOS7-MASTER.COM\u0026#34;: Principal \u0026#34;root/admin@CENTOS7-MASTER.COM\u0026#34; created. [root@centos7-master ~]# kadmin.local kadmin: ktadd -k /data/root.keytab root/admin kadmin: q [root@centos7-master ~]# kinit root/admin 安装KDC Client服务 进入从Cluster机器，执行如下命令安装KDC Cliente服务：\n1 yum -y install krb5-libs krb5-workstation 更新配置并测试 拷贝主节点的krb5.conf和root.keytab到从节点服务，参考如下：\n1 2 3 4 5 6 [root@centos7-cluster01 ~]# scp root@centos7-master:/etc/krb5.conf /etc/krb5.conf [root@centos7-cluster01 ~]# scp root@centos7-master:/data/root.keytab /data/root.keytab [root@centos7-cluster01 ~]# kadmin -p root/admin Authenticating as principal root/admin with password. Password for root/admin@CENTOS7-MASTER.COM: kadmin: 拷贝keytab文件 拷贝root.keytab到/data/root.keytab目录，注意此处指的是所有机器\n创建Nifi服务证书 创建证书 解压nifi-toolkit-1.4.0-bin.tar.gz文件后进入bin目录，执行以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@centos7-master ~]# ./tls-toolkit.sh standalone -n \u0026#39;centos7-master, centos7-cluster01\u0026#39; -C \u0026#39;CN=admin, OU=ApacheNIFI\u0026#39; -o \u0026#39;./target\u0026#39; -f \u0026#39;/usr/local/bin/nifi-ncm/conf/nifi.properties\u0026#39; [root@centos7-master target]# tree . ├── centos7-cluster01 │ ├── keystore.jks │ ├── nifi.properties │ └── truststore.jks ├── centos7-master │ ├── keystore.jks │ ├── nifi.properties │ └── truststore.jks ├── CN=admin_OU=ApacheNIFI.p12 ├── CN=admin_OU=ApacheNIFI.password ├── nifi-cert.pem └── nifi-key.key -n 表示机器的hostname -C 生成浏览器证书（注意： CN=admin, 后面的空格一定要保留） -o 输出的目录 -f Nifi的配置文件位置 拷贝证书 拷贝生成好证书到主从节点服务器下NIFI安装目录中的conf文件夹，如下：\n1 2 [root@centos7-master target]# scp centos7-cluster01/* centos7-cluster01:/usr/local/bin/nifi-cluster01/conf [root@centos7-master target]# cp target/centos7-master/* /usr/local/bin/nifi-ncm/conf/ 配置Zookeeper服务 注意：所有的主从节点都需要操作\n创建id文件 进入到NIFI安装目录下，并创建state/zookeeper目录和myid文件，然后把对应的ID写入到文件中，操作如下：\n1 2 [root@centos7-master nifi-ncm]# mkdir -p state/zookeeper [root@centos7-master nifi-ncm]# echo -n \u0026#39;1\u0026#39; \u0026gt; state/zookeeper/myid 注意： 从节点上创建的myid为2，如：echo -n '2' \u0026gt; state/zookeeper/myid\n修改配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 clientPort=2181 initLimit=10 autopurge.purgeInterval=24 syncLimit=5 tickTime=2000 dataDir=./state/zookeeper autopurge.snapRetainCount=30 # # Specifies the servers that are part of this zookeeper ensemble. For # every NiFi instance running an embedded zookeeper, there needs to be # a server entry below. For instance: # # server.1=nifi-node1-hostname:2888:3888 # server.2=nifi-node2-hostname:2888:3888 # server.3=nifi-node3-hostname:2888:3888 # # The index of the server corresponds to the myid file that gets created # in the dataDir of each node running an embedded zookeeper. See the # administration guide for more details. # # 注意修改成你对应的服务器地址 server.1=centos7-master:2888:3888 server.2=centos7-cluster01:2888:3888 更新状态配置 进入到Nifif安装目录下修改conf/state-management.xml配置，在zk-provider节点下添加连接字符串\n1 2 3 4 5 6 7 8 \u0026lt;cluster-provider\u0026gt; \u0026lt;id\u0026gt;zk-provider\u0026lt;/id\u0026gt; \u0026lt;class\u0026gt;org.apache.nifi.controller.state.providers.zookeeper.ZooKeeperStateProvider\u0026lt;/class\u0026gt; \u0026lt;property name=\u0026#34;Connect String\u0026#34;\u0026gt;centos7-master:2181,centos7-cluster01:2181\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Root Node\u0026#34;\u0026gt;/nifi\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Session Timeout\u0026#34;\u0026gt;10 seconds\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Access Control\u0026#34;\u0026gt;Open\u0026lt;/property\u0026gt; \u0026lt;/cluster-provider\u0026gt; 更新NIFI配置 进入到Nifif安装目录下修改conf/nifi.properties文件，把内置的zookeeper启动和cluster设置成true，如下：\nnifi.state.management.embedded.zookeeper.start=true nifi.cluster.is.node=true # zookeeper properties, used for cluster management # nifi.zookeeper.connect.string=centos7-master:2181,centos7-cluster01:2181 nifi.zookeeper.connect.timeout=3 secs nifi.zookeeper.session.timeout=3 secs nifi.zookeeper.root.node=/nifi 配置Nifi Admin初始化 更新NIFI配置 进入到Nifif安装目录修改conf/nifi.properties文件，把kerberos5的登录适配加上，如下：\nnifi.kerberos.krb5.file=/etc/krb5.conf # kerberos service principal # nifi.kerberos.service.principal=root/admin@CENTOS7-MASTER.COM nifi.kerberos.service.keytab.location=/data/root.keytab 更新用户配置 进入到Nifif安装目录中的conf目录，添加authorizer到authorizers.xml，打开file-provider节点注释并添加如下内容：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;authorizer\u0026gt; \u0026lt;identifier\u0026gt;file-provider\u0026lt;/identifier\u0026gt; \u0026lt;class\u0026gt;org.apache.nifi.authorization.FileAuthorizer\u0026lt;/class\u0026gt; \u0026lt;property name=\u0026#34;Authorizations File\u0026#34;\u0026gt;./conf/authorizations.xml\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Users File\u0026#34;\u0026gt;./conf/users.xml\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Initial Admin Identity\u0026#34;\u0026gt;root/admin@CENTOS7-MASTER.COM\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Legacy Authorized Users File\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Node Identity 1\u0026#34;\u0026gt;CN=centos7-master, OU=NIFI\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Node Identity 2\u0026#34;\u0026gt;CN=centos7-cluster01, OU=NIFI\u0026lt;/property\u0026gt; \u0026lt;/authorizer\u0026gt; 更新登录配置 进入到Nifif安装目录中的conf目录，修改login-identity-providers.xml 文件，打开kerberos-provider节点注释：\n1 2 3 4 5 6 7 \u0026lt;provider\u0026gt; \u0026lt;identifier\u0026gt;kerberos-provider\u0026lt;/identifier\u0026gt; \u0026lt;class\u0026gt;org.apache.nifi.kerberos.KerberosProvider\u0026lt;/class\u0026gt; \u0026lt;property name=\u0026#34;Default Realm\u0026#34;\u0026gt;CENTOS7-MASTER.COM\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Kerberos Config File\u0026#34;\u0026gt;/etc/krb5.conf\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Authentication Expiration\u0026#34;\u0026gt;12 hours\u0026lt;/property\u0026gt; \u0026lt;/provider\u0026gt; 启动NIFI服务 先启动主节点的NIFI，而后启动从节点的NIFI，执行命令./bin/nifi.sh start， 然后打开浏览器输入https://centos7-master:9443/nifi/便会跳转到登录页面，输入在第1步骤创建的用户与密码，即可登录成功。界面显示如下：\n如上面两图显示，在界面的左上角可以清楚的看到当前节点数为2，用户为**root/admin@CENTOS7-MASTER.COM**，其中centos7-master是协调器，centos7-cluster01是主要节点，主菜单中也增加有了Cluster，User和Policies选项。\n至此Apache NIFI的集群服务与用户认证便完成好啦，后面便可开展下一步的工作。\n遇到的坑：\n首次登录时提示用户名或密码无效，可通过kadmin更新用户的密码 登录成功后提示用户没有对应的策略，重启NIFI服务即可 引用参考\nnifi-security-user-authentication-with-kerberos.html Nifi-搭建 kerberos认证原理\u0026mdash;讲的非常细致，易懂 Kerberos 基本安装与配置 收到的赏金 感谢各位的慷慨解囊!\n序号 昵称 来源 金额(元) 留言 1 林俗人 微信 2 感谢博主，感谢分享! ","date":"2017-10-22T11:42:29+00:00","updated":"2017-10-22T11:42:29+00:00"},{"permalink":"/tech/ambari-monitor-status-issues.html","title":"关于Ambari中服务运行正常UI却显示服务停止的问题","content":"很多时候环境的维护的确是件头痛的事件，这不本来在Ambari的Dashboard页面显示正常服务的监控，实然间出现了个奇怪的现象： 在机器查询服务的运行进程是正常的，可偏偏Ambari的UI界面却显示状为停止，但端口检查又显示正常的。如下图：\n本也可以放任不管的(反正服务运行正常就好)，但无奈强迫症的\u0026quot;毛病\u0026quot;又犯了，非得把它消灭掉心里才舒服。尝试了几次都没能成功，后来回想下好像同事有手动启动的某些组件，难道是这个原因。使用ps检查了这些组件的进程用户，发现确实如此，强制杀死这些组件，然后使用Ambari UI重启它们，可最终的结果还是没变。\n真是挺郁闷的，此时也只好借助google啦，然后找到一篇类似问题的文章，里面提及到了运行时的xx.pid权限问题，真是一语点醒梦中人，赶紧的查看下这些组件的pid文件权限，果然如此，因为之前的启动是用超管用户，而实际上这些组件有对应的用户维护。删除这些xxx.pid文件，再在Ambari UI上重启这些服务，一切恢复正常，漂亮的绿色界面又回来啦。\n参考引用：\nservice-is-running-but-ambari-shows-serice-is-stop ","date":"2017-10-18T16:13:36+00:00","updated":"2017-10-18T16:13:36+00:00"},{"permalink":"/tech/hive2-jdbc-connector-issues.html","title":"HiveServer2因JDBC版本引起的问题","content":"之前一直都是用HDP来搭建和管理Hadoop环境，在安装完成调试时也未曾出现过棘手的问题，但这次在Centos6x系统上布署好后却是遇到奇怪的问题：\n表面上看来Hive服务是正常运行的，进程运行正常，页面UI也正常，日志也没错误输出。简单的建表的语句都能执行，可偏偏在导入本地/HDFS数据时，便就抛出异常啦。错误的堆栈信息如下：\n1 com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;OPTION SQL_SELECT_LIMIT=DEFAULT\u0026#39; at line 1 另外一个问题在使用Ambari提供的HiveView UI进行HDFS数据导入提示文件不存在，错误信息如下：\n1 org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path \u0026#39;\u0026#39;/tmp/xxx/xxxxx.csv\u0026#39;\u0026#39;: No files matching path hdfs:/... 简单描述下所使用的环境：\nHive - 1.2.1000\nMySQL - 5.6.17\nMySQL JDBC - 5.1.17\n问题一\n从报错的信息可以明显知道是语法错误的问题，不过麻烦的是它没有打印出有问题的SQL语句，通过google找到了遇到相同问题文章，其中指出这是MySQL JDBC驱动5.1.17版本以下的BUG，只需要更新JDBC驱动的版本即可。那么似乎问题变得简单啦，找到新的JDBC驱动文件，执行如下操作:\n拷贝驱动文件 1 2 3 4 5 6 # 拷贝到Amabri Server的资源目录 mv mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar ln -s -f /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java.jar # 拷贝到share目录 mv mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java-5.1.44.jar ln -s -f /usr/share/java/mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java.jar 重新设置Ambari驱动引用 1 ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 删除Ambari Agent上面的旧的驱动，并重启 1 2 3 4 # 注意做好备份和删除的路径 rm -rf /var/lib/ambari-agent/tmp/mysql-* # 重启服务 ambari-agent restart 在Ambari UI上重启Hive组件服务 理论上有这些操作便可解决问题了，可在运行数据导入后仍是出现同样的问题，说明上面的文件更新操作没有成功，切换到Hive Master机器上找到lib目录下的驱动文件，解压后发现版本确实没有变化，那么只能手动强制替换了，把Hive Master，Slave机器上的驱动全替换成最新版本，然后再次重启Hive组件服务，接着就出现个新问题。\n问题二\n单纯的从上述的日志无法确定问题的本身，因为可以确切的确定文件是存在于HDFS之上的。所以还是切换到Hive服务日志上面，找到下面的一段日志：\nERROR [HiveServer2-Background-Pool: Thread-4456]: hdfs.KeyProviderCache (KeyProviderCache.java:createKeyProviderURI(87)) - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider !! ERROR [HiveServer2-Background-Pool: Thread-4456]: metadata.Hive (Hive.java:copyFiles(2853)) - Failed to move: org.apache.hadoop.security.AccessControlException: Permission denied. user=admin is not the owner of inode=xxxxx.csv at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkOwner(FSPermissionChecker.java:250) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:227) 从这段日志明显的看出是用户权限的问题，不过这边有点不解，为何Ambari Hive View不直接使用超级用户进行操作，现在只能是强行的更改文件的所属者，命令如下：\nhdfs dfs -chown hdfs:hadoop /tmp/XXX/XXX.CSV 至此所有问题都修复完成，重新执行导入操作，一切运行正常，数据成功导入。\n参考引用：\nhive-metastore-not-working-syntax-error-option-sql ","date":"2017-10-17T17:33:04+00:00","updated":"2017-10-17T17:33:04+00:00"},{"permalink":"/tech/azkaban-execute-jobs.html","title":"Azkaban所支持的Job类型及示例","content":"在官方文档的介绍中，了解到Azkaban所支持的工作类型还是很丰富的，如：Command，HadoopShell，Python，Java，Hive，Pig等等。不过在此我们主要具体只来讲解下Python与Java的工作类型任务，其它工作类型的话，比如Commnad，Hive，HadoopShell相对比较简单就不做详解，有需要的话可以自行实践一下。\n不管提交哪一种任务，Azkaban默认都是通过上传压缩包来管理，那么在此建议大家养成一个习惯，不要所执行的文件(代码)打包到Azkaban的工程包里面。这样带来的好处是显而易见的，比如：\n工程创建的速度快，不需要上传执行部分文件\n避免了修改MySQL中的max_allow_packet参数以解决工程文件上传失败的问题\n在分布式布署环境中，当执行Task免去了在不同节点中拷贝工程包的麻烦\nJava工作任务 由于工作业务场景中，大部分的代码都是Java来编写的，这也正是选择Azkaban的重要原因。与常见的Java程序并无太大的差异，唯一的不同便是程序入口的方法不一样。需要在入口的类中增加个**run**方法，即这方法是启动整体个Task的关键。示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package io.github.elkan1788.azkabantasks; import azkaban.utils.Props; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Azkaban java job example * @author elkan1788@gmail.com */ public class JobMain { private static final Logger logger = LoggerFactory.getLogger(JobMain.class); private int fileRows; private int fileLine; /** * Dynamic parameters set */ public JobMain(String name, Props props) { this.fileRows = props.getInt(\u0026#34;file.rows\u0026#34;); this.fileLine = props.getInt(\u0026#34;file.line\u0026#34;); } public void run() throws Exception { logger.info(\u0026#34; ### this is JavaMain method ###\u0026#34;); logger.info(\u0026#34;fileRows value is ==\u0026gt; \u0026#34; + fileRows); logger.info(\u0026#34;fileLine value is ==\u0026gt; \u0026#34; + fileLine); } } 在上面的示例代码中，增加了动态参数设置，最后在打包的时候并不需要指定MainClass的所在，只要项目中的所有相关的代码及依赖打包到一个独立的文件即可。\n另外我们还需要构建一个Azkaban工程脚本来告诉它如何执行我们的任务，脚本示例如下：\n1 2 3 4 5 6 7 8 type=java job.class=io.github.elkan1788.azkabantasks.JobMain #指定执行jar包的路径 classpath=/home/azkaban/javademo/* #用户参数1 file.rows=10 #用户参数2 file.line=50 为了不让任务太单调，顺便个简单的命令输出，组成个FLOW形式输出，参考脚本如下：\n1 2 3 type=command dependencies=java command=whoami 效果如下：\nPthon工作任务 Python的工作任务相对就简单了，不过目前没找到动态入参的方法。执行Python工作任务的方法有两种, 参考代码如下：\ncommand类型 1 2 type=command command=python -u /home/azkaban/pythondemo/helloworld.py python类型 1 2 3 type=python python=python script=/home/azkaban/pythondemo/helloworld.py 效果如下：\n总结 总的来说，Azkaban编写任务的脚本还是简单且灵活的，不过也有比较坑人的地方。比如前面举粟的Java工作任务，在实际的运行过程中是需要添加hadoop的依赖包及相关配置，能过查阅官方文档得知是因为Java任务类型是在HadoopJava衍生出来的，所以也就难怪了。还好这也是只是配置环境时的问题，后续的应用开发还是挺方便的。\n","date":"2017-09-09T18:45:42+00:00","updated":"2017-09-09T18:45:42+00:00"},{"permalink":"/tech/azkaban-install-use-share.html","title":"定时调度任务器Azkaban安装","content":"背景与介绍 在大数据繁杂的ETL或其它数据处理过程当中，有些任务是需要定时执行的，虽然Linux自带了cron命令功能，但是仍不能满足最大的一点就是它不能提供集中式的管理和可视化的编辑。其实在大数据的生态当中已集成有个定时调度框架Oozie，只是实践下来发现其学习成本不低，布署的过程也较复杂。在尝试过其它分布工调度框架后（如阿里的宙斯Zeus），还是选择了社区较多人使用的Azkaban。\nAzkaban3相对于上个版本所做的更改还是比较大的，感兴趣的话可以到其官方网站 Azkaban 了解下。接下来主要还是分享下Azkaban3的安装布署，下面是Azkaban3的系统架构设计图：\n图中的3个组件便是Azkaban3的重要组成部分：\nMySQL关系数据存储数据 Web Server GUI管理服务提供者 Executor Server 分布式节点服务布署 数据库初始化 建议使用MySQL5.6及以上版本的数据库，首先创建一个名为azkaban的数据库：\n1 mysql\u0026gt; CREATE DATABASE azkaban DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 指定某个数据库用户，为其赋予对azkaban数据库具有SELECT,INSERT,UPDATE,DELETE的操作权限：\n1 mysql\u0026gt; GRANT SELECT,INSERT,UPDATE,DELETE ON azkaban.* to \u0026#39;azkaban-dba\u0026#39;@\u0026#39;%\u0026#39; WITH GRANT OPTION; 最后就是导入创建表的SQL语句，官方提供的建表语句比较分散，为此特地整理了份完整的建表语句 Azkaban Create Tables 密码: 8ne8 :\n1 mysql\u0026gt; source /opt/download/azkaban-create-tables.sql 注意：由于Azkaban3的项目发布是通过上传文件实现的，因此需要把MySQL中允许上传包大小的能数调整下，此参数位于[mysqld]下：max_allowed_packet=64M，根据实际情况修改适合大小。\n其实有个办法可做到不修改此参数 ，就是打包Azkaban项目时尽量不要包依赖文件放进来，通过相对路径的引用即可。\nWeb Server布署 Web Server目录下有7个文件夹，描述如下：\n文件夹 描述 bin 脚本相关文件，如启动，停止Jetty服务 conf Solo服务的配件文件 lib Web Server必须的依赖包库 extlib 第三方扩展依赖包 plugins Azkaban插件安装位置 web Web Server的文件，如css，js, html等 Web Server的布署需要修改至少4处地方，具体如下：\nazkaban.properties配置 官方默认的配置文件中缺少了多执行器的参数设置，参考如下：\n# Azkaban Personalization Settings # 站点名称，中文可用UTF-8编码，不过邮件通知不支持 azkaban.name=Azkaban azkaban.label=Production Environment azkaban.version=3.25 azkaban.color=#FF3601 azkaban.default.servlet.path=/index web.resource.dir=web/ default.timezone.id=Asia/Shanghai # Azkaban UserManager class user.manager.class=azka ban.user.XmlUserManager user.manager.xml.file=conf/azkaban-users.xml # Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects # DB settings database.type=mysql mysql.port=3306 mysql.host=127.0.0.1 mysql.database=azkaban mysql.user=azkaban-dba mysql.password=12345678 mysql.numconnections=100 # Velocity dev mode velocity.dev.mode=false # Azkaban Jetty server properties. jetty.hostname=localhost jetty.use.ssl=false jetty.maxThreads=25 jetty.port=8081 # Azkaban Executor settings executor.port=12321 # Notification Email Settings mail.sender=elkan1788@gmail.com mail.host=stmp.gmail.com mail.user=elkan1788@gmail.com mail.password=12345678 lockdown.create.projects=false cache.directory=cache # JMX stats jetty.connector.stats=true executor.connector.stats=true # Azkaban plugin settings azkaban.jobtype.plugin.dir=plugins/jobtypes # Multiple executors settings azkaban.use.multiple.executors=true azkaban.executorselector.filters=StaticRemainingFlowSize,CpuStatus azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1 azkaban.executorselector.comparator.Memory=1 azkaban.executorselector.comparator.LastDispatched=1 azkaban.executorselector.comparator.CpuUsage=1 azkaban-users.xml配置 Azkaban采用的是类似Spring Securit的账户信息配置，参考如下：\n1 2 3 4 5 6 7 8 9 \u0026lt;azkaban-users\u0026gt; \u0026lt;!-- UserAccount Info --\u0026gt; \u0026lt;user groups=\u0026#34;azkaban\u0026#34; password=\u0026#34;azkaban\u0026#34; roles=\u0026#34;admin\u0026#34; username=\u0026#34;azkaban\u0026#34;/\u0026gt; \u0026lt;user password=\u0026#34;metrics\u0026#34; roles=\u0026#34;metrics\u0026#34; username=\u0026#34;metrics\u0026#34;/\u0026gt; \u0026lt;!-- Role Info --\u0026gt; \u0026lt;role name=\u0026#34;admin\u0026#34; permissions=\u0026#34;ADMIN\u0026#34;/\u0026gt; \u0026lt;role name=\u0026#34;metrics\u0026#34; permissions=\u0026#34;METRICS\u0026#34;/\u0026gt; \u0026lt;/azkaban-users\u0026gt; log4j.properties配置 官方默认的配置文件中只配置了终端的输出，通过Shell脚本重定向形成日志输出，而log4j本身是支持按日期增量管理的，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 log4j.rootLogger=INFO,C,file log4j.appender.C=org.apache.log4j.ConsoleAppender log4j.appender.C.Target=System.err log4j.appender.C.layout=org.apache.log4j.PatternLayout log4j.appender.C.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n log4j.appender.file=org.apache.log4j.DailyRollingFileAppender log4j.appender.file.File=/opt/azkaban3/web-server/logs/web-server.log log4j.appender.file.DatePattern=\u0026#39;.\u0026#39;yyyy-MM-dd log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %5p [%t](%F:%L) - %m%n 启停脚本 官方默认提供启停脚本并不太友好，稍稍做了些许修改，参考如下：\n启动脚本 (bin/start-web.sh) 1 2 3 4 5 !/bin/bash # 官方默认 # bin/azkaban-web-start.sh \u0026#34;$@\u0026#34; \u0026gt;\u0026gt; logs/webServerLog_`date +%Y%m%d`.out 2\u0026gt;\u0026amp;1 \u0026amp; bin/azkaban-web-start.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 停止脚本(bin/shutdown-web.sh) 1 2 3 4 !/bin/bash # 官方默认 # bin/azkaban-web-shutdown.sh \u0026#34;$@\u0026#34; \u0026gt;\u0026gt; logs/webServerLog_`date +%Y%m%d`.out 2\u0026gt;\u0026amp;1 \u0026amp; bin/azkaban-web-shutdown.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 其他配置 可以把一些公共的配置统一放到conf/global.properties配置中统一管理，如项目执行成功，失败的通知人电子邮件，默认的执行类型等等。\nExecutor Server布署 Executor Server与Web Server相比就只是少了个plugins目录，描述如下：\n文件夹 描述 bin 脚本相关文件，如启动，停止Jetty服务 conf Solo服务的配件文件 lib Executor Server必须的依赖包库 extlib 第三方扩展依赖包 plugins Azkaban插件安装位置 原则上建议一台机器上只布署一个Executor Server节点，因为在节点启动的时候它会自动加入到数据库executors列表中，当然也是可以通过端口干预的方法来配置本地伪分布模式布署。\nExecutor Server布署相对简单多了，只要更新3处即可，具体如下：\nazkaban.properties配置 只需要修改下官方默认配置文件的值即可，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # Azkaban Personalization Settings default.timezone.id=Asia/Shanghai # Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects # DB settings database.type=mysql mysql.port=3306 mysql.host=127.0.0.1 mysql.database=azkaban mysql.user=azkaban-dba mysql.password=12345678 mysql.numconnections=100 # Velocity dev mode velocity.dev.mode=false # Azkaban Executor settings executor.host=127.0.0.1 executor.port=12321 executor.maxThreads=50 executor.flow.threads=30 # JMX stats jetty.connector.stats=true jetty.host=127.0.0.1 executor.connector.stats=true # Azkaban plugin settings azkaban.jobtype.plugin.dir=plugins/jobtypes log4j.properties配置 参考上面的Web Server中的配置即可，注意修改日志文件的输出路径。\n启停脚本 同样的对启停脚本做了些更改，方便后期日志的回放，参考如下：\n启动脚本(bin/start-exec.sh) 1 2 3 4 5 6 7 #!/bin/bash export HADOOP_HOME=/opt/hdp/2.3.2.0-2950/hadoop # pass along command line arguments to azkaban-executor-start.sh script # bin/azkaban-executor-start.sh \u0026#34;$@\u0026#34; \u0026gt;\u0026gt; logs/executorServerLog_`date +%Y%m%d`.out 2\u0026gt;\u0026amp;1 \u0026amp; bin/azkaban-executor-start.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 停止脚本(bin/shutdown-exec.sh) 1 2 3 4 5 6 7 #!/bin/bash export HADOOP_HOME=/opt/hdp/2.3.2.0-2950/hadoop # pass along command line arguments to azkaban-executor-start.sh script # bin/azkaban-executor-shutdown.sh \u0026#34;$@\u0026#34; \u0026gt;\u0026gt; logs/executorServerLog_`date +%Y%m%d`.out 2\u0026gt;\u0026amp;1 \u0026amp; bin/azkaban-executor-shutdown.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 启动预览 至此Azkaban3运行所需要的关键配置已经配置好，接下就是启动相应的服务预览下劳动成果。\n启动 启动顺序如下：\n启动 Executor Server服务： sh bin/start-exec.sh\n更新数据表：在excecutors表中找到executor server hostname对应的记录，把最后一列active 的值更新为 1\n启动Web Server服务：sh bin/start-web.sh\n注意：启动前请确定端口正常未占用，另外留意内存的使用情况。\n启动成功后，在浏览器中输入http://localhost:8081便可看到Web Server的界面，如下图所示：\nDemo 在上述启动成功的Web Server中创建中新的项目，命名为：ShellJob-Demo，然后把下面示例Job下载并上传至刚才创建好的项目中，注意不需要解压哦。然后在项目中找到Exectue Flow按钮，然后不断的下一步即可，如下图组所示：\nBase Flow Demo 密码: 4f4f Azkaban3是通过Web Server把任务(Job)提交到Executor Server执行的，因此在界面上是不能直观的看到程序执行过程，但可以通过执行列表中找到正在运行的任务，查看其日志的方式来了解运行过程，如下图组所示：\n好啦，至此Azkaban3的服务布署及简单示例便完成收工，是不是相对而言比较简单呢。初步阶段来看Azkaban3的使用还是可以贴合业务的场景使用，只是后面提升过程发现它自身也并不完善，比如在上面启动过程中需要手动去更新数据库才能激活Executor Server（只是首次启动时），另外官方并未提供Executor Server运行的管理，分布式运行时需要手动指定Executor Server的ID 等等。但是基本上还是可以满足日常的使用，特别是它的Job Flow设计。最后要是关于Azkaban3有问题可评论中一起讨论，后续也会更新相关的使用教程，敬请关注。\n","date":"2017-09-08T14:29:42+00:00","updated":"2017-09-08T14:29:42+00:00"},{"permalink":"/tech/use-travis-ci-push-hexo-blog.html","title":"使用Github，Travis CI自动布署Hexo博客到Coding，OSChina服务器","content":"通常我们都是在本地用hexo deploy发布博客文章到远程的Pages服务器，可别忘记了我们是还需要提交代码的，所以是不是觉得有点麻烦还得分开两步进行操作。这时突然想起是否可用Travis CI工具来完成这个布署的操作呢？答案是肯定的，整体的流程大致如下：\n在本地(又或者Github网站)上编辑文章 提交文章到Github服务器 Travis CI收到通知，同步最新的Github代码，并执行用户自定义好的Travis脚本生成静态博客 最终再把生成好的博客推送到指定的Pages服务器 只是这其中有点比较麻烦的问题就是如何保护我们的私钥，还好Travis CI已经为我们准备好啦，那么就开始我们的捣腾之旅吧。\n准备Travis Client工具 准备Ruby环境 Ruby的安装请移步搜索引擎，在此只是提示下建议使用2.0以上的版本，另外就是注意更新gem的镜像地址： Ruby China 。\nTravis CI账户 如有需要可以单独注册账号，建议直接使用Github Token登录即可。 接下来就是需要生成个Github Token，在Github的个设置面板中找到，或者是直接点击 Github Tokens 进行创建，如下图所示：\n保存好刚刚创建的Token，然后使用Github授权登录Travis CI并跳转至控制面板 Travis Profile ，选择需要创建的项目(即你的博客项目)如下图所示\nTravis Client安装 Travis Client安装非常的简单，命令如下：\n1 sudo gem install travis -v 1.8.8 --no-rdoc --no-ri 安装成功后，使用如下命令检查，安装成功会有版本号的输出。\n1 travis version 使用如下命令检验上一步所生成的Github Token，并登录Travis CI成功后会返回欢迎信息。\n1 2 travis login -g fb25xxxxxxxxxxx Successfully logged in as xxxx! SSH私钥加密 切换到博客的根据目录，创建一个名为.travis的目录，并把用于Coding和OSChina的私钥拷贝至此，使用如下的命令生成Travis能识别的加密文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 travis encrypt-file id_rsa Detected repository as elkan1788/my-hexo-blog, is this correct? |yes| yes encrypting id_rsa for elkan1788/my-hexo-blog storing result as id_rsa.enc storing secure env variables for decryption Please add the following to your build script (before_install stage in your .travis.yml, for instance): openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in id_rsa.enc -out id_rsa -d Pro Tip: You can add it automatically by running with --add. Make sure to add id_rsa.enc to the git repository. Make sure not to add id_rsa to the git repository. Commit all changes to your .travis.yml. 加密成功后千万要记得要把id_rsa文件删除，并把如下的语句保存好，后续在布署脚本中用得上：\n1 openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in id_rsa.enc -out id_rsa -d 准备Travis脚本 编写Travis脚本 Travis脚本使用的是yml语法，写起来并不难，注意空格的缩进就好。在博客根目录下创建名为.travis.yml的文件，内容参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # Define language environment language: node_js # use root accout or not sudo: false # node js version node_js: stable # setting timezone before_install: - export TZ=\u0026#39;Asia/Shanghai\u0026#39; # cache installed modules cache: apt: true directories: - node_modules # add pages server domain addons: ssh_known_hosts: - git.coding.net - git.oschina.net # auto deploy blog to pages server deploy: provider: script script: sh .travis/deploy.sh skip_cleanup: true on: branch: master # offical request dist: precise # which branch trigger branches: only: - master 如果不确定所编写的脚本是否正确，可借助Travis CI进行校验，命令如下：\n1 2 travis lint .travis.yml Hooray, .travis.yml looks valid :) 编辑deploy.sh脚本 接下来就是编写个发布博客文章到Pages服务器的脚本，主要的流程如下：\n解密SSH私钥，并输出到指定的目录 修改私钥的文件权限，启动SSH Agent， 添加私钥 设置Git配置，主要是用户名，邮箱地址 使用Hexo命令-\u0026gt;清理，生成，发布 脚本内容参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash # Decrypt the private SSH key openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in .travis/id_rsa.enc -out ~/.ssh/id_rsa -d # Set the permission of the private SSH key chmod 600 ~/.ssh/id_rsa # Start SSH agent eval $(ssh-agent) # Add the SSH private key to the system ssh-add ~/.ssh/id_rsa # Set Git config git config --global user.name \u0026#34;凡梦星尘\u0026#34; git config --global user.email elkan1788@gmail.com # Clean, generate and deploy to Pages server hexo clean \u0026amp;\u0026amp; hexo g \u0026amp;\u0026amp; hexo deploy 发表文章 使用hexo new \u0026quot;article tittle\u0026quot;命令创建一篇文章，然后加入你想吐槽的观点，内容等保存，然后用git push命令推送代码到Github服务器，此时登录Travis CI便可以在对应的项目中看到\u0026quot;华丽\u0026quot;的日志输出如下图所示：\n如果最后的结果是绿色，那么恭喜你，你的博客已经布署成功，赶紧去刷新页面瞅瞅。\n至此所有的配置结束，怎么样，感觉是不是很炫，只要一个简单的git push命令即保存代码又搞定博客站点布署，如有问题欢迎吐槽。\n参考：\n使用Github、Travis-CI和Coding.net自动部署博客［一］ 使用Github、Travis-CI和Coding.net自动部署博客［二］ 使用Github、Travis-CI和Coding.net自动部署博客［三］ ","date":"2017-08-19T15:40:26+00:00","updated":"2017-08-19T15:40:26+00:00"},{"permalink":"/tech/pymssql-azure-mssql-datasource-connect.html","title":"pymssql连接azure云的MSSQL数据库","content":"码好代码在测试环境做好测试后，满怀信心的去布署上线到生产环境，结果就是一堆的异常，具体查看了后发现是连接数据库的问题，异常信息如下：\n1 2 3 4 (40532, \u0026#39;Cannot open server \u0026#34;1433D\u0026#34; requested by the login. The login failed.DB-Lib error message 20018, severity 20:\\n General SQL Server error: Check messages from the SQL Server\\n DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed\\n\u0026#39;) 难道是环境安装的有问题，切换了下测试环境又没有问题，好吧，只好再次求助Google，最后找到了原因，应该是微软云自己做的规则，在用户名中加入主机名称就好了，参考如下：\n1 2 import pymssql conn = pymssql.connect(server=\u0026#39;yourserver.database.chinacloudapi.cn\u0026#39;, user=\u0026#39;yourusername@yourserver\u0026#39;, password=\u0026#39;yourpassword\u0026#39;, database=\u0026#39;AdventureWorks\u0026#39;) @yourserver 就是这个关键字\n参考：\n使用 Python 查询 Azure SQL 数据库 Cannot open server \u0026ldquo;1433D\u0026rdquo; requested by the login ","date":"2017-08-17T18:20:18+00:00","updated":"2017-08-17T18:20:18+00:00"},{"permalink":"/tech/mac-install-pymssql-module.html","title":"在Mac/Linux系统下安装pymssql模块","content":"在非Windows环境下去访问，连接 MSSQL 数据，本身就是件苦差事来的。自写Python程序以来在ORM方面都是使用pyxxx的模块，果不其然连接 MSSQL 也有个模块叫pymssql，只是实际使用中并不是特别的顺利。如笔者所处的环境就是如此，开发环境为OSX 10.11，发布环境为CentOS 6.4，按官方的安装步骤实行下来，Linux 环境是OK的，只是 Mac 环境下安装失败，错误的堆栈信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Running setup.py install for pymssql ... error Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \u0026#34;import setuptools, tokenize;__file__=\u0026#39;/private/tmp/pip-build-KA5ksi/pymssql/setup.py\u0026#39;;exec(compile(getattr(tokenize, \u0026#39;open\u0026#39;, open)(__file__).read().replace(\u0026#39;\\r\\n\u0026#39;, \u0026#39;\\n\u0026#39;), __file__, \u0026#39;exec\u0026#39;))\u0026#34; install --record /tmp/pip-A3wRBy-record/install-record.txt --single-version-externally-managed --compile: setup.py: platform.system() =\u0026gt; \u0026#39;Darwin\u0026#39; setup.py: platform.architecture() =\u0026gt; (\u0026#39;64bit\u0026#39;, \u0026#39;\u0026#39;) setup.py: platform.libc_ver() =\u0026gt; (\u0026#39;\u0026#39;, \u0026#39;\u0026#39;) setup.py: Detected Darwin/Mac OS X. You can install FreeTDS with Homebrew or MacPorts, or by downloading and compiling it yourself. Homebrew (http://brew.sh/) -------------------------- brew install freetds MacPorts (http://www.macports.org/) ----------------------------------- sudo port install freetds ...... /usr/bin/clang -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/opt/local/include -I/opt/local/include/freetds -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c _mssql.c -o build/temp.macosx-10.6-intel-2.7/_mssql.o -DMSDBLIB _mssql.c:18924:15: error: use of undeclared identifier \u0026#39;DBVERSION_80\u0026#39; __pyx_r = DBVERSION_80; 在安装pymssql之前有个关于的组件为FreeTDS，所遇到的问题也就是出现在此组件上面。 在Linux和OSX环境下的安装命令分别如下：\n1 2 3 4 5 # Linux yum install freetds-devel.x86_64 # Mac brew install freetds 在Mac环境中需要注意freetds的版本引起的问题，可以正常使用的版本为0.91，修正后的安装命令如下：\n1 2 3 brew uninstall --force freetds brew install freetds@0.91 brew link --force freetds@0.91 另外还得需要安装一个Python模块，安装命令如下：\n1 pip install cython 上述环境准备就绪后，便可以顺利的安装pymssql模块，执行如下安装命令：\n1 pip install pymssql 写个简单的测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python # -*- coding: utf_8 -*- # coding=utf8 import pymssql server = \u0026#34;192.168.1.2\u0026#34; user = \u0026#34;sa\u0026#34; password = \u0026#34;123456\u0026#34; conn = pymssql.connect(server, user, password, database=\u0026#34;platform\u0026#34;) cursor = conn.cursor() cursor.execute(\u0026#34;SELECT * FROM Table\u0026#34;) row = cursor.fetchone() while row: row = cursor.fetchone() print row conn.close() OK，全部搞定，继续码代码去。\n参考如下：\npymssql-isseues432 mac-pip-install-pymssql-error ","date":"2017-08-16T13:50:55+00:00","updated":"2017-08-16T13:50:55+00:00"},{"permalink":"/tech/hue-rdbms-mysql-chinese.html","title":"Hue中集成MySQL数据显示乱码","content":"Hue is a Web applications that enables you to easily interact with an Hadoop cluster. Hue applications let you browse HDFS, Jobs, run Hive, Pig and Cloudera Impala queries, manage the Hive Metastore, HBase, Sqoop, ZooKeeper, MapReduce jobs, and create and schedule worklows with Oozie.\n更加关于HUE的介绍及演示可访问其官方网站： http://gethue.com 在此主要解决的是在HUE过程中集成MYSQL管理时，遇到了数据库开发中常见的中文乱码问题。先来看看集成MySQL的配置描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ########################################################################### # Settings for the RDBMS application ########################################################################### [librdbms] # The RDBMS app can have any number of databases configured in the databases # section. A database is known by its section name # (IE sqlite, mysql, psql, and oracle in the list below). [[databases]] # sqlite configuration. ## [[[sqlite]]] # Name to show in the UI. ## nice_name=SQLite # For SQLite, name defines the path to the database. ## name=/tmp/sqlite.db # Database backend to use. ## engine=sqlite # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ ## options={} # mysql, oracle, or postgresql configuration. [[[mysql]]] # Name to show in the UI. nice_name=\u0026#34;MY SQL DB\u0026#34; # For MySQL and PostgreSQL, name is the name of the database. # For Oracle, Name is instance of the Oracle server. For express edition # this is \u0026#39;xe\u0026#39; by default. name=mysql # Database backend to use. This can be: # 1. mysql # 2. postgresql # 3. oracle engine=mysql # IP or hostname of the database to connect to. host=localhost # Port the database server is listening to. Defaults are: # 1. MySQL: 3306 # 2. PostgreSQL: 5432 # 3. Oracle Express Edition: 1521 port=3306 # Username to authenticate with when connecting to the database. user=USER # Password matching the username to authenticate with when # connecting to the database. password=PASSWORD # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ # options={} 这段配置很简单理解起来也难，可实际运行过程中就遇到了两个难题，先是显示出现乱码问题，另外就是配置中给的文档链接地址是**404**，真是尴尬啦。追溯下来最后到找到关于 sql-mode 设置，想下应该是支持MySQL的命令吧，然后就在配置最后一段加入如下的命令：\n1 options={ \u0026#34;init_command\u0026#34;:\u0026#34;SET NAMES `utf8`\u0026#34;} 实验了一下，乱码问题OK，中文显示正常。\n其实要不生产环境的话就不用如此的折腾，最简单的办法就是更新my.ini配置，你懂的。\n","date":"2017-08-15T15:13:39+00:00","updated":"2017-08-15T15:13:39+00:00"},{"permalink":"/tech/python-output-conosle-intime.html","title":"Python在命令行即时输出","content":"在程序遇到问题需要DEBUG时，通过会增加一些**print**语句输出。于是乎按惯例也在Python的代码中加入print调试，然后输入python xxxx.py，满怀信心的期待着调试信息的满屏滚动，结果是过了好阵子才显示出来。为何会这样呢？\n根据网友建议增加个-u参数就OK，后来查了下原因：Python在默认情况会先把print输出到缓冲中，待缓冲满或程序后才会输出。所以可以在运行Python程序时加入此参数是非常的有用。\n1 python -u xxxx.py 除此之外还支持别的参数，参考如下\n-B 参数，在import时候，不产生pyc或者pyo文件 -c 参数，直接运行python语句 -i 参数，运行完python脚本文件以后打开一个python环境，方便查看运行结果 -m 参数，将模块按照脚本执行 -V 参数，输出Python的版本 -O 参数，产生一个优化的pyo文件（和-B 参数一起使用无效） -v 参数，会输出每一个模块引用信息，包括从何处引用的，以及何时被清除的 -u 参数，在print记录时候很有用，使用这个参数 会强制 stdin, stdout 和 stderr变为无缓冲的，会立刻输出出来，而不是等缓冲区满了才会打印数据。 参考:\nPython命令行参数学习 ","date":"2017-08-13T14:19:14+00:00","updated":"2017-08-13T14:19:14+00:00"},{"permalink":"/tech/python-pip-install-chinese-mirror.html","title":"Python pip中国镜像服务器地址","content":"今天在安装一个Python模块\u0026ndash;\u0026gt;pymysql结果等待时间特别的长，最后超时失败啦，起初是以为是网络带宽问题，让IT调整后仍是失败，随后尝试查找国内的镜像，还有真人也遇到过相同的问题。镜像列表如下：\n1 2 3 4 5 6 https://pypi.douban.com/simple/ 豆瓣 http://mirrors.aliyun.com/pypi/simple/ 阿里 http://pypi.hustunique.com/simple/ 华中理工大学 http://pypi.sdutlinux.org/simple/ 山东理工大学 http://pypi.mirrors.ustc.edu.cn/simple/ 中国科学技术大学 https://pypi.tuna.tsinghua.edu.cn/simple 清华 然后在安装模块时，使用如下的命令：\n1 pip install xxxx -i https://pypi.douban.com/simple 网友还介绍了把镜像地址写入到配置文件的方法，但尝试没有成功，不明白其中的原因，待跟进。\n参考：\nPython pip 国内镜像大全及使用办法 ","date":"2017-08-11T14:17:01+00:00","updated":"2017-08-11T14:17:01+00:00"},{"permalink":"/tech/use-hexo-rebuild-blog-site.html","title":"使用Hexo重新构建个人博客站点","content":"其实在Github Page上面也是混迹许久啦，虽然现在各种Blog网站层出不穷，但是作为IT界的程序猿还是喜欢自己动手捣鼓捣鼓，成功固然是欣喜失败也会不气妥。 Github Page刚出道时使用的是Jekyll，简单的解释其实就是一个静态化网站的工具，这不现在又兴起一个名为Hexo(**Nodejs**实现)的工具。两者的目标皆是一致的，只不过对比下来发现Hexo上手确实要容易些，加者它能轻松的在本地实现调试，故有想法想再次折腾一翻，构建个Hexo版本的个人博客。\n介绍另一款静态网站工具 Gor ，它是鄙人一直崇拜的大拿 Wendal 的杰作，熟悉GO语言的朋友有可以关注下。\n动手前先对Pages服务做了个简单的调查，别无它意，就是现在Github用户越来越多且服务器又在国外的，生活在天朝的我们你懂的啦。惊喜的发现目前国内的Git服务商都提供了Pages实现，最后选择了 Gitee 和 Coding 作为新博客落脚点，其中Coding作为首先/默认服务，Gitee为备选的服务，作此选择的原因很简单：Coding不但提供了自定义域名，而且还附带了https免费证书，真是漂亮。\n对于Hexo环境的搭建在此就不在累述啦，官方文档给出了详细的说明(操作也是相当的简单)请移步： https://hexo.io/zh-cn/docs/index.html 。搭建好后可以在官方网站提供的 主题 页面中选择自己所喜爱的风格，个人选择的是较热门的 NexT ，喜欢它的简单，轻爽。\nNexT配置使用也是很简易的，下面就个人在搭建过程中遇到的问题做个简单的归纳：\n1.插件的的安装 Hexo相当的灵活提供丰富的插件支持，根据个人的需要可自行安装，个人的安装记录如下：\n1 2 3 4 5 6 7 8 9 # 生成RSS npm install hexo-generator-feed --save # 生成Site map为爬虫服务准备 npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save # 压缩站点文件 npm install hexo-all-minifier --save # 发布至Git服务器 npm install hexo-deployer-git --save 2.第三方服务集成 作为博客网站肯定是少不了互动的环节，现在的互联网世界早就已提供了此功能，在此主要用到的功能有：文章阅读，文章数字统计，站点PV/UV，评论回复。其它的功能集成应该都没难度，只要在对应的服务商站点注册好，填写对应的ID，KEY即可。主要提及下文章数字统计的功能：\n登录 LeanCloud 找到你的应用，点击其右上角的设置按钮，如下图所示: 接着点击左侧菜单中的存储，然后在中间的列表中点击创建Class，输入名称点击创建即可，如下图所示： 此时先别设置安全域名，直接在本地启动Hexo服务，不停的刷新页面，便可以看到你想结果啦，就是这么的简单。\n搭建过程中发现NexT的jiathis代码模板已过且没有uid的概念，另外统计代码的存放位置也是有问题的，fork后提交的pull请求，如有兴趣可以关注下： pull-1796 3.同时发布到多个Git服务器 因为选择了Gitee和Coding为博客的运行服务器，所以在发布时需要同时推送，参考如下：\n1 2 3 4 5 6 7 # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: coding: git@git.coding.net:lisenhui/lisenhui.git,master oschina: git@git.oschina.net:lisenhui/lisenhui.git,master 4.自定义域名绑定 除了在Git Pages服务商那里绑定自定义的域名外，我们还需要在站点中添加个名为CNAME的文件，内容为你想指向的域名。在此建议使用 DNSPod 做域名的解析，可精细指定不来源访问不同的服务(是不是有点分发的味道)，具体的操作可以参考官方/网上教程。\n到此个人的博客站点便是搭建完成，效果演示如本站, 若是懒的配置，直接clone鄙人的博客项目即可(记得要把名字改掉呀,哈), 如下：\n1 git clone https://git.oschina.net/lisenhui/my-hexo-blog.git 欢迎各位拍砖和鲜花\n实际上Hexo博客的搭建只需要如下几步：\nnpm install -g hexo-cli mkdir hexo-blog hexo init hexo-blog cd hexo-blog git clone https://github.com/iissnan/hexo-theme-next themes/next vi _config.yml (change theme: next) hexo g \u0026amp;\u0026amp; hexo s (打开浏览器输入: http://127.0.0.1:4000) 参考文章：\nHexo常用命令 leanCloud,实现文章阅读量统计 Hexo+Next主题博客提交百度谷歌收录 使用Hexo + Next搭建静态博客 ","date":"2017-08-02T16:04:35+00:00","updated":"2017-08-02T16:04:35+00:00"},{"permalink":"/tech/hexo-hello-world.html","title":"Hexo blog Hello World","content":"Welcome to Hexo ! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub .\nQuick Start Create a new post 1 $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing Run server 1 $ hexo server More info: Server Generate static files 1 $ hexo generate More info: Generating Deploy to remote sites 1 $ hexo deploy More info: Deployment ","date":"2017-07-31T18:32:53+00:00","updated":"2017-07-31T18:32:53+00:00"},{"permalink":"/tech/nodejs-apidoc-generator.html","title":"APIDoc自动生成接口文档","content":"对于项目开发常见的前后端分离模式来说，中间在后端完成接口开发交付对接时，前端人员往往苦于没有接口文档会经常\u0026quot;跑去\u0026quot;骚扰后端人员，真是苦不堪言哪。要是此时有个文档化的说明那就轻松多啦，现在后端流行的文档生成利器有Swagger，它虽然方便，但是也有弊端得写在的后台的代码中，而且启动整个后台项目才能访问。或许有时还真不太方便的，另外就是项目初期要对接口做个规划也无法用这个方法，难道就没有别的办法了嘛？\n最后在浩瀚的网络中还是找到个不错的工具—— Nodejs APIDoc ，非常的强大，支持当前流行的开发语言，如Java,PHP,JavaScript,Python,Ruby等等，下面就来简单的介绍下它的使用方法。\n安装模块 前面的介绍中已经说了它是基于NodeJS环境，所以你必须先有个NodeJS环境，然后就是安装下APIDoc模块，参考命令如下：\n1 npm install apidoc -g 工程配置文件 接下来创建个工程文件夹，并入个工程的配置文件，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;name\u0026#34;: \u0026#34;XXXX开放接口平台\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.1\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;XXXX开放接口平台，设计所有与第三方服务对接的接口服务。请注意所有的接口数据交互格式为JSON格式。\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;XXXX开放接口平台\u0026#34;, \u0026#34;generator\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;XXXX\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2017-07-18 15:46:55\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://xxxx.com\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.1\u0026#34; } } 接口文档 所有相关的准备工作完成后，那么此时我们就需要来写关于接口描述的文档，这个具体要看你今后实际项目的开发语言，建议尽量选择相同的，在此我就以Java为示例，不需要具体的代码，只需填充代码注释部分的内容，参考如下：\nhello-api.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 /** * @apiDefine xxxxx * * XXX 当前接口文档名称(一般就对接客户的名称) */ /** * @apiDefine Err400 * * @apiError {String} tranDate 发生交易的日期 * @apiError {String} tranTime 发生交易的时间 * @apiError {String} serviceId 机构代码(东吴提供) * @apiError {Number} resultCode 1,表示成功,0表示失败 * @apiError {String} resultComment 失败原因描述 * * @apiErrorExample Error400-Response: * HTTP/1.1 400 * { * \u0026#34;tranDate\u0026#34;: \u0026#34;20170718\u0026#34;, * \u0026#34;tranTime\u0026#34;: \u0026#34;131223\u0026#34;, * \u0026#34;serviceId\u0026#34;: \u0026#34;xxxx\u0026#34;, * \u0026#34;resultCode\u0026#34;: 0, * \u0026#34;resultComment\u0026#34;: \u0026#34;请求数据语法格式有误.\u0026#34; * } */ /** * @apiDefine Suc200 * * @apiSuccess {String} tranDate 发生交易的日期 * @apiSuccess {String} tranTime 发生交易的时间 * @apiSuccess {String} serviceId 机构代码(东吴提供) * @apiSuccess {Number} resultCode 1,表示成功,0表示失败 * @apiSuccess {String} resultComment 失败原因描述 * * @apiSuccessExample Success-Response: * HTTP/1.1 200 * { * \u0026#34;tranDate\u0026#34;: \u0026#34;20170718\u0026#34;, * \u0026#34;tranTime\u0026#34;: \u0026#34;131223\u0026#34;, * \u0026#34;serviceId\u0026#34;: \u0026#34;xxxx\u0026#34;, * \u0026#34;resultCode\u0026#34;: 1, * \u0026#34;resultComment\u0026#34;: \u0026#34;Success\u0026#34; * } */ /** * @apiDefine AccessKey * * @apiHeader {String} access-key 加密密钥: 当前日期+指定字符串的32位MD5加密字符串. * * @apiHeaderExample {json} Header-Example: * { * \u0026#34;access-key\u0026#34;: \u0026#34;cfa1fd55a89f45c9800120d6cbff0b33\u0026#34; * } */ /** * @api {PUT} /dwhealath/synccustomerinfo.do 同步客户基础信息 * @apiDescription 批量次同步客户的基础信息，建议每个批次不要大于1000条记录。 * * @apiVersion 1.0.1 * @apiName customer * @apiGroup dwHealth * * @apiUse AccessKey * * @apiParam {String} cusName 姓名 * @apiParam {String} cusSex 性别 * @apiParam {String} cusBirthday 生日 * @apiParam {String} cusIdType 证件类型 * @apiParam {String} cusIdNo 证件号码 * @apiParam {String} cusCompanyId 工作单位 * @apiParam {String} cusServItemNo 计划编号 * * @apiParamExample {json} Request-Example: * { * \u0026#34;serviceId\u0026#34;: \u0026#34;xxxx\u0026#34;, * \u0026#34;data\u0026#34;: [ * { * \u0026#34;cusName\u0026#34;: \u0026#34;张三\u0026#34;, * \u0026#34;cusSex\u0026#34;: \u0026#34;男\u0026#34;, * \u0026#34;cusBirthday\u0026#34;: \u0026#34;2017-07-18\u0026#34;, * \u0026#34;cusIdType\u0026#34;: \u0026#34;身份证\u0026#34;, * \u0026#34;cusIdNo\u0026#34;: \u0026#34;4419381788902217652\u0026#34;, * \u0026#34;cusCompanyId\u0026#34;: \u0026#34;1024\u0026#34;, * \u0026#34;cusServItemNo\u0026#34;: \u0026#34;201707181313132\u0026#34;, * } * ...... * ] * } * * @apiUse Suc200 * * @apiUse Err400 * */ 生成接口文档 最后我们生成接口文档只需要一句简单的命令即可，如下：\n1 apidoc -i apidoc/ -o apidoc/ i 工程所在的文件夹 o 接口文档输出文件夹 文档效果如下图所示：\n常见问题 提示 error: Can not read: package.json, please check the format (e.g. missing comma). 解决方案：把文件另存为UTF-8格式，或是检查其它格式问题\n","date":"2017-07-18T15:23:43+00:00","updated":"2017-07-18T15:23:43+00:00"},{"permalink":"/tech/kylin-integrate-with-zeppelin.html","title":"Kylin集成Zeppelin展示数据","content":"实际上kylin自带的WEB UI已经集成了建议的图形报表，有常见的线形，柱形及饼图，用于数据的初步展示是完全够用的。如果要更加丰富的展示，那可以考虑使用别的工具，现在就试试官方推荐的Apache Zeppelin。\n打开 Apache Zeppelin官方网站 ，选择下载**zeppelin-0.7.1-bin-netinst.tgz**，版本其它的插件可以后续再安装。下载并解压到你想要运行的目录，然后拷贝conf/zeppelin-site.xml.template为conf/zeppelin-site.xml 修改对应的绑定地址和商口号。接着就是安装kylin插件， 命令如下：\n1 bin/install-interpreter.sh --name kylin --artifact org.apache.zeppelin:zeppelin-kylin:0.7.1 安装完成后使用如下命令启动zeppelin：\n1 2 bin/zeppelin-daemon.sh start # stop 停止 至此就可以打开浏览器然后访问zeppelin的WEB UI， 如下图所示：\nOK, 接下来就是创建与Kylin的连接，在Zeppelin中叫做Interpreter, 点击页面右上角的anonymous选择它如下图所示：\n同样的点击右上角的Create按钮，参考下图填写的数据填写你的真实数据：\n保存好后，点击左上角的Notebook\u0026ndash;\u0026gt; + Create new note如下图所示：\n把下面的SQL语句写入到notebook中：\n1 2 3 4 5 6 select fact.part_dt, lookup.categ_lvl2_name, count(distinct seller_id) as sellers from kylin_sales fact inner join kylin_category_groupings lookup on fact.leaf_categ_id = lookup.leaf_categ_id and fact.lstg_site_id = lookup.site_id group by fact.part_dt, lookup.categ_lvl2_name order by fact.part_dt desc 点击右边的开始按钮即可完成查询，出来一个表格数据 ，然后选取你所需要的图形报表形式，数据便会自动的渲染，点击settings可以有更多的调整。\n关于Zeppelin其它应用还需要慢慢了解，后续再跟进。\n参考：\ninterpreter-installation kylin ","date":"2017-06-02T18:03:23+00:00","updated":"2017-06-02T18:03:23+00:00"},{"permalink":"/tech/sqoop-import-data-to-hive.html","title":"Sqoop工具导入数据到Hive小记","content":"最近正在捣鼓构建数据仓库的事宜，正好有部分维度表的数据需要来自于RDBMS的数据，在HADOOP环境最流行的莫过于Apache的Sqoop工具，按官方的文档操作下来也很顺畅的，不过当要应用到业务场景上时问题便出现了。\n在Hive上面创建了一个Dimension表并用ORC格式储存（关于Hive ORC存储的介绍参考 Hive:ORC File Format存储格式详解 ），然后在执行Sqoop导入便会抛出下面的异常：\n1 FAILED: SemanticException Unable to load data to destination table. Error: The file that you are trying to load does not match the file format of the destination table. 经过几番测试后发现，Sqoop默认导入的数据格式为TXTFILE，所以当建表时使用TXTFILE存储格式就能正常的导入数据，但这不是我们所想要的，又查看了一下文档，发现其在1.4.5版本后提供了一个hcatalog命令是可以支持ORC File Format，参考命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 sqoop import --connect jdbc:mysql://master01:3306/data_pipeline --username dw --password-file hdfs:///user/hdfs/dw.txt --table dim_calendar --split-by ek_cal_id --compress --fields-terminated-by \u0026#34;,\u0026#34; --lines-terminated-by \u0026#34;\\n\u0026#34; --hcatalog-database default --hcatalog-table dim_calendar --map-column-hive cal_date=DATE,ts=TIMESTAMP --hcatalog-storage-stanza \u0026#39;stored as orc tblproperties (\u0026#34;orc.compress\u0026#34;=\u0026#34;SNAPPY\u0026#34;)\u0026#39; 从上面命令可以看出后续可以自由的定义存储格式及压缩格式，不过这边还有个问题会有个告警，如下：\n1 2 WARN hcat.SqoopHCatUtilities: Column cal_date had to be cast to a less precise type DATE in hcatalog WARN hcat.SqoopHCatUtilities: Column ts had to be cast to a less precise type TIMESTAMP in hcatalog 这个问题暂时没有办法解决，HIVE好像还支持这两种类型的数据格式，后面再跟进一下看看。\n执行Sqoop命令时一下要记得切换到同时安装有Sqoop Client与Hive Client的集群机器上，不然就会出现数据导入失败的情况。\n参考：\nSqoop使用手册 Hive:ORC File Format存储格式详解 Hive创建表时添加中文注释后乱码问题 SQOOP Import to Snappy ORC qoop Hive table import, Table dataType doesn\u0026rsquo;t match with database ","date":"2017-05-24T20:18:53+00:00","updated":"2017-05-24T20:18:53+00:00"},{"permalink":"/tech/linux-daemon-supervisor.html","title":"Supervisor介绍与使用","content":"很多时候我们自己开发的或别的服务都没有后台的守护进程，那么进程很容易就会被不小心的杀死，此时就需要有个程序去监控和维护这些程序服务。网上搜罗了一番后发现Supervisor组件正好能实现我们想要的，同时还支持对这些程序的统一管理，Nice!\n1 Supervisor is a client/server system that allows its users to monitor and control a number of processes on UNIX-like operating systems. 看完 官方网站 对Supervisor的定义描述，便立马觉得要实验一下。好在Linux系统中天生就是支持Python的，那么只要安装好PIP就可以得到你想要的一切。\n1.安装 pip：\n1 easy_install pip 2.安装 Supervisor:\n1 pip install supervisor 3.配置文件\n1 echo_supervisord_conf\u0026gt;/etc/supervisord.conf 3.1 配置文件详解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [unix_http_server] file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用 ;chmod=0700 ; socket 文件的 mode，默认是 0700 ;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=0.0.0.0:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 [supervisord] logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log logfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MB logfile_backups=10 ; 日志文件保留备份数量默认 10 loglevel=info ; 日志级别，默认 info，其它: debug,warn,trace pidfile=/tmp/supervisord.pid ; pid 文件 nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动 minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024 minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致 ;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件 [include] files = /etc/supervisor/*.conf ; 可以是 *.conf 或 *.ini 4.守护进程配置说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [program:kafka] directory = /root/kafka_2.10-0.10.1.1/bin/ ; 程序的启动目录 command = kafka-server-start.sh /root/kafka_2.10-0.10.1.1/config/server.properties ; 启动命令，可以看出与手动在命令行启动的命令是一样的 autostart = true ; 在 supervisord 启动的时候也自动启动 startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了 autorestart = true ; 程序异常退出后自动重启 startretries = 3 ; 启动失败自动重试次数，默认是 3 user = root ; 用哪个用户启动 redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 false stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数 ; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile = /var/log/kafka-server.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH ; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 5.启动服务\n1 supervisord -c /etc/supervisord.conf 6.用supervisorctl管理守护的进程\n1 2 3 4 5 6 # all 可换成具体的进程名称 supervisorctl status all supervisorctl start all # 重新加载配置 supervisorctl reload 7.启用WEB界面\n1 2 3 4 ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 然后在浏览器中输入： http://127.0.0.1:9001， 输入登录信息， 界面展现如下：\n现在你可以尝试下杀死守护进程，看看它是不是又自动重启， 当然如果要是supervisord服务被杀死那么也就没戏啦。\n","date":"2017-05-18T07:10:23+00:00","updated":"2017-05-18T07:10:23+00:00"},{"permalink":"/tech/maven-deploy-center-sign-failed.html","title":"发布jar到Maven时遭遇gpg签名失败","content":"有许久没维护自己开源的项目了，此次在修复BUG发布时遭遇失败，检查后发现原因是因为gpg签名失败，没办法换了MAC电脑有些操作不熟悉是有点郁闷的。\n关于如何将自己的JAR共享到Maven中央仓库，网上有很多的资源，大家可以自行尝试一下，其实也不难的，完全没必要担心英语的问题。\n分享一个别人整理的GitBook: 发布到中央仓库 1 2 3 [INFO] --- maven-gpg-plugin:1.6:sign (sign-artifacts) @ mpsdk4j --- gpg: 签名时失败： Inappropriate ioctl for device gpg: signing failed: Inappropriate ioctl for device 上面就是GPG在签名时遇到的问题，单纯从字面上来看是说对于此设备有个不适合的ioctl，不明白是何东西。最后一步步探究下来发现是因为管理GPG的服务器不能用的缘故，在网上找了个新的服务器重新上传如下：\n1 2 3 4 gpg --keyserver hkp://pgp.mit.edu --send-keys DAB131AA5564DCF176 #如果不放心的话，可以使用下面的命令检查一下 gpg --keyserver hkp://pgp.mit.edu --recv-keys DAB131AA5564DCF176 好啦，重新打包release jar包， 很开心的看到了SUCCESS的结果，收工。\n","date":"2017-05-17T17:02:23+00:00","updated":"2017-05-17T17:02:23+00:00"},{"permalink":"/tech/github-push-failed.html","title":"Github push失败：Could not resolve hostname","content":"平时最常用的git push命令突然间居然不可以用（错误日志如下），脑子首先蹦出的想法就是：难道Github又被墙了么！以前出现过类似这样的现象，需要通过指定hosts来加速访问。\ngit push 执行后返回的错误日志：\n1 2 3 4 ssh: Could not resolve hostname github.com:elkan1788: nodename nor servname provided, or not known fatal: Could not read from remote repository. Please make sure you have the correct access rights 首先用最简单的SSH命令检测一下，结果如下：\n1 2 3 4 5 6 ssh -T git@github.com Hi elkan1788! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. ssh -T git@git.oschina.net Welcome to Git@OSC, 凡梦星尘! 那说明git sever都是正常的，那为何push会失败呢？ 网友方法都一一试过，像指定hosts, 更新ssh key，添加DNS: 8.8.8.8等等。最后没有办法暂时把ssh更换成https模式， 执行git push输入用户与密码提交成功。 可是根本的问题并没有解决，最后想要不重新clone项目试试，于是乎重新创建目录，clone项目修改文件提交，结果是成功了。\n此时只能说是太诡异了，仔细回想下是否改动过配置呢？但确定是没有的，不过想起了上次编绎源码安装时更新了软件，难道是这个问题，输出git的版本如下：\n1 2 git --version git version 2.11.0 (Apple Git-81) 果不其然git是被更新了，但目前没有找到问题的确切的根源，主要的解决办法就是重新clone项目，问题自行解决， 后续有更新再跟进下。\n","date":"2017-05-16T10:21:43+00:00","updated":"2017-05-16T10:21:43+00:00"},{"permalink":"/tech/zookeeper-unload-data-exception.html","title":"Zookeeper崩溃后无法加载事务日志","content":"今天在生产的HDP环境中，遇到一件非常诡异的事情。明明搭建了2台zookeeper集群，却是莫明其妙的不见了，而且HDP服务还不报错，认真的检查过环境还是没有找到异常的信息，真是说不明白了。\n言归正传， 还是说说后面遇的问题吧： 生产环境zookeeper崩溃，查看日志发现是磁盘空间已经写满。起初以为是很简单的操作，删除无用的日志文件释放磁盘空间（这是不得不吐槽下HDP的日志文件是超多的，奈何生产环境又不敢不预留长些的时间），然后重启zookeeper满心欢喜的等待着服务恢复正常。然而这次没有看到成功的提示，异常不断各服务连接zookeeper都失败了。这时真的是郁闷了，空间明明已经是充足的。异常信息如下：\n1 2 3 2017-05-15 11:02:24,421 - INFO [main:FileSnap@83] - Reading snapshot /hadoop/zookeeper/version-2/snapshot.5ff3bc 2017-05-15 11:02:26,492 - ERROR [main:Util@239] - Last transaction was partial. 2017-05-15 11:02:26,494 - ERROR [main:QuorumPeer@530] - Unable to load database on disk 网上一阵搜索，期待可以找到相关的案例分享，案例倒是找到了不过，那些只是遇到问题并没有完全解决， 案例如下：\nZOOKEEPER-1621 数据文件读取异常 此时真是有点无语了，在着手查看zookeeper的源码时，同时切换成百度搜索引擎查找案例(大家都比较喜欢用Google，你懂的)，没想到还真的找到解决办法了，网友分享的案例：\nZooKeeper启动报错Last transaction was partial. 解决方法 1 2 3 4 5 6 7 8 原文如下： ZooKeeper 在硬盘满后，无法再次启动，抛出Last transaction was partial. Bug见：https://issues.apache.org/jira/browse/ZOOKEEPER-1621 首先我的环境是单节点，ZooKeeper的版本是3.4.8。 因为是单节点，ZooKeeper无法启动影响非常大，多节点也有可能出现同时硬盘都写满的情况，如果问题在线上发生，后果不堪设想。 折腾了一下，发现，把ZooKeeper安装目录下的data/log/version-2下的，大小为0（异常的）日志，删除掉后，再重启 ，问题解决！ 检查了一下对应的目录就真的发现了一个大小为0的log文件，删除然后启动zookeeper， OK输出日志正常，通过zookeeper client连接查看数据恢复正常。终于悬着的心可以放下来了，不过之前那个zookeeper莫名的消失问题还是没有找到原因。此次的经验教训就是以后类似这些重要的目录一定要做热备份，在大数据环境中zookeeper的生要性可想而知，还好此次是有惊无险。\n","date":"2017-05-15T12:34:21+00:00","updated":"2017-05-15T12:34:21+00:00"},{"permalink":"/tech/offline-install-hdp-ambari-notes.html","title":"离线安装HDP2.6(1)-Ambari Server","content":"1.参考文档 FYI: HDP Install Documents HDP Install Manual 2. 硬件环境 首先是要准备3台机器,安装最新的CentOS7.2，机器的配置参考要求如下：\nCPU Memory Disk Remark 4核 26G 200G 主节点/1台 4核 16G 200G 从节点/2台 3. HDP安装文件 下载离线安装的文件：\nFile Name Download Link ambari-2.5.0.3 http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3/ambari-2.5.0.3-centos7.tar.gz HDP-2.6.0.3 http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/HDP-2.6.0.3-centos7-rpm.tar.gz HDP-UTILS-1.1.0.21 http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz 4. SSH免密登录 配置免密码登录，注意这里主要是指master机器登录到其它cluster机器。所以最好先给机器指定好特定的hostname标识分开，参考如下：\nIP Host Name 192.168.1.1 test-hdp-master01 192.168.1.2 test-hdp-cluster01 192.168.1.3 test-hdp-cluster02 需要注意一点是，在CentOS7中过修改 /etc/hosts 文件已经无法实现机器名称的修改，需要使用新的命令： hostnamectl set-hostname test-hdp-master01\n然后在master机器上使用ssh-keygen -t RSA 密令生成SSH密钥，再使用命令 ssh-copy-id -i ~/.ssh/id_rsa.pub root@test-hdp-cluster01 拷贝到其它两台cluster机器，最后使用SSH登录命令检查是否安装成功，同时把hostname，IP地址写入到每台机器的/etc/hosts文件里面。\n5. 时间同步 安装NTP服务 （ 参考 )\n在Master机器上执行以下的命令安装并启动ntpd服务：\n1 2 3 yum install ntp -y systemctl start ntpd 修改配置文件，允许同网段下面的机器同步时间。\n1 2 3 4 5 6 vi /etc/ntp.conf # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # 找到这段配置，改写成如下的配置 restrict 192.168.51.0 mask 255.255.255.0 nomodify 在其它两台Cluster机器安装NTP客户端，执行命令如下：\n1 2 3 4 5 6 7 8 yum install ntpdate -y crontab -e # 每分钟同步一次 */1 * * * * ntpdate -u 192.168.51.21 \u0026amp;\u0026amp; hwclock -w systemctl start crond.service 6. 配置YUM镜像 6.1 解压文件 将第2步中下载的三个文件解压\n注意 HDP-UTIL是没根目录的，所以最好创建一个目录，解压好的目录结构如下：\n1 2 3 4 5 6 7 8 [root@test-hdp-master01 hdp-download]# ll total 8676352 drwxr-xr-x 3 root root 20 Apr 25 16:03 ambari -rw-r--r-- 1 root root 1657013486 Apr 6 11:14 ambari-2.5.0.3-centos7.tar.gz drwxr-xr-x 3 1001 users 20 Apr 3 08:58 HDP -rw-r--r-- 1 root root 6356134913 Apr 3 09:25 HDP-2.6.0.3-centos7-rpm.tar.gz drwxr-xr-x 21 root root 4096 Apr 25 16:16 HDP-UTILS -rw-r--r-- 1 root root 871424874 Mar 31 03:11 HDP-UTILS-1.1.0.21-centos7.tar.gz 6.2 启动HTTP服务 启动HTTPServer服务，这里不用安装Apache直接用下面的Python命令启动即可：\n1 python -m SimpleHTTPServer 88 6.3 修改Repo文件 找到6.1解压目录下面的ambari.repo与hdp.repo文件，将里面的baseurl,gpgkey更新为本地HTTP服务地址即可，如下：\nambari.repo\n1 2 3 4 5 6 7 8 9 10 #VERSION_NUMBER=2.5.0.3-7 [ambari-2.5.0.3] name=ambari Version - ambari-2.5.0.3 # baseurl=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3 baseurl=http://192.168.51.21:88/ambari/centos7 gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.51.21:88/ambari/centos7/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 hdp.repo\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #VERSION_NUMBER=2.6.0.3-8 [HDP-2.6.0.3] name=HDP Version - HDP-2.6.0.3 # baseurl=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3 baseurl=http://192.168.1.1:88/HDP/centos7 gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.1.1:88/HDP/centos7/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 [HDP-UTILS-1.1.0.21] name=HDP-UTILS Version - HDP-UTILS-1.1.0.21 # baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7 baseurl=http://192.168.1.1:88/HDP-UTILS gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.1.1:88/HDP-UTILS/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 6.3 安装ambari-server 在Master机器上安装ambari-server服务\n1 yum install ambari-server 7. 配置JDK环境 将下载好的JDK压缩包解压到/user/share/jdk目录下，然后再编辑/etc/profile文件在末尾加入下面的代码：\n1 2 3 export JAVA_HOME=/usr/share/jdk/jdk1.8.0_131 export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar export PATH=$JAVA_HOME/bin:$PATH 最后命令source /etc/profile编绎一下文件即可，在其它两台Cluster上面重复此操作，记得用java -version验证是否安装成功。\n8. 安装MySQL数据库 参考 下载mysql源安装包并安装\n1 2 3 4 5 6 7 8 9 10 11 12 wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm yum localinstall mysql57-community-release-el7-8.noarch.rpm #检查mysql源是否安装成功 yum repolist enabled | grep \u0026#34;mysql.*-community.*\u0026#34; mysql-connectors-community/x86_64 MySQL Connectors Community 33 mysql-tools-community/x86_64 MySQL Tools Community 47 mysql57-community/x86_64 MySQL 5.7 Community Server 187 yum install mysql-community-server -y 在安装日志找到默认密码并修改\n1 2 3 4 5 6 7 8 9 10 11 grep \u0026#39;temporary password\u0026#39; /var/log/mysqld.log 2017-04-25T23:51:03.380340Z 1 [Note] A temporary password is generated for root@localhost: dCAdHOM+H4z% ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;dCAdHOM+H4zz%\u0026#39;; UPDATE user SET host=\u0026#39;%\u0026#39; WHERE user=\u0026#39;root\u0026#39;; CREATE USER \u0026#39;ambari\u0026#39;@\u0026#39;192.168.51.%\u0026#39; IDENTIFIED BY \u0026#39;1wVhZ7nd@T\u0026#39;; GRANT ALL PRIVILEGES ON hive.* TO \u0026#39;hive\u0026#39;@\u0026#39;192.168.51.%\u0026#39; IDENTIFIED BY \u0026#39;1wVhZ7nd@T\u0026#39; FLUSH PRIVILEGES; 修改默认字符集\n1 2 3 4 5 vi /etc/my.cnf # 在mysqld选项下面增加 character_set_server=utf8 init_connect=\u0026#39;SET NAMES utf8\u0026#39; 设置开机启动\n1 2 3 4 5 systemctl enable mysqld systemctl daemon-reload #启动mysql systemctl start mysqld 9. 安装mysql connector jar文件 1 2 3 4 yum install yum-utils yumdownloader mysql-connector-java rpm -ivh mysql-connector-java-5.1.25-3.el7.noarch.rpm --force --nodeps ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 10. 设置Ambari Server Setup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [root@test-hdp-master01 hdp-download]# ambari-server setup -j /usr/share/jdk/jdk1.8.0_131 Using python /usr/bin/python Setup ambari-server Checking SELinux... SELinux status is \u0026#39;disabled\u0026#39; Customize user account for ambari-server daemon [y/n](n)? y Enter user account for ambari-server daemon (root): Adjusting ambari-server permissions and ownership... Checking firewall status... Checking JDK... WARNING: JAVA_HOME /usr/share/jdk/jdk1.8.0_131 must be valid on ALL hosts WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts. Completing setup... Configuring database... Enter advanced database configuration [y/n](n)? y Configuring database... ============================================================================== Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL / MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere [7] - BDB ============================================================================== Enter choice (3): 3 Hostname (localhost): test-hdp-master01 Port (3306): Database name (ambari): Username (ambari): Enter Database Password (sDgu-5H1sW): Configuring ambari database... Copying JDBC drivers to server resources... Configuring remote database connection properties... WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql Proceed with configuring remote database connection properties [y/n](y)? y Extracting system views... ............ Adjusting ambari-server permissions and ownership... Ambari Server \u0026#39;setup\u0026#39; completed successfully. 注意在选择数据库会要输入数据库名，用户名，密码等信息，请保存好这些信息，后面在创建数据库时有用的\n11. 创建元数据库 1 2 3 4 5 6 7 8 CREATE DATABASE `ambari` CHARACTER SET utf8 COLLATE utf8_general_ci; CREATE USER \u0026#39;ambari\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;sDgu-5H1sW\u0026#39; GRANT USAGE ON `ambari`.* TO \u0026#39;ambari\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;sDgu-5H1sW\u0026#39; FLUSH PRIVILEGES; USE \u0026#39;ambari\u0026#39; GO; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql 12. 启动Ambari Server 使用命令ambari-server start启动，然后打开浏览器输入http://192.168.1.1:8080/，便可以看到Ambari的登录界面，输入默认用户密码登录，接着就可以安装Hadoop组件服务啦。\n13. 安装过程中的问题记录 13.1 HostName指定问题 在这个过程中，如果会出现ambari-server的hostname无法指定，目前通过直接改写代码实现。\n1 2 3 4 vi /usr/lib/python2.6/site-packages/ambari_server/setupAgent.py # 把315行代码更新如下 # hostname = args[2] hostname = \u0026#34;test-hdp-master01\u0026#34; 13.2 MySQL连接失败 在安装时测试MySQL连接失败，与上次面的问题差不多，也只能是修改下代码：\n1 2 3 4 5 # 注意这里指你安装Hive, oozie服务的机器 vi /var/lib/ambari-agent/cache/custom_actions/scripts/check_host.py # 把279行代码更新如下 # jdk_location = config[\u0026#39;commandParams\u0026#39;][\u0026#39;jdk_location\u0026#39;] jdk_location = \u0026#39;http://\u0026#39; + ambari_server_hostname + \u0026#39;:8080/resources/\u0026#39; 在安装各个服务时如果提示无法下载文件，那么也要修改代码，这边主要是发现Hive的安装会出现：\n1 2 3 4 5 # 注意这里指你安装Hive服务的机器 vi /usr/lib/python2.6/site-packages/resource_management/core/source.py # 把169行的代码更新如下： # self.url = self.name self.url = self.name.replace(\u0026#39;localhost\u0026#39;,\u0026#39;test-hdp-master01\u0026#39;) 14. 卸载HDP服务 参考官方文档： Uninstall ","date":"2017-04-17T19:52:31+00:00","updated":"2017-04-17T19:52:31+00:00"},{"permalink":"/tech/ssh-login-without-password.html","title":"Linux使用SSH免密码登录","content":"现在分布式集群非常的流行, 经常在不同的机器上面切换来回那是家常便饭. 如果每次切换都需要输入用户名与密码, 那就是要崩溃的节奏啊. 好在SSH-KEY给我们提供了便利, 只要在master生成一个PUB_KEY, 然后拷贝到clusters中, 以后便可以直接使用ssh hostname即能快速,方便的切换到需要操作的机器上面.\n先说下机器的环境:\n2台服务器均为Centos 6.7 x86_64 系统\n主节点master, IP地址: 192.168.8.200\n从节点cluster01, IP地址: 192.168.8.201\n下面首先在主节点上生成一个SSH-KEY, 在终端输入ssh-keygen -t rsa, 这里使用默认的存放的目录, 无密码, 连续按2次回车键即可, 如下图所示:\n然后将生成的PUB_KEY文件, 使用cat管道命令输出名称为authorized_keys的文件, 再用scp命令拷贝一份到节点服务器上面(此时是要输入密码的), 如下图所示:\n如无法执行scp命令, 请执行安装命令: yum install -y openssh-clients\n登录节点服务器, 在用户根目录下执行下面的命令:\n1 2 3 chmod 700 .ssh/ chmod 600 .ssh/authorized_keys 那么到这一步我们便可以实现SSH免密码登录的功能. 回到主节点服务器, 用ssh hostname就可以切换到想到操作的节点机器上面, Good Luck.\n注意:\nauthorized_keys 文件一定要在主节点服务器上生成, 不然是无效的, 即拷贝了PUB_KEY文件到节点服务器也仍是需要密码登录.\n如果是比较新的sshd, 可以用ssh-copy-id hostname的命令快捷的实现上面的步骤, 不过记得要先安装openssh-clients.\n参考:\nLinux下SSH免密码登录 Linux教程:SSH免密码登录的方法 ssh设置免密码登陆仍然需要密码 SSH免密码登录详解 原理:\n为了更好的理解SSH免密码登录原理，我们先来说说SSH的安全验证，SSH采用的是”非对称密钥系统”，即耳熟能详的公钥私钥加密系统，其安全验证又分为两种级别。\n基于口令的安全验证 这种方式使用用户名密码进行联机登录，一般情况下我们使用的都是这种方式。整个过程大致如下：\u0026raquo; （1）客户端发起连接请求。\n（2）远程主机收到用户的登录请求，把自己的公钥发给客户端。\n（3）客户端接收远程主机的公钥，然后使用远程主机的公钥加密登录密码，紧接着将加密后的登录密码连同自己的公钥一并发送给远程主机。\n（4）远程主机接收客户端的公钥及加密后的登录密码，用自己的私钥解密收到的登录密码，如果密码正确则允许登录，到此为止双方彼此拥有了对方的公钥，开始双向加密解密。\nPS：当网络中有另一台冒牌服务器冒充远程主机时，客户端的连接请求被服务器B拦截，服务器B将自己的公钥发送给客户端，客户端就会将密码加密后发送给冒牌服务器，冒牌服务器就可以拿自己的私钥获取到密码，然后为所欲为。因此当第一次链接远程主机时，在上述步骤的第（3）步中，会提示您当前远程主机的”公钥指纹”，以确认远程主机是否是正版的远程主机，如果选择继续后就可以输入密码进行登录了，当远程的主机接受以后，该台服务器的公钥就会保存到 ~/.ssh/known_hosts文件中。\n基于密匙的安全验证 这种方式你需要在当前用户家目录下为自己创建一对密匙，并把公匙放在需要登录的服务器上。当你要连接到服务器上时，客户端就会向服务器请求使用密匙进行安全验证。服务器收到请求之后，会在该服务器上你所请求登录的用户的家目录下寻找你的公匙，然后与你发送过来的公匙进行比较。如果两个密匙一致，服务器就用该公匙加密“质询”并把它发送给客户端。客户端收到“质询”之后用自己的私匙解密再把它发送给服务器。与第一种级别相比，第二种级别不需要在网络上传送口令。\nPS：简单来说，就是将客户端的公钥放到服务器上，那么客户端就可以免密码登录服务器了，那么客户端的公钥应该放到服务器上哪个地方呢？默认为你要登录的用户的家目录下的 .ssh 目录下的 authorized_keys 文件中（即：~/.ssh/authorized_keys）。\n","date":"2016-05-29T12:34:21+00:00","updated":"2016-05-29T12:34:21+00:00"},{"permalink":"/tech/git-commands-collect.html","title":"Git 操作命令收集","content":"都说好性不如烂笔头, 一点也没有错呀. 虽然学习Git已经有1个多年头, 但是有些时候那比较少用的命令总是一时想不起来.所以还是决定把它写到blog里面, 不仅把经验分享出去, 而且也便于自己查找, 此博文会持续累加.\nGit命令别名(非常实用) 1 git config --global alias.co checkout 解读: 用co替代checkout, 除此之外, 还可以把一些组合的命令用别名设置, 例如:\nAlias Name Description co checkout ci commit br brach l log \u0026ndash;oneline 回退到首次提交(估计很少人会遇到) 1 git update-ref -d HEAD Tag操作\n查看标签\n1 git tag -l 创建标签 1 git tag -a 1.0.1-Release -m \u0026#34;Release 1.0.1 version\u0026#34; 删除标签 1 git tag -d 1.0.1-Release 远程推送 1 git push --tag 远程删除 1 git push origin :refs/tags/1.0.1-Release Git学习推荐:\n廖雪峰-Git教程 ","date":"2016-01-29T12:34:21+00:00","updated":"2016-01-29T12:34:21+00:00"},{"permalink":"/tech/mpsdk4j-intro-mapaccount.html","title":"mpsdk4j的点滴记录--MPAccount","content":"mpsdk4j是在实际的生产项目中抽离出来的开源分享项目,它的成长至今也算是有不少的经历吧, 最近一直忙于工作与生活上的事情疏忽了对它的关心. 自去年下决心对它重构并建立了QQ交流群( 486192816 )后, 逐渐的有不业界朋友前来关注, 在此非常感谢他们的支持. 都说用过方知其好, 可实际情况确不是这么乐观呀,在大家的使用过程中发现mpsdk4j有不少欠缺与不足的地方. 之前一直想在元旦发布的2.b.1版本也拖延至今还没有交工, 在此对大家说声抱歉, 以后定会嘉勉.下面还是先进入此次的主题\u0026ndash;初识mpsdk4j之MPAccount. (注: 对于有微信开发基础与项目经验的可略过)\nmpsdk4j自发布之时起的目标就是要做到原生态,简单易用. 不过在实际的交流过程中发现一个普遍的现象, 就是对初次接触微信开发的朋友来说,mpsdk4j的使用还是有点难(这也是为何要写这一篇博文的原因之一). 那么接下来我们就先简单的认识下微信公众平台开的所需要的元素, 以及它们与mpsdk4j之的映射关系.\n微信公众号属性 序号 属性 示例 备注 1 公众号原始ID gh_20e50b3b4r9u 以gh_开头的(不明白其含义) 2 公众号昵称 mpsdk4j 用户自定义的公众号别名 3 用户唯一凭证(应用ID) wxa822bd879532187 以字母wx开头的,其含义大概是微信的拼音首字母 4 用户唯一凭证密钥(应用密钥) 613d3ce897hgf71a875d1342c8325f3d 32位的随机字符串 5 AES 加解密密钥 JwAsfZH4p9iuuvfxjry6cLtlOgZAd853kJQ5hNv5OI4 43位的随机字符串 6 开发者服务令牌 weixindev 用户接入微信开发者服务时的自定义令牌 7 公众号类型 S D: 订阅号, S: 服务号, E: 企业号 (预留字段) 8 是否认证 true true: 通过认证, false: 未通过认证 (同上也是预留字段) mpsdk4j中的代码映射关系 那么在mpsdk4j中我设计了一个对象, 位于io.github.elkan1788.mpsdk4j.vo包中其名字叫MPAccount, 直译过来是微信公众号的意思. 它将上面的8个公众号属性对应的代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 /** * 微信公众号信息 * * @author 凡梦星尘(elkan1788@gmail.com) * @since 2.0 */ public class MPAccount { /** * 公众号原始ID */ private String mpId; /** * 公众号昵称 */ private String nickName; /** * 应用Id */ private String appId; /** * 应用密钥 */ private String appSecret; /** * 令牌 */ private String token; /** * AES安全加密密钥 */ private String AESKey; /** * 公众号类型 * D:订阅号 * E:企业号 * S:服务号 */ private String mpType; /** * 是否认证 */ private boolean pass; ...... } 有过微信开发经验的朋友, 都不难看出这些属性都是微信公众号必备的, 前面6个属性是可以微信公众号管理平台上直观的看到, 后面2个属性是从中经验中吸取提炼出来的, 在后面的许多开发中有使用的需求. 比如在调用微信的语音识别接口时就是得先了解当前公众号是否通过认证, 只有认证成功的公众号才有权限使用语音识别接口. 在实际的项目经验中, 你直接把此类设计成一个数据库表用来管理微信公众号信息.\n或许你会觉得看完这些文章并没有太大的收获, 那不要紧, 你可以把它收藏起来, 当作是文档工具使用. 哪天你在开发的时候不记得了其中某个属性的含义, 可以倒回头来再拾起. 如有更好的建议或是意见, 可以在下面回复.\n参考:\n接入指南 消息加密 ","date":"2016-01-23T16:08:32+00:00","updated":"2016-01-23T16:08:32+00:00"},{"permalink":"/tech/mapdb-write-read-sync.html","title":"MapDB 同步读写示例","content":"MapDB 是一个快速、易用的嵌入式Java数据库引擎. 最主要的特点之一就是支持磁盘存储,直接把内存中的Hash Map同步写入到磁盘. 另外特别惊喜的是它支持ACID事务,MVCC隔离, 且有全职的开发者支持.\n看完官方的文档与示例后,基本上可以确定它符合业务场景的使用要求.另外发现官方正在重构3.x的版本, 但应该不会这么快发布吧.用google搜索了下关于MapDB的使用案例, 也不是很多. 可能是本来官方的文档就齐全有关吧,API也不复杂,跟着官方的文档走一遍就可以上手了.\n动手测试了简单的示例后, 突然冒出一个疑问, 如何实现同时操作磁盘上的一个数据库, 以及同一个HashMap呢? 这里需要明白的, MapDB存储到磁盘上的数据库文件,并非只是存放了一个HashMap, 这有点类似数据库里可以有多张表的概念相同. 那么数据库是可以支持多连接的, MapDB是否也同样支持呢?(理想确实很丰满,但现实太骨感了!)\n初步检验的结果是, MapDB并不支持同时访问磁盘上的同一文件. 那么也就是只能创建一个长连接, 直到业务功能处理完成再关闭它. 幸运的是它支持对已经存在或是运行中的同一个HashMap进行读写操作. 下面来看看简单的示例代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 import org.mapdb.BTreeMap; import org.mapdb.DB; import org.mapdb.DBMaker; import org.testng.annotations.AfterTest; import org.testng.annotations.BeforeTest; import org.testng.annotations.Test; import java.io.File; import java.util.Map; import java.util.Random; import java.util.SortedMap; import static org.testng.Assert.*; /** * MapDB 测试 * * @author 凡梦星尘(elkan1788@gmail.com) * @since 2016.1.19 */ public class MapDBTest { private DB diskDB; Map\u0026lt;Integer, String\u0026gt; data; @BeforeTest public void init() { // 文件名字可以自己定义 File dbFile = new File(\u0026#34;D:/mapdb.data\u0026#34;); // DB有且只打开一次连接 diskDB = DBMaker.fileDB(dbFile) // 很是好奇,关闭锁定,还是不支持多事务访问同一个数据库文件 .fileLockDisable() // 最好开启,在程度异常或JVM关闭可正常关闭数据库 // 有过一次无法访问未关闭数据库文件的异常 .closeOnJvmShutdown() // 如果不需要回滚的可以关闭,提高读写效率 .transactionDisable() // 这里测试所没不保留磁盘文件 .deleteFilesAfterClose() // 这里没有找到读取的API,或者就是不支持多连接的吧 .make(); } @AfterTest public void destroy() { assertTrue(!data.isEmpty()); // 本应该是99才对,但会合并内存中其它数据 Map\u0026lt;Integer, String\u0026gt; temp = diskDB.treeMap(\u0026#34;sort_mapdb\u0026#34;); assertEquals(temp.size(), 100); // 这里需要注意下,有可能make成功的数据库也是关闭的 // 如果不做检查的话,可能抛出:IllegalAccessError(\u0026#34;DB was already closed\u0026#34;) if (diskDB.isClosed()) { diskDB.isClosed(); } } @Test(invocationCount = 10) public void testSyncWrite() throws Exception { // 支持多种类型Map,如B+ tree, sort等等 // 但value貌似支持引用类型, 不支持Object, 可能是 // 跟序列化到磁盘存储有关 data = diskDB.treeMapCreate(\u0026#34;nice_mapdb\u0026#34;) // 开启快速计数器 .counterEnable() // 这步很关键,如果不带get,那么就只是make,无法支持多连接 .makeOrGet(); int len = 99; int ran = new Random().nextInt(100)+1; while (--len \u0026gt;= 0) { data.put(len * ran, \u0026#34;value-\u0026#34;+len * ran); } assertFalse(data.isEmpty()); } @Test(invocationCount = 10) public void testReadAndDel() throws Exception { data = diskDB.treeMapCreate(\u0026#34;nice_mapdb\u0026#34;) .counterEnable() .makeOrGet(); if (!data.isEmpty()) { for (Integer key : data.keySet()) { if (key % 2 == 0 || key % 5 == 0) { data.remove(key); } } assertTrue(data.size() \u0026gt; 0); } } @Test public void testOtherMap() throws Exception { SortedMap\u0026lt;Integer, String\u0026gt; data = diskDB.treeMapCreate(\u0026#34;sort_mapdb\u0026#34;) .counterEnable() .makeOrGet(); int len = 99; while (--len \u0026gt;= 0) { data.put(len, \u0026#34;sorted-\u0026#34;+len); } assertNotNull(data); // 创建另一个map BTreeMap\u0026lt;Integer, String\u0026gt; btree = diskDB.treeMapCreate(\u0026#34;sort_mapdb2\u0026#34;) .counterEnable() .makeOrGet(); // 很是奇怪, 为何这里的name没有效果, 会自动合并到同时一时内存所有treeMap中 SortedMap\u0026lt;Integer, String\u0026gt; tree = diskDB.treeMap(\u0026#34;sort_mapdb1\u0026#34;); tree.put(100, \u0026#34;sorted-100\u0026#34;); btree.put(100, \u0026#34;sorted-101\u0026#34;); assertEquals(tree.get(100), \u0026#34;sorted-100\u0026#34;); assertEquals(data.get(100), \u0026#34;sorted-100\u0026#34;); } } 在这里没有详细的探讨关于MapDB是如何实现与磁盘持久化同步, 直接使用官方默认的值, 当然你也可以自己配置读写同步的心跳时间间隔. 在测试的过程观察发现, MapDB在创建磁盘的数据库文件时, 初始化大小写为2MB, 然后在同步内存数据时, 会先产生出一个临时文件, 当这个临时文件达到一定大小时就会合并到主体数据库文件. 至于其它的功能和代码中的疑问, 有待继续观察, 欢迎共同交流.\n参考资料:\nMapDB 官网 官方示例 MapDB实现分析 ","date":"2016-01-19T21:11:20+00:00","updated":"2016-01-19T21:11:20+00:00"},{"permalink":"/tech/redis-install-settings.html","title":"Redis 安装与配置","content":"Redis 是一款依据BSD开源协议发行的高性能Key-Value存储系统（cache and store）。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。 更多介绍 系统环境: Linux 3.10.0-229.el7.x86_64 x86_64 x86_64 x86_64 GNU/Linux(Centos7.1)\n1.下载\n1 2 $ wget http://download.redis.io/releases/redis-3.0.1.tar.gz 解压安装 1 2 3 4 $ tar -zxf redis-3.0.1.tar.gz $ cd ./redis-3.0.1 $ make \u0026amp;\u0026amp; make install 配置Redis服务 1 2 3 4 $ cp ./redis-3.0.1/utils/redis_init_script /etc/rc.d/init.d/redis $ mkdir P /etc/redis $ cp ./redis-3.0.1/redis.conf /etc/reddis/6379.conf 启动Redis 1 2 3 4 $ service redis start $ ps -ef|grep redis $ root 8687 1 0 12:06 ? 00:00:00 /usr/local/bin/redis-server *:6379 redis.conf参数说明 daemonize：是否以后台daemon方式运行\npidfile：pid文件位置\nport：监听的端口号\ntimeout：请求超时时间\nloglevel：log信息级别\nlogfile：log文件位置\ndatabases：开启数据库的数量\nsave * ：保存快照的频率，第一个表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。\nrdbcompression：是否使用压缩\ndbfilename：数据快照文件名（只是文件名，不包括目录）\ndir：数据快照的保存目录（这个是目录）\nappendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。\nappendfsync：appendonlylog如何同步到磁盘（三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步）\n","date":"2015-06-29T12:34:21+00:00","updated":"2015-06-29T12:34:21+00:00"},{"permalink":"/tech/nutz-jdoc-chinese.html","title":"Nutz源码Jdoc在IDE中补全提示时出现乱码解决办法","content":"接触Nutz也有一段时间，随着对它使用的不断深入了解，才越发觉它的强悍与作者的设计巧妙，特别喜欢它那个JUnit测试报告，而且更新的速度也挺快的，到现在的1.b.44版本，ssh所拥有的功能可以说它也已经完全具备了。对于程序员来说学习一种新技术最快捷的办法就是Demo+API，这两样也是必备之需哪。Nutz在这方面做的也是相当的不错，比如在Demo方面有人贡献出了整个CMS的源码(非常感谢作者的分享哪，从里面学习了不少知识)，API方面提供了常见的CHM格式和JAR包。不过这个JAR的API在实现应用中却是出了点小问题，下面就来详细说说。\n我的开发环境：\n操作系统：Window7\nJava虚拟机：JDK1.7\nIDE工具：Netbeans7.1\n项目编码格式：UTF-8\n用Netbeans创建一个简单的WEB工程，把从GOOGLE CODE下载来的Nutz相关文件里面抽取出开发所必须的创建了一个新的库引用，这些操作和显示都正常，但当用代码自动补全时，发现了个问题，代码补全出来的JDOC居然是乱码的，如下图所示：\n咦，这是怎么回事呢？？重新检查了自己的工程编码属性，确定是UTF-8没有错哪，如下图所示：\n试着打开源码查看，却是得到提示信息说“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？”\n难道说Nutz生成JDOC时使用的是GBK编码来的，看来只好连接GitHub库下载个库看看。下载下来查看工程的编码格式也是UTF-8，这就奇怪了\u0026ndash;乱码从何产生呢？？看来只好自己生成个JDOC看看了，在UTF-8环境中生成JDOC要注意编码格式的设置，如下图所示，\n生成好JDOC后，直接修改Netbeans库的源码和JDOC连接，打开创建的工程使用代码自动补全提示一切正常.\n问题算是解决了，不过引起这个问题的原因还真得思考下，编码格式的不同所造成的影响还真是郁闷哪。上面提到在没有修改前打开源码提示信息“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？” 按照信息所描述是不是将Nutz的源码修改成GBK编码格式也可以呢？于是写了个编码格式轮换输出小程序测试了下，结果说明猜想是正确的，呵~\n其实这个小程序不单只是可以转换Nutz的源码，它还可以转换任何项目的编码格式(仅支持JAVA文件)，注意是由UTF-8转换成GBK编码格式哦，那么接下来就慢慢体验下Nutz给你所带来的“美妙体验”吧，呵~\nPS: 示例源下载 ","date":"2012-04-20T19:11:20+00:00","updated":"2012-04-20T19:11:20+00:00"},{"permalink":"/tech/java-hard-rsr232.html","title":"Java程序与RSR232串口通讯小练手","content":"一直以来都是在学习J2EE方面的应用系统开发，从未想过用JAVA来编写硬件交互程序，不过自己就是喜欢尝试一些未曾接触的新东西。在网上搜索了些资源，了解到JAVA写串口通讯的还是蛮多的，那么便着手准备开发调试环境。软件程序开发环境搭建不成问题，可这硬件环境就有点犯难啦。更何况自己用的是笔记本哪来的串口呀，再说要是真拿这串口硬件来自己也不会弄，随即想到了虚拟机，觉得这东西应该也有虚拟的吧，果真跟自己的猜测一样还真有这东西，顺便也下载了个串口小助手做为调试之用。\n下面就先看看软件环境的搭建：\n下载comm.jar、win32com.dll和javax.comm.properties。 (附件提供下载) 介绍：comm.jar提供了通讯用的java API，win32com.dll提供了供comm.jar调用的本地驱动接口，javax.comm.properties是这个驱动的类配置文件 拷贝javacomm.jar到X:\\jre\\lib\\ext目录下面; 拷贝javax.comm.properties到X:\\jre\\lib目录下面; 拷贝win32com.dll到X:\\jre\\bin目录下面; 更新下IDE里面的JDK环境，如下图： 接着是硬件虚拟环境安装虚拟串口，这里我用的是VSPD6.0(附件提供下载)，安装好后启动VSPD添加我们所需要的端口，注意这里是按组的方式添加的，例如COM1和COM2是一组同时添加，以此类推。\n所有环境都准备好后，先来简单认识下comm.jar的内容。单从comm API的javadoc来看，SUM提供给我们的只有区区以下13个类或接口，具体如下：\n1 2 3 4 5 6 7 8 9 10 javax.comm.CommDriver javax.comm.CommPort javax.comm.ParallelPort javax.comm.SerialPort javax.comm.CommPortIdentifier javax.comm.CommPortOwnershipListener javax.comm.ParallelPortEvent javax.comm.SerialPortEvent javax.comm.ParallelPortEventListener (extends java.util.EventListener) javax.comm.SerialPortEventListener (extends java.util.EventListener) javax.comm.NoSuchPortException javax.comm.PortInUseException javax.comm.UnsupportedCommOperationException 这些类和接口命名一看便知其意，就不做一一介绍啦，可以到官网或网上找到更详细的信息。下面先测试下所搭建的环境是否可用，主要代码如下：\n1 2 3 4 5 6 7 8 9 10 Enumeration\u0026lt;?\u0026gt; en = CommPortIdentifier.getPortIdentifiers(); CommPortIdentifier portId; while (en.hasMoreElements()) { portId = (CommPortIdentifier) en.nextElement(); // 如果端口类型是串口，则打印出其端口信息 if (portId.getPortType() == CommPortIdentifier.PORT_SERIAL) { System.out.println(portId.getName()); } } 运行代码后，控制台有输出正确的端口(如下图)，说明所有环境正常可进行下步工作，否则请检查。\n最后要解决的就是与串口数据交互的问题。在这个问题上，最主要的难点就是数据读取，因为我们不知道端口什么时候会有数据到来，也不知数据长度如何。通常，串口通信应用程序有两种模式，一种是实现SerialPortEventListener接口，监听各种串口事件并作相应处理；另一种就是建立一个独立的接收线程专门负责数据的接收。参考众多老前辈的代码后，下面就采用第一种方式写了个简单的助手程序，具体的实现请看详细代码，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 package com.elkan1788.view; import java.awt.BorderLayout; import java.awt.Button; import java.awt.Color; import java.awt.Font; import java.awt.GridLayout; import java.awt.Image; import java.awt.TextArea; import java.awt.TextField; import java.awt.event.ActionEvent; import java.awt.event.ActionListener; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.util.ArrayList; import java.util.Enumeration; import java.util.List; import java.util.TooManyListenersException; import javax.comm.CommPortIdentifier; import javax.comm.NoSuchPortException; import javax.comm.PortInUseException; import javax.comm.SerialPort; import javax.comm.SerialPortEvent; import javax.comm.SerialPortEventListener; import javax.comm.UnsupportedCommOperationException; import javax.imageio.ImageIO; import javax.swing.JComboBox; import javax.swing.JFrame; import javax.swing.JLabel; import javax.swing.JOptionPane; import javax.swing.JPanel; import javax.swing.SwingConstants; import javax.swing.border.EmptyBorder; public class JavaRs232 extends JFrame implements ActionListener, SerialPortEventListener { /** * JDK Serial Version UID */ private static final long serialVersionUID = -7270865686330790103L; protected int WIN_WIDTH = 380; protected int WIN_HEIGHT = 300; private JComboBox\u0026lt;?\u0026gt; portCombox, rateCombox, dataCombox, stopCombox, parityCombox; private Button openPortBtn, closePortBtn, sendMsgBtn; private TextField sendTf; private TextArea readTa; private JLabel statusLb; private String portname, rate, data, stop, parity; protected CommPortIdentifier portId; protected Enumeration\u0026lt;?\u0026gt; ports; protected List\u0026lt;String\u0026gt; portList; protected SerialPort serialPort; protected OutputStream outputStream = null; protected InputStream inputStream = null; protected String mesg; protected int sendCount, reciveCount; /** * 默认构造函数 */ public JavaRs232() { super(\u0026#34;Java RS-232串口通信测试程序 凡梦星尘\u0026#34;); setSize(WIN_WIDTH, WIN_HEIGHT); setLocationRelativeTo(null); Image icon = null; try { icon = ImageIO.read(JavaRs232.class.getResourceAsStream(\u0026#34;/res/rs232.png\u0026#34;)); } catch (IOException e) { showErrMesgbox(e.getMessage()); } setIconImage(icon); setResizable(false); scanPorts(); initComponents(); setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); setVisible(true); } /** * 初始化各UI组件 * @since 2012-3-22 下午11:56:39 */ public void initComponents() { // 共用常量 Font lbFont = new Font(\u0026#34;微软雅黑\u0026#34;, Font.TRUETYPE_FONT, 14); // 创建左边面板 JPanel northPane = new JPanel(); northPane.setLayout(new GridLayout(1, 1)); // 设置左边面板各组件 JPanel leftPane = new JPanel(); leftPane.setOpaque(false); leftPane.setLayout(new GridLayout(3,2)); JLabel portnameLb = new JLabel(\u0026#34;串口号：\u0026#34;); portnameLb.setFont(lbFont); portnameLb.setHorizontalAlignment(SwingConstants.RIGHT); portCombox = new JComboBox\u0026lt;String\u0026gt;((String [])portList.toArray(new String[0])); portCombox.addActionListener(this); JLabel databitsLb = new JLabel(\u0026#34;数据位：\u0026#34;); databitsLb.setFont(lbFont); databitsLb.setHorizontalAlignment(SwingConstants.RIGHT); dataCombox = new JComboBox\u0026lt;Integer\u0026gt;(new Integer[]{5, 6, 7, 8}); dataCombox.setSelectedIndex(3); dataCombox.addActionListener(this); JLabel parityLb = new JLabel(\u0026#34;校验位：\u0026#34;); parityLb.setFont(lbFont); parityLb.setHorizontalAlignment(SwingConstants.RIGHT); parityCombox = new JComboBox\u0026lt;String\u0026gt;(new String[]{\u0026#34;NONE\u0026#34;,\u0026#34;ODD\u0026#34;,\u0026#34;EVEN\u0026#34;,\u0026#34;MARK\u0026#34;,\u0026#34;SPACE\u0026#34;}); parityCombox.addActionListener(this); // 添加组件至面板 leftPane.add(portnameLb); leftPane.add(portCombox); leftPane.add(databitsLb); leftPane.add(dataCombox); leftPane.add(parityLb); leftPane.add(parityCombox); //创建右边面板 JPanel rightPane = new JPanel(); rightPane.setLayout(new GridLayout(3,2)); // 设置右边面板各组件 JLabel baudrateLb = new JLabel(\u0026#34;波特率：\u0026#34;); baudrateLb.setFont(lbFont); baudrateLb.setHorizontalAlignment(SwingConstants.RIGHT); rateCombox = new JComboBox\u0026lt;Integer\u0026gt;(new Integer[]{2400,4800,9600,14400,19200,38400,56000}); rateCombox.setSelectedIndex(2); rateCombox.addActionListener(this); JLabel stopbitsLb = new JLabel(\u0026#34;停止位：\u0026#34;); stopbitsLb.setFont(lbFont); stopbitsLb.setHorizontalAlignment(SwingConstants.RIGHT); stopCombox = new JComboBox\u0026lt;String\u0026gt;(new String[]{\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;1.5\u0026#34;}); stopCombox.addActionListener(this); openPortBtn = new Button(\u0026#34;打开端口\u0026#34;); openPortBtn.addActionListener(this); closePortBtn = new Button(\u0026#34;关闭端口\u0026#34;); closePortBtn.addActionListener(this); // 添加组件至面板 rightPane.add(baudrateLb); rightPane.add(rateCombox); rightPane.add(stopbitsLb); rightPane.add(stopCombox); rightPane.add(openPortBtn); rightPane.add(closePortBtn); // 将左右面板组合添加到北边的面板 northPane.add(leftPane); northPane.add(rightPane); // 创建中间面板 JPanel centerPane = new JPanel(); // 设置中间面板各组件 sendTf = new TextField(42); readTa = new TextArea(8,50); readTa.setEditable(false); readTa.setBackground(new Color(225,242,250)); centerPane.add(sendTf); sendMsgBtn = new Button(\u0026#34; 发送 \u0026#34;); sendMsgBtn.addActionListener(this); // 添加组件至面板 centerPane.add(sendTf); centerPane.add(sendMsgBtn); centerPane.add(readTa); // 设置南边组件 statusLb = new JLabel(); statusLb.setText(initStatus()); statusLb.setOpaque(true); // 获取主窗体的容器,并将以上三面板以北、中、南的布局整合 JPanel contentPane = (JPanel)getContentPane(); contentPane.setLayout(new BorderLayout()); contentPane.setBorder(new EmptyBorder(0, 0, 0, 0)); contentPane.setOpaque(false); contentPane.add(northPane, BorderLayout.NORTH); contentPane.add(centerPane, BorderLayout.CENTER); contentPane.add(statusLb, BorderLayout.SOUTH); } /** * 初始化状态标签显示文本 * @return String * @since 2012-3-23 上午12:01:53 */ public String initStatus() { portname = portCombox.getSelectedItem().toString(); rate = rateCombox.getSelectedItem().toString(); data = dataCombox.getSelectedItem().toString(); stop = stopCombox.getSelectedItem().toString(); parity = parityCombox.getSelectedItem().toString(); StringBuffer str = new StringBuffer(\u0026#34;当前串口号:\u0026#34;); str.append(portname).append(\u0026#34; 波特率:\u0026#34;); str.append(rate).append(\u0026#34; 数据位:\u0026#34;); str.append(data).append(\u0026#34; 停止位:\u0026#34;); str.append(stop).append(\u0026#34; 校验位:\u0026#34;); str.append(parity); return str.toString(); } /** * 扫描本机的所有COM端口 * @since 2012-3-23 上午12:02:42 */ public void scanPorts() { portList = new ArrayList\u0026lt;String\u0026gt;(); Enumeration\u0026lt;?\u0026gt; en = CommPortIdentifier.getPortIdentifiers(); CommPortIdentifier portId; while(en.hasMoreElements()){ portId = (CommPortIdentifier) en.nextElement(); if(portId.getPortType() == CommPortIdentifier.PORT_SERIAL){ String name = portId.getName(); if(!portList.contains(name)) { portList.add(name); } } } if(null == portList || portList.isEmpty()) { showErrMesgbox(\u0026#34;未找到可用的串行端口号,程序无法启动!\u0026#34;); System.exit(0); } } /** * 打开串行端口 * @since 2012-3-23 上午12:03:07 */ public void openSerialPort() { // 获取要打开的端口 try { portId = CommPortIdentifier.getPortIdentifier(portname); } catch (NoSuchPortException e) { showErrMesgbox(\u0026#34;抱歉,没有找到\u0026#34;+portname+\u0026#34;串行端口号!\u0026#34;); setComponentsEnabled(true); return ; } // 打开端口 try { serialPort = (SerialPort) portId.open(\u0026#34;JavaRs232\u0026#34;, 2000); statusLb.setText(portname+\u0026#34;串口已经打开!\u0026#34;); } catch (PortInUseException e) { showErrMesgbox(portname+\u0026#34;端口已被占用,请检查!\u0026#34;); setComponentsEnabled(true); return ; } // 设置端口参数 try { int rate = Integer.parseInt(this.rate); int data = Integer.parseInt(this.data); int stop = stopCombox.getSelectedIndex()+1; int parity = parityCombox.getSelectedIndex(); serialPort.setSerialPortParams(rate,data,stop,parity); } catch (UnsupportedCommOperationException e) { showErrMesgbox(e.getMessage()); } // 打开端口的IO流管道 try { outputStream = serialPort.getOutputStream(); inputStream = serialPort.getInputStream(); } catch (IOException e) { showErrMesgbox(e.getMessage()); } // 给端口添加监听器 try { serialPort.addEventListener(this); } catch (TooManyListenersException e) { showErrMesgbox(e.getMessage()); } serialPort.notifyOnDataAvailable(true); } /** * 给串行端口发送数据 * @since 2012-3-23 上午12:05:00 */ public void sendDataToSeriaPort() { try { sendCount++; outputStream.write(mesg.getBytes()); outputStream.flush(); } catch (IOException e) { showErrMesgbox(e.getMessage()); } statusLb.setText(\u0026#34; 发送: \u0026#34;+sendCount+\u0026#34; 接收: \u0026#34;+reciveCount); } /** * 关闭串行端口 * @since 2012-3-23 上午12:05:28 */ public void closeSerialPort() { try { if(outputStream != null) outputStream.close(); if(serialPort != null) serialPort.close(); serialPort = null; statusLb.setText(portname+\u0026#34;串口已经关闭!\u0026#34;); sendCount = 0; reciveCount = 0; sendTf.setText(\u0026#34;\u0026#34;); readTa.setText(\u0026#34;\u0026#34;); } catch (Exception e) { showErrMesgbox(e.getMessage()); } } /** * 显示错误或警告信息 * @param msg 信息 * @since 2012-3-23 上午12:05:47 */ public void showErrMesgbox(String msg) { JOptionPane.showMessageDialog(this, msg); } /** * 各组件行为事件监听 */ public void actionPerformed(ActionEvent e) { if(e.getSource() == portCombox || e.getSource() == rateCombox || e.getSource() == dataCombox || e.getSource() == stopCombox || e.getSource() == parityCombox){ statusLb.setText(initStatus()); } if(e.getSource() == openPortBtn){ setComponentsEnabled(false); openSerialPort(); } if(e.getSource() == closePortBtn){ if(serialPort != null){ closeSerialPort(); } setComponentsEnabled(true); } if(e.getSource() == sendMsgBtn){ if(serialPort == null){ showErrMesgbox(\u0026#34;请先打开串行端口!\u0026#34;); return ; } mesg = sendTf.getText(); if(null == mesg || mesg.isEmpty()){ showErrMesgbox(\u0026#34;请输入你要发送的内容!\u0026#34;); return ; } sendDataToSeriaPort(); } } /** * 端口事件监听 */ public void serialEvent(SerialPortEvent event) { switch (event.getEventType()) { case SerialPortEvent.BI: case SerialPortEvent.OE: case SerialPortEvent.FE: case SerialPortEvent.PE: case SerialPortEvent.CD: case SerialPortEvent.CTS: case SerialPortEvent.DSR: case SerialPortEvent.RI: case SerialPortEvent.OUTPUT_BUFFER_EMPTY: break; case SerialPortEvent.DATA_AVAILABLE: byte[] readBuffer = new byte[50]; try { while (inputStream.available() \u0026gt; 0) { inputStream.read(readBuffer); } StringBuilder receivedMsg = new StringBuilder(\u0026#34;/-- \u0026#34;); receivedMsg.append(new String(readBuffer).trim()).append(\u0026#34; --/\\n\u0026#34;); readTa.append(receivedMsg.toString()); reciveCount++; statusLb.setText(\u0026#34; 发送: \u0026#34;+sendCount+\u0026#34; 接收: \u0026#34;+reciveCount); } catch (IOException e) { showErrMesgbox(e.getMessage()); } } } /** * 设置各组件的开关状态 * @param enabled 状态 * @since 2012-3-23 上午12:06:24 */ public void setComponentsEnabled(boolean enabled) { openPortBtn.setEnabled(enabled); openPortBtn.setEnabled(enabled); portCombox.setEnabled(enabled); rateCombox.setEnabled(enabled); dataCombox.setEnabled(enabled); stopCombox.setEnabled(enabled); parityCombox.setEnabled(enabled); } /** * 运行主函数 * @param args * @since 2012-3-23 上午12:06:45 */ public static void main(String[] args) { new JavaRs232(); } } 代码编写完成，按下F11键进入调试状态，一切运行正常良好，请看图：\n启动界面 端口检测 通讯测试 最后再抽空来美化程序下，效果更漂亮 PS: 示例源下载 ","date":"2012-03-24T22:21:20+00:00","updated":"2012-03-24T22:21:20+00:00"},{"permalink":"/tech/nutz-ke-lhg-my97.html","title":"国内技术强强联手之Nutz+KindEditor+LHGDialog+My97DatePicker","content":"有段时间没关注过国内IT技术发展情况了，前些天在学习国内的一个开源技术Nutz时想练个手，但一时又不知写些什么好，想了一会还是选择了自己的“老友”KindEditor。对它虽不敢说是透彻的了解(个人的JS水平有限，呵~)，但至少也能很熟练的运用。官网很早便推出了大家期待已久的KE4，不过我一起都没有更新，正好这次拿它来历练下，嘻~。可是想到前面写的那些KE应用示例都是单调的，上次的那个还好有EasyUI做衬托，不过这个UI框架对于小小于的练手项目来说还是庞大了点。于是又便开始寻思着找别的UI看看，突然间起了以前用过的LHGDialog弹出窗口组件还蛮不错的，便去它官网逛了一圈。没有想到还真是让人喜出望外呀，LHG现也更新为4的版本了，那效果的炫丽真是让人颇然心动。下面就先来欣赏下花费2个多小时的劳动成果吧（现在是真相时间），呵呵……\n在此不得不称赞下Nutz的高效简约之美，和以前的KE版本一样还是把上传部分的JSP页面翻译成后台JAVA代码，唯一不同的就是那些相同功能的实现代码精简了好多呀，官网示例中的两个JSP文件被有压缩成了一个只有不到400行的JAVA后台代码，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 package org.nutz.kindeditor4.plugin; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.Comparator; import java.util.Date; import java.util.HashMap; import java.util.List; import java.util.Map; import javax.servlet.ServletContext; import org.nutz.ioc.loader.annotation.IocBean; import org.nutz.log.Log; import org.nutz.log.Logs; import org.nutz.mvc.annotation.AdaptBy; import org.nutz.mvc.annotation.At; import org.nutz.mvc.annotation.Param; import org.nutz.mvc.upload.UploadAdaptor; /** * KindEditor在线编辑器文件上传,管理模块 * @author Elkan(elkan1788@gmail.com) */ @At(\u0026#34;/nutz/ke4plugin\u0026#34;) @AdaptBy(type = UploadAdaptor.class) @IocBean public class KindEditor4Module { // 日志输出对象 private static Log log = Logs.get(); // 文件目录名称 private String fileDir; // 文件后缀名称 private String fileExt; // 当前站点上下文 private String pageCtx; // 站点真实路径 private String relPath; // 上传文件保存路径 private String savePath; // 允许上传文件后缀MAP数组 private static final HashMap\u0026lt;String, String\u0026gt; extMap = new HashMap\u0026lt;String, String\u0026gt;(); // 允许上传文件大小MAP数组 private static final HashMap\u0026lt;String,Long\u0026gt; sizeMap = new HashMap\u0026lt;String, Long\u0026gt;(); // 上传文件存放根目录 private String filePath = \u0026#34;/attached/\u0026#34;; static { // 初始后缀名称MAP数组 extMap.put(\u0026#34;image\u0026#34;, \u0026#34;gif,jpg,jpeg,png,bmp\u0026#34;); extMap.put(\u0026#34;flash\u0026#34;, \u0026#34;swf,flv\u0026#34;); extMap.put(\u0026#34;media\u0026#34;, \u0026#34;swf,flv,mp3,wav,wma,wmv,mid,avi,mpg,asf,rm,rmvb\u0026#34;); extMap.put(\u0026#34;file\u0026#34;, \u0026#34;doc,docx,xls,xlsx,ppt,txt,zip,rar\u0026#34;); // 初始文件大小MAP数组 sizeMap.put(\u0026#34;image\u0026#34;, 100 * 1024l); sizeMap.put(\u0026#34;flash\u0026#34;, 10 * 1024 * 1024l); sizeMap.put(\u0026#34;media\u0026#34;, 10 * 1024 * 1024l); sizeMap.put(\u0026#34;file\u0026#34;, 10 * 1024 * 1024l); } @At public Map\u0026lt;String, Object\u0026gt; upload(@Param(\u0026#34;imgFile\u0026#34;) File tempFile, @Param(\u0026#34;dir\u0026#34;) String dir, ServletContext context) { // 初始相关变量 Map\u0026lt;String, Object\u0026gt; execute = new HashMap\u0026lt;String, Object\u0026gt;(); pageCtx = context.getContextPath().concat(filePath); relPath = context.getRealPath(filePath); fileDir = dir; if (null == dir || dir.isEmpty()) { fileDir = \u0026#34;file\u0026#34;; } // 检查是否有上传文件 if (null == tempFile) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;请选择上传文件.\u0026#34;); return execute; } // 检查上传文件保存目录是否存在或可写 if (!isExistOrRwFolder()) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;上传文件保存目录不存在或\\n是没有写入权限,请检查.\u0026#34;); return execute; } // 检查目录名称是否正确 if (!extMap.containsKey(fileDir)) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;目录名不正确,请检查.\u0026#34;); return execute; } // 计算出文件后缀名 String tempFileName = tempFile.getName(); fileExt = tempFileName.substring(tempFileName.lastIndexOf(\u0026#34;.\u0026#34;) + 1); // 检查上传文件类型 if(!Arrays.\u0026lt;String\u0026gt;asList(extMap.get(fileDir).split(\u0026#34;,\u0026#34;)).contains(fileExt)){ execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;上传文件的格式被拒绝,\\n只允许\u0026#34; + extMap.get(fileDir) + \u0026#34;格式的文件.\u0026#34;); return execute; } // 检查上传文件的大小 long maxSize = sizeMap.get(fileDir); if (tempFile.length() \u0026gt; maxSize) { execute.put(\u0026#34;error\u0026#34;, 1); String size = null; if(maxSize \u0026lt; 1024) { size = maxSize + \u0026#34;B\u0026#34;; } if(maxSize \u0026gt; 1024 \u0026amp;\u0026amp; maxSize \u0026lt; 1024 * 1024){ size = maxSize/1024 + \u0026#34;KB\u0026#34;; } if(maxSize \u0026gt; 1024 * 1024){ size = maxSize/(1024 * 1024) + \u0026#34;MB\u0026#34;; } execute.put(\u0026#34;message\u0026#34;, \u0026#34;上传文件大小超过限制,只允\\n许上传小于 \u0026#34; + size + \u0026#34; 的文件.\u0026#34;); return execute; } // 生成新的文件名,并按日期分类 newSavePath(); // 拷贝上传文件至指定存放目录 copy(tempFile, savePath); // 计算出文件输出路径 int point = savePath.lastIndexOf(\u0026#34;/\u0026#34;) - 8; StringBuilder url = new StringBuilder(pageCtx); url.append(fileDir).append(\u0026#34;/\u0026#34;); url.append(savePath.substring(point)); // 返回上传文件的输出路径至前端 execute.put(\u0026#34;error\u0026#34;, 0); execute.put(\u0026#34;url\u0026#34;, url.toString()); return execute; } @At public Map\u0026lt;String, Object\u0026gt; manager(@Param(\u0026#34;dir\u0026#34;) String dir, @Param(\u0026#34;path\u0026#34;) String path, @Param(\u0026#34;order\u0026#34;) String order, ServletContext context) { // 初始相关变量 Map\u0026lt;String, Object\u0026gt; execute = new HashMap\u0026lt;String, Object\u0026gt;(); pageCtx = context.getContextPath().concat(filePath); relPath = context.getRealPath(filePath); fileDir = dir; if (null == dir || dir.isEmpty()) { fileDir = \u0026#34;file\u0026#34;; } if (!extMap.containsKey(fileDir)) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;目录名不正确,请检查.\u0026#34;); return execute; } String tempPath = null == path ? fileDir.concat(\u0026#34;/\u0026#34;) : fileDir.concat(\u0026#34;/\u0026#34;+path); String curPath = pageCtx.concat(tempPath); String curFileDir = relPath.concat(\u0026#34;/\u0026#34;+tempPath); String curDir = path; String moveupDir = \u0026#34;\u0026#34;; // 检查当前目录是否为根目录 if (!\u0026#34;\u0026#34;.equals(path)) { String str = curDir.substring(0, curDir.length() - 1); moveupDir = str.lastIndexOf(\u0026#34;/\u0026#34;) \u0026gt;= 0 ? str.substring(0, str.lastIndexOf(\u0026#34;/\u0026#34;) + 1) : \u0026#34;\u0026#34;; } // 检查..命令 if(path.indexOf(\u0026#34;..\u0026#34;) \u0026gt;= 0){ execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;不允许使用..命令返回上一层.\u0026#34;); return execute; } //最后一个字符不是/ if (!\u0026#34;\u0026#34;.equals(path) \u0026amp;\u0026amp; !path.endsWith(\u0026#34;/\u0026#34;)) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;文件路径不合法.\u0026#34;); return execute; } // 检查当前目录 File curPathFile = new File(curFileDir); if (!curPathFile.isDirectory()) { execute.put(\u0026#34;error\u0026#34;, 1); execute.put(\u0026#34;message\u0026#34;, \u0026#34;当前目录不存在.\u0026#34;); return execute; } //遍历目录取的文件信息 List\u0026lt;HashMap\u0026gt; fileList = new ArrayList\u0026lt;HashMap\u0026gt;(); if (curPathFile.listFiles() != null) { for (File file : curPathFile.listFiles()) { HashMap\u0026lt;String, Object\u0026gt; hash = new HashMap\u0026lt;String, Object\u0026gt;(); String fileName = file.getName(); if (file.isDirectory()) { hash.put(\u0026#34;is_dir\u0026#34;, true); hash.put(\u0026#34;has_file\u0026#34;, (file.listFiles() != null)); hash.put(\u0026#34;filesize\u0026#34;, 0L); hash.put(\u0026#34;is_photo\u0026#34;, false); hash.put(\u0026#34;filetype\u0026#34;, \u0026#34;\u0026#34;); } else if (file.isFile()) { fileExt = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;) + 1).toLowerCase(); hash.put(\u0026#34;is_dir\u0026#34;, false); hash.put(\u0026#34;has_file\u0026#34;, false); hash.put(\u0026#34;filesize\u0026#34;, file.length()); hash.put(\u0026#34;is_photo\u0026#34;, Arrays.\u0026lt;String\u0026gt;asList(extMap.get(\u0026#34;image\u0026#34;).split(\u0026#34;,\u0026#34;)).contains(fileExt)); hash.put(\u0026#34;filetype\u0026#34;, fileExt); } hash.put(\u0026#34;filename\u0026#34;, fileName); hash.put(\u0026#34;datetime\u0026#34;, new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;).format(file.lastModified())); fileList.add(hash); } } // 文件排序方式 String tempOrder = order != null ? order.toLowerCase() : \u0026#34;name\u0026#34;; if (\u0026#34;size\u0026#34;.equals(tempOrder)) { Collections.sort(fileList, new SizeComparator()); } else if (\u0026#34;type\u0026#34;.equals(tempOrder)) { Collections.sort(fileList, new TypeComparator()); } else { Collections.sort(fileList, new NameComparator()); } // 输出遍历后的文件信息数据 execute.put(\u0026#34;moveup_dir_path\u0026#34;, moveupDir); execute.put(\u0026#34;current_dir_path\u0026#34;, curDir); execute.put(\u0026#34;current_url\u0026#34;, curPath); execute.put(\u0026#34;total_count\u0026#34;, fileList.size()); execute.put(\u0026#34;file_list\u0026#34;, fileList); return execute; } /** * 判断文件上传保存的文件夹是否存在或可写 * @return 如果存在且可写返回\u0026#34;true\u0026#34;,否则返回\u0026#34;false\u0026#34; */ public boolean isExistOrRwFolder(){ if(null == relPath || relPath.isEmpty()) { return false; } File folder = new File(relPath); if(!folder.exists()) return false; if(!folder.isDirectory()) return false; if(!folder.canWrite()) return false; return true; } /** * 生成新的文件名,且按日期分类管理 */ public void newSavePath() { StringBuilder tempPath = new StringBuilder(relPath); tempPath.append(\u0026#34;/\u0026#34;).append(fileDir).append(\u0026#34;/\u0026#34;); SimpleDateFormat folderNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMdd\u0026#34;); tempPath.append(folderNameFormat.format(new Date())); File temp = new File(tempPath.toString()); if(!temp.exists()) temp.mkdirs(); SimpleDateFormat fileNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMddkkmmss_S\u0026#34;); tempPath.append(\u0026#34;/\u0026#34;).append(fileNameFormat.format(new Date())); tempPath.append(\u0026#34;.\u0026#34;).append(fileExt); savePath = tempPath.toString().replaceAll(\u0026#34;\\\\\\\\\u0026#34;, \u0026#34;/\u0026#34;); } /** * 拷贝文件 * @param src 源文件 * @param tar 目标路径 */ public void copy(File src, String tar) { // 判断源文件或目标路径是否为空 if (null == src || null == tar || tar.isEmpty()) { return; } InputStream srcIs = null; OutputStream tarOs = null; try { srcIs = new FileInputStream(src); File tarFile = new File(tar); tarOs = new FileOutputStream(tarFile); byte[] buffer = new byte[4096]; int n = 0; while (-1 != (n = srcIs.read(buffer))) { tarOs.write(buffer, 0, n); } } catch (IOException e) { log.error(\u0026#34;Copy File is Fali, Because \u0026#34;+e); } finally { try { if (null != srcIs) { srcIs.close(); } if (null != tarOs) { tarOs.close(); } } catch (IOException e) { log.error(\u0026#34;Close Stream is Fail, Because \u0026#34;+e); } } } /** * 根据文件名称排序 */ public class NameComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { return ((String) hashA.get(\u0026#34;filename\u0026#34;)).compareTo((String) hashB.get(\u0026#34;filename\u0026#34;)); } } } /** * 根据文件大小排序 */ public class SizeComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { if (((Long) hashA.get(\u0026#34;filesize\u0026#34;)) \u0026gt; ((Long) hashB.get(\u0026#34;filesize\u0026#34;))) { return 1; } else if (((Long) hashA.get(\u0026#34;filesize\u0026#34;)) \u0026lt; ((Long) hashB.get(\u0026#34;filesize\u0026#34;))) { return -1; } else { return 0; } } } } /** * 根据文件类型排序 */ public class TypeComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { return ((String) hashA.get(\u0026#34;filetype\u0026#34;)).compareTo((String) hashB.get(\u0026#34;filetype\u0026#34;)); } } } } 虽说代码精简了，但是功能却是一个没有含糊呀，接着欣赏效果图吧。\nNutz对于JAVA程序员来说，是除SSH外的另一个选择，一个美好的开始，如果你有使用相信你定会深学的爱上它，嘻~，别的就不多说了，下面直接把源码给奉上吧，因为时间紧迫(待会就要坐车回家了，嘎~，终于放假了)就只是随笔写了下，写的不好还望大家见谅。\nPS: 示例源下载 ","date":"2012-01-13T10:21:20+00:00","updated":"2012-01-13T10:21:20+00:00"},{"permalink":"/tech/whosip-tool.html","title":"IP地址查询Web接口调用","content":"今天刚好有个站点上要用到一个IP地址显示的功能，随即便想想应该有免费的接口可用吧，百度一下找到了太平洋网站提供的API，那么接下来便是Code Time。\n看完了它的参数说明和调用方式后，选择了其中的jsFunction方式，现在把经验分享出来给大家参考，具体的代码和效果如下：：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;!DOCTYPE html PUBLIC \u0026#34;-//W3C//DTD HTML 4.01 Transitional//EN\u0026#34; \u0026#34;http://www.w3.org/TR/html4/loose.dtd\u0026#34;\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;ip查询\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/1.7.0/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; $(function(){ $(\u0026#34;\u0026lt;span id=\u0026#39;ipShow\u0026#39;\u0026gt;\u0026lt;/span\u0026gt;\u0026#34;).appendTo(\u0026#34;body\u0026#34;); $.getScript(\u0026#34;http://whois.pconline.com.cn/jsFunction.jsp?callback=jsShow\u0026amp;ip=61.235.82.163\u0026#34;); }); function jsShow(location){ $(\u0026#34;#ipShow\u0026#34;).html(location); } \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 效果如下：\n具体参数如下：\n有不明白的地方，可以留言讨论。\n","date":"2011-11-18T10:21:20+00:00","updated":"2011-11-18T10:21:20+00:00"},{"permalink":"/tech/kindeditor-jsp-struts2-servlet.html","title":"JSP版本的KindEidtor在线编辑器第二季：Servlet+Struts2集成版","content":"前段时间我在论坛上发布了一篇名为 《JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)》 得到了大家的积极响应，不过令我觉得有点遗憾的是，有很多人都不是真的讨论技术问题，而是向我索取源码，说实在的自已的劳动成果就这样白白奉献出来，觉得有点对不起自己了，要知道我们国内的技术员都是没有金钱后盾啊。唉，最近都太忙了就没有怎么太在意这件事，今晚刚好有空过来看看。看了那么多人留下的印记后，觉得自己也应该要无私一下才是吧，咱老毛说的对：要像雷锋同志学习，呵呵…… 其实在上面我已经说过了，这个JAR里面的功能我只是把官网的JSP代码改编而已，废话就先不多说了，下面直接上码吧，可要接稳了哦。\n图片上传功能代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; import java.util.Iterator; import java.util.List; import java.util.Random; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.apache.commons.fileupload.FileItem; import org.apache.commons.fileupload.FileItemFactory; import org.apache.commons.fileupload.FileUploadException; import org.apache.commons.fileupload.disk.DiskFileItemFactory; import org.apache.commons.fileupload.servlet.ServletFileUpload; import com.elkan.utils.ImageUtil; /** * 实现KindEditor图片上传的Servlet * * @author SENHUI * * @since 2011/03/21 20:20:23 */ public class UploadImage extends HttpServlet { private static final long serialVersionUID = 5121794650920770832L; // 上传图片的最大宽度 protected int MAX_WIDTH = -1; // 上传图片的最大高度 protected int MAX_HEIGHT = -1; // 上传图片的大小 protected long MAX_SIZE = 1000000; // 定义允许上传的图片的扩展名 protected String[] IMAGETYPES = new String[] { \u0026#34;gif\u0026#34;, \u0026#34;jpg\u0026#34;, \u0026#34;jpeg\u0026#34;, \u0026#34;png\u0026#34;, \u0026#34;bmp\u0026#34; }; // 定义上传图片保存目录路径 protected String UPLOAD_PATH = \u0026#34;\u0026#34;;\t// 上传图片设置信息 protected String id = \u0026#34;\u0026#34;; // 上传图片的TITLE属性值 protected String imgTitle = \u0026#34;\u0026#34;; protected int imgWidth = -1; protected int imgHeight = -1; protected String imgBorder = \u0026#34;\u0026#34;; protected String resizeImg = \u0026#34;\u0026#34;; protected boolean isFlag = false; protected String tempTitle = \u0026#34;\u0026#34;; @SuppressWarnings(\u0026#34;deprecation\u0026#34;) @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;text/html; charset=UTF-8\u0026#34;); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter(\u0026#34;UPLOAD_PATH\u0026#34;); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg(\u0026#34;你还没设置上传图片保存的目录路径!\u0026#34;)); return; } //判断是否设置了上传图片的大小 if(this.getInitParameter(\u0026#34;MAX_SIZE\u0026#34;) != null){ MAX_SIZE = Integer.parseInt(this.getInitParameter(\u0026#34;MAX_SIZE\u0026#34;)); } //判断是否设置了上传图片的类型 if(this.getInitParameter(\u0026#34;IMAGETYPES\u0026#34;) != null){ IMAGETYPES = toArray(this.getInitParameter(\u0026#34;IMAGETYPES\u0026#34;)); } // 图片保存目录路径 String uploadPath = new StringBuffer(request.getSession().getServletContext().getRealPath(\u0026#34;/\u0026#34;)).append(savePath).toString(); // 图片保存目录URL String saveUrl = new StringBuffer(request.getContextPath()).append(\u0026#34;/\u0026#34;).append(savePath).toString(); // 检查上传图片是否存在 if (!ServletFileUpload.isMultipartContent(request)) { out.println(alertMsg(\u0026#34;请选择你要上传的图片!\u0026#34;)); return; } // 检查目录 File uploadDir = new File(uploadPath); if (!uploadDir.isDirectory()) { out.println(alertMsg(\u0026#34;上传图片保存的目录不存在。\u0026#34;)); return; } // 检查目录写权限 if (!uploadDir.canWrite()) { out.println(alertMsg(\u0026#34;上传图片保存的目录没有写权限。\u0026#34;)); return; } // 准备上传图片 FileItemFactory factory = new DiskFileItemFactory(); ServletFileUpload upload = new ServletFileUpload(factory); upload.setHeaderEncoding(\u0026#34;UTF-8\u0026#34;); List\u0026lt;?\u0026gt; items = null; String temp = null; try { items = upload.parseRequest(request);\tIterator\u0026lt;?\u0026gt; itr = items.iterator(); while (itr.hasNext()) { FileItem item = (FileItem) itr.next(); // 上传图片的原文件名 String fileName = item.getName(); temp = (String) item.getName(); if(temp != null \u0026amp;\u0026amp; !isFlag){ temp = temp.substring(temp.lastIndexOf(\u0026#34;\\\\\u0026#34;)+1); tempTitle = temp; isFlag = true; } // KindEditor编辑器的ID if(((String)item.getFieldName()).equals(\u0026#34;id\u0026#34;)){ id = item.getString(); } // 上传图片的重新提示 if(((String)item.getFieldName()).equals(\u0026#34;imgTitle\u0026#34;)){ imgTitle = item.getString(); if(imgTitle != null){ imgTitle = new String(imgTitle.getBytes(\u0026#34;ISO8859-1\u0026#34;),\u0026#34;UTF-8\u0026#34;); } } // 设置图片的宽度 if(((String)item.getFieldName()).equals(\u0026#34;imgWidth\u0026#34;)){ String imgWidth = item.getString(); if(imgWidth != null \u0026amp;\u0026amp; !imgWidth.isEmpty()){ this.imgWidth = Integer.parseInt(imgWidth); } } // 设置图片的高度 if(((String)item.getFieldName()).equals(\u0026#34;imgHeight\u0026#34;)){ String imgHeight = item.getString(); if(imgHeight != null \u0026amp;\u0026amp; !imgHeight.isEmpty()){ this.imgHeight = Integer.parseInt(imgHeight); } } // 设置图片的边框 if(((String)item.getFieldName()).equals(\u0026#34;imgBorder\u0026#34;)){ imgBorder = item.getString(); } long fileSize = item.getSize(); if (!item.isFormField()) {\t// 检查文件大小 if (fileSize \u0026gt; MAX_SIZE) { out.println(alertMsg(\u0026#34;上传文件大小超过限制。\u0026#34;)); return; } // 检查扩展名 String fileExt = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;) + 1).toLowerCase(); if (!Arrays.\u0026lt;String\u0026gt; asList(IMAGETYPES).contains(fileExt)) { out.println(alertMsg(\u0026#34;上传图片扩展名是不允许的扩展名。\u0026#34;)); return; } // 根据时间创建文件夹 SimpleDateFormat folderNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMdd\u0026#34;); String realPath = uploadPath + folderNameFormat.format(new Date()); File folder = new File(realPath); boolean flag = folder.exists(); // 确认文件夹是否已经存在 if(!flag){ flag = folder.mkdir(); } // 创建文件夹并上传图片 if(flag){ SimpleDateFormat fileNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMddHHmmss\u0026#34;);\tString newFileName = fileNameFormat.format(new Date()) + \u0026#34;_\u0026#34;+ new Random().nextInt(1000) + \u0026#34;.\u0026#34; + fileExt;\tFile uploadedFile = new File(realPath, newFileName);\titem.write(uploadedFile); resizeImg = uploadedFile.getPath(); resizeImg = resizeImg.replaceAll(\u0026#34;\\\\\\\\\u0026#34;, \u0026#34;/\u0026#34;); saveUrl += folderNameFormat.format(new Date()) + \u0026#34;/\u0026#34; + newFileName;\t}else{ System.out.println(\u0026#34; 文件夹创建失败，请确认磁盘没有写保护并且空件足够\u0026#34;); }\t} } // 判断是否设置图片的最大宽度与高度 String max_width = this.getInitParameter(\u0026#34;MAX_WIDTH\u0026#34;); String max_height = this.getInitParameter(\u0026#34;MAX_HEIGHT\u0026#34;); if((max_width != null \u0026amp;\u0026amp; !max_width.isEmpty())){ MAX_WIDTH = Integer.parseInt(max_width); } if(max_height != null \u0026amp;\u0026amp; !max_height.isEmpty()){ MAX_HEIGHT = Integer.parseInt(max_height); } if(imgTitle == null || imgTitle.isEmpty()){ imgTitle = tempTitle; } // 判断是否要压缩图片 if(MAX_WIDTH != -1 || MAX_HEIGHT != -1) { // 压缩图片 ImageUtil.resizeImg(resizeImg, resizeImg, MAX_WIDTH, MAX_HEIGHT); if(this.imgWidth \u0026gt; ImageUtil.ImgWidth){ this.imgWidth = ImageUtil.ImgWidth; } if(this.imgHeight \u0026gt; ImageUtil.ImgHeight){ this.imgHeight = ImageUtil.ImgHeight; } // 返回编辑器 out.println(insertEditor(id, saveUrl, imgTitle, imgWidth, imgHeight, imgBorder)); }else{ // 返回编辑器 out.println(insertEditor(id, saveUrl, imgTitle, imgWidth, imgHeight, imgBorder)); }\t} catch (FileUploadException e) { e.printStackTrace(); } catch (Exception e) { e.printStackTrace(); }finally{ out.flush(); out.close(); isFlag = false; } } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } /** * 输出打印上传失败的JSON语句 * * @param message 失败信息 * * @return 页面上传失败的JSON语句 */ public String alertMsg(String message) { StringBuffer sb = new StringBuffer(\u0026#34;{\\\u0026#34;error\\\u0026#34;:\\\u0026#34;1\\\u0026#34;,\\\u0026#34;message\\\u0026#34;:\\\u0026#34;\u0026#34;); sb.append(message).append(\u0026#34;\\\u0026#34;}\u0026#34;); return sb.toString(); } /** * 输出插入图片至编辑器语句的脚本 * * @param id 编辑器ID * * @param saveUrl 上传图片的浏览地址 * * @param imgTitle 图片的提示信息 * * @param imgWidth 设置图片的宽度 * * @param imgHeight 设置图片的宽度 * * @param imgBorder 设置图片的边框 * * @return 插入图片至编辑器的脚本语句 */ public String insertEditor(String id, String saveUrl, String imgTitle, int imgWidth, int imgHeight, String imgBorder){ StringBuffer sb = new StringBuffer(\u0026#34;\u0026lt;script type\\\u0026#34;text/javascript\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;parent.KE.plugin[\\\u0026#34;image\\\u0026#34;].insert(\\\u0026#34;\u0026#34;).append(id).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;); sb.append(saveUrl).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;).append(imgTitle).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;); sb.append(imgWidth).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;).append(imgHeight).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;); sb.append(imgBorder).append(\u0026#34;\\\u0026#34;);\u0026#34;); sb.append(\u0026#34;\u0026lt;/script\u0026gt;\u0026#34;); return sb.toString(); } /** * 输出允许上传图片类型的数组 * * @param filesType 允许上传的图片类型 * * @return 允许上传图片类型 */ public String[] toArray(String filesType){ if(filesType == null){ return null; } String[] types = filesType.split(\u0026#34;,\u0026#34;); String[] allowTypes = new String[types.length]; int i = 0; for(String type : types){ allowTypes[i] = type; i++; } return allowTypes; } } 上传图片管理代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.Comparator; import java.util.Hashtable; import java.util.List; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class UploadImageManager extends HttpServlet { private static final long serialVersionUID = -8359652838938248988L; // 定义允许上传的图片的扩展名 protected String[] FILETYPES = new String[] { \u0026#34;gif\u0026#34;, \u0026#34;jpg\u0026#34;, \u0026#34;jpeg\u0026#34;, \u0026#34;png\u0026#34;, \u0026#34;bmp\u0026#34; }; // 定义上传图片保存目录路径 protected String UPLOAD_PATH = \u0026#34;\u0026#34;; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;text/html; charset=UTF-8\u0026#34;); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter(\u0026#34;UPLOAD_PATH\u0026#34;); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg(\u0026#34;你还没设置读取上传图片保存的目录路径!\u0026#34;)); return; } // 图片保存目录路径 String rootPath = new StringBuffer(request.getSession().getServletContext().getRealPath(\u0026#34;/\u0026#34;)).append(savePath).toString();\t// 图片保存目录URL String rootUrl = new StringBuffer(request.getContextPath()).append(\u0026#34;/\u0026#34;).append(savePath).toString(); //根据path参数，设置各路径和URL String path = request.getParameter(\u0026#34;path\u0026#34;) != null ? request.getParameter(\u0026#34;path\u0026#34;) : \u0026#34;\u0026#34;; String currentPath = rootPath + path; String currentUrl = rootUrl + path; String currentDirPath = path; String moveupDirPath = \u0026#34;\u0026#34;; if (!\u0026#34;\u0026#34;.equals(path)) { String str = currentDirPath.substring(0, currentDirPath.length() - 1); moveupDirPath = str.lastIndexOf(\u0026#34;/\u0026#34;) \u0026gt;= 0 ? str.substring(0, str.lastIndexOf(\u0026#34;/\u0026#34;) + 1) : \u0026#34;\u0026#34;; } //排序形式，name or size or type String order = request.getParameter(\u0026#34;order\u0026#34;) != null ? request.getParameter(\u0026#34;order\u0026#34;).toLowerCase() : \u0026#34;name\u0026#34;; //不允许使用..移动到上一级目录 if (path.indexOf(\u0026#34;..\u0026#34;) \u0026gt;= 0) { out.println(alertMsg(\u0026#34;不允许使用移动到上一级目录\u0026#34;)); return; } //最后一个字符不是/ if (!\u0026#34;\u0026#34;.equals(path) \u0026amp;\u0026amp; !path.endsWith(\u0026#34;/\u0026#34;)) { out.println(\u0026#34;Parameter is not valid.\u0026#34;); return; } //目录不存在或不是目录 File currentPathFile = new File(currentPath); if(!currentPathFile.isDirectory()){ out.println(\u0026#34;Directory does not exist.\u0026#34;); return; } //遍历目录取的文件信息 List\u0026lt;Hashtable\u0026lt;?,?\u0026gt;\u0026gt; fileList = new ArrayList\u0026lt;Hashtable\u0026lt;?,?\u0026gt;\u0026gt;(); if(currentPathFile.listFiles() != null) { for (File file : currentPathFile.listFiles()) { Hashtable\u0026lt;String, Object\u0026gt; hash = new Hashtable\u0026lt;String, Object\u0026gt;(); String fileName = file.getName(); if(file.isDirectory()) { hash.put(\u0026#34;is_dir\u0026#34;, true); hash.put(\u0026#34;has_file\u0026#34;, (file.listFiles() != null)); hash.put(\u0026#34;filesize\u0026#34;, 0L); hash.put(\u0026#34;is_photo\u0026#34;, false); hash.put(\u0026#34;filetype\u0026#34;, \u0026#34;\u0026#34;); } else if(file.isFile()){ String fileExt = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;) + 1).toLowerCase(); hash.put(\u0026#34;is_dir\u0026#34;, false); hash.put(\u0026#34;has_file\u0026#34;, false); hash.put(\u0026#34;filesize\u0026#34;, file.length()); hash.put(\u0026#34;is_photo\u0026#34;, Arrays.\u0026lt;String\u0026gt;asList(FILETYPES).contains(fileExt)); hash.put(\u0026#34;filetype\u0026#34;, fileExt); } hash.put(\u0026#34;filename\u0026#34;, fileName); hash.put(\u0026#34;datetime\u0026#34;, new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;).format(file.lastModified())); fileList.add(hash); } } if (\u0026#34;size\u0026#34;.equals(order)) { Collections.sort(fileList, new SizeComparator()); } else if (\u0026#34;type\u0026#34;.equals(order)) { Collections.sort(fileList, new TypeComparator()); } else { Collections.sort(fileList, new NameComparator()); } out.println(toJSONString(currentUrl, currentDirPath, moveupDirPath, fileList)); out.flush(); out.close(); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } /** * 输出打印上传失败语句的脚本 * * @param message 失败信息 * * @return 页面打印的脚本语句 */ public String alertMsg(String message) { StringBuffer sb = new StringBuffer(\u0026#34;\u0026lt;script type\\\u0026#34;text/javascript\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;alert(\\\u0026#34;\u0026#34;).append(message).append(\u0026#34;\\\u0026#34;);\u0026#34;); sb.append(\u0026#34;\u0026lt;/script\u0026gt;\u0026#34;); return sb.toString(); } public String toJSONString(String currentUrl, String currentDirPath, String moveupDirPath, List\u0026lt;Hashtable\u0026lt;?, ?\u0026gt;\u0026gt; fileList){ StringBuilder sb = new StringBuilder(\u0026#34;{\\\u0026#34;current_url\\\u0026#34;:\\\u0026#34;\u0026#34;); sb.append(currentUrl).append(\u0026#34;\\\u0026#34;,\u0026#34;).append(\u0026#34;\\\u0026#34;current_dir_path\\\u0026#34;:\\\u0026#34;\u0026#34;); sb.append(currentDirPath).append(\u0026#34;\\\u0026#34;,\\\u0026#34;moveup_dir_path\\\u0026#34;:\\\u0026#34;\u0026#34;).append(moveupDirPath).append(\u0026#34;\\\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;file_list\\\u0026#34;:[\u0026#34;); int i = 0; sb.append(\u0026#34;{\u0026#34;); for(Hashtable\u0026lt;?,?\u0026gt; he : fileList){\tif(i != (fileList.size() - 1)){ sb.append(\u0026#34;\\\u0026#34;filename\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;filename\u0026#34;)).append(\u0026#34;\\\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;filesize\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;filesize\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;filetype\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;filetype\u0026#34;)).append(\u0026#34;\\\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;has_file\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;has_file\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;is_dir\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;is_dir\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;is_photo\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;is_photo\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;datetime\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;datetime\u0026#34;)).append(\u0026#34;\\\u0026#34;\u0026#34;); sb.append(\u0026#34;},{\u0026#34;); }else{ sb.append(\u0026#34;\\\u0026#34;filename\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;filename\u0026#34;)).append(\u0026#34;\\\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;filesize\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;filesize\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;filetype\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;filetype\u0026#34;)).append(\u0026#34;\\\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;has_file\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;has_file\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;is_dir\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;is_dir\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;is_photo\\\u0026#34;:\u0026#34;).append(he.get(\u0026#34;is_photo\u0026#34;)).append(\u0026#34;,\u0026#34;); sb.append(\u0026#34;\\\u0026#34;datetime\\\u0026#34;:\\\u0026#34;\u0026#34;).append(he.get(\u0026#34;datetime\u0026#34;)).append(\u0026#34;\\\u0026#34;\u0026#34;); sb.append(\u0026#34;}\u0026#34;); } i++; } i = 0; sb.append(\u0026#34;],\\\u0026#34;total_count\\\u0026#34;:\u0026#34;).append(fileList.size()).append(\u0026#34;}\u0026#34;); return sb.toString(); } public class NameComparator implements Comparator\u0026lt;Object\u0026gt; { public int compare(Object a, Object b) { Hashtable\u0026lt;?, ?\u0026gt; hashA = (Hashtable\u0026lt;?, ?\u0026gt;) a; Hashtable\u0026lt;?, ?\u0026gt; hashB = (Hashtable\u0026lt;?, ?\u0026gt;) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { return ((String) hashA.get(\u0026#34;filename\u0026#34;)).compareTo((String) hashB.get(\u0026#34;filename\u0026#34;)); } } } public class SizeComparator implements Comparator\u0026lt;Object\u0026gt; { public int compare(Object a, Object b) { Hashtable\u0026lt;?, ?\u0026gt; hashA = (Hashtable\u0026lt;?, ?\u0026gt;) a; Hashtable\u0026lt;?, ?\u0026gt; hashB = (Hashtable\u0026lt;?, ?\u0026gt;) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { if (((Long) hashA.get(\u0026#34;filesize\u0026#34;)) \u0026gt; ((Long) hashB.get(\u0026#34;filesize\u0026#34;))) { return 1; } else if (((Long) hashA.get(\u0026#34;filesize\u0026#34;)) \u0026lt; ((Long) hashB.get(\u0026#34;filesize\u0026#34;))) { return -1; } else { return 0; } } } } public class TypeComparator implements Comparator\u0026lt;Object\u0026gt; { public int compare(Object a, Object b) { Hashtable\u0026lt;?, ?\u0026gt; hashA = (Hashtable\u0026lt;?, ?\u0026gt;) a; Hashtable\u0026lt;?, ?\u0026gt; hashB = (Hashtable\u0026lt;?, ?\u0026gt;) b; if (((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; !((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return -1; } else if (!((Boolean) hashA.get(\u0026#34;is_dir\u0026#34;)) \u0026amp;\u0026amp; ((Boolean) hashB.get(\u0026#34;is_dir\u0026#34;))) { return 1; } else { return ((String) hashA.get(\u0026#34;filetype\u0026#34;)).compareTo((String) hashB.get(\u0026#34;filetype\u0026#34;)); } } } } 附件上传代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; import java.util.Iterator; import java.util.List; import java.util.Random; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.apache.commons.fileupload.FileItem; import org.apache.commons.fileupload.FileItemFactory; import org.apache.commons.fileupload.disk.DiskFileItemFactory; import org.apache.commons.fileupload.servlet.ServletFileUpload; public class UploadAccessory extends HttpServlet { private static final long serialVersionUID = 1L; // 上传文件的大小 protected long MAX_SIZE = 1000000; // 定义允许上传的文件的扩展名 protected String[] FILETYPES = new String[]{\u0026#34;doc\u0026#34;, \u0026#34;xls\u0026#34;, \u0026#34;ppt\u0026#34;, \u0026#34;pdf\u0026#34;, \u0026#34;txt\u0026#34;, \u0026#34;rar\u0026#34; , \u0026#34;zip\u0026#34;}; // 定义上传文件保存目录路径 protected String UPLOAD_PATH = \u0026#34;\u0026#34;; protected String id = \u0026#34;\u0026#34;; protected String attachTitle = \u0026#34;\u0026#34;; protected boolean isFlag = false; protected String tempTitle = \u0026#34;\u0026#34;; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;text/html; charset=UTF-8\u0026#34;); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter(\u0026#34;UPLOAD_PATH\u0026#34;); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg(\u0026#34;你还没设置上传文件保存的目录路径!\u0026#34;)); return; } //判断是否设置了上传文件的大小 if(this.getInitParameter(\u0026#34;MAX_SIZE\u0026#34;) != null){ MAX_SIZE = Integer.parseInt(this.getInitParameter(\u0026#34;MAX_SIZE\u0026#34;)); } //判断是否设置了上传文件的类型 if(this.getInitParameter(\u0026#34;FILETYPES\u0026#34;) != null){ FILETYPES = toArray(this.getInitParameter(\u0026#34;FILETYPES\u0026#34;)); } // 文件保存目录路径 String uploadPath = new StringBuffer(request.getSession().getServletContext().getRealPath(\u0026#34;/\u0026#34;)).append(savePath).toString(); // 文件保存目录URL String saveUrl = new StringBuffer(request.getContextPath()).append(\u0026#34;/\u0026#34;).append(savePath).toString(); if(!ServletFileUpload.isMultipartContent(request)){\tout.println(alertMsg(\u0026#34;请选择要上传的文件。\u0026#34;)); return; } //检查目录 File uploadDir = new File(uploadPath); if(!uploadDir.isDirectory()){ out.println(alertMsg(\u0026#34;上传目录不存在。\u0026#34;)); return; } //检查目录写权限 if(!uploadDir.canWrite()){ out.println(alertMsg(\u0026#34;当前角色对上传目录没有写权限。\u0026#34;)); return; } FileItemFactory factory = new DiskFileItemFactory(); ServletFileUpload upload = new ServletFileUpload(factory); upload.setHeaderEncoding(\u0026#34;UTF-8\u0026#34;); String temp = null; String ext = null; try{ List\u0026lt;?\u0026gt; items = upload.parseRequest(request); Iterator\u0026lt;?\u0026gt; itr = items.iterator(); while (itr.hasNext()) { FileItem item = (FileItem) itr.next(); String fileName = item.getName(); temp = (String) item.getName(); if(temp != null \u0026amp;\u0026amp; !isFlag){ temp = temp.substring(temp.lastIndexOf(\u0026#34;\\\\\u0026#34;)+1); tempTitle = temp; isFlag = true; } // KindEditor编辑器的ID if(((String)item.getFieldName()).equals(\u0026#34;id\u0026#34;)){ id = item.getString(); } // 上传图片的重新提示 if(((String)item.getFieldName()).equals(\u0026#34;attachTitle\u0026#34;)){ attachTitle = item.getString(); if(attachTitle != null){ attachTitle = new String(attachTitle.getBytes(\u0026#34;ISO8859-1\u0026#34;),\u0026#34;UTF-8\u0026#34;); } } if (!item.isFormField()) { //检查文件大小 if(item.getSize() \u0026gt; MAX_SIZE){\tout.println(alertMsg(\u0026#34;上传文件大小超过限制。\u0026#34;)); return; } //检查扩展名 String fileExt = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;) + 1).toLowerCase(); if(!Arrays.\u0026lt;String\u0026gt;asList(FILETYPES).contains(fileExt)){ out.println(alertMsg(\u0026#34;上传文件扩展名是不允许的扩展名。\u0026#34;)); return; } // 根据时间创建文件夹 SimpleDateFormat folderNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMdd\u0026#34;); String realPath = uploadPath + folderNameFormat.format(new Date()); File folder = new File(realPath); boolean flag = folder.exists(); // 确认文件夹是否已经存在 if(!flag){ flag = folder.mkdir(); } // 创建文件夹并上传图片 if(flag){ SimpleDateFormat fileNameFormat = new SimpleDateFormat(\u0026#34;yyyyMMddHHmmss\u0026#34;);\tString newFileName = fileNameFormat.format(new Date()) + \u0026#34;_\u0026#34;+ new Random().nextInt(1000) + \u0026#34;.\u0026#34; + fileExt;\tFile uploadedFile = new File(realPath, newFileName);\titem.write(uploadedFile); saveUrl += folderNameFormat.format(new Date()) + \u0026#34;/\u0026#34; + newFileName;\text = fileExt; }else{ System.out.println(\u0026#34; 文件夹创建失败，请确认磁盘没有写保护并且空件足够\u0026#34;); }\t} } if(attachTitle == null || attachTitle.isEmpty()){ attachTitle = tempTitle; } out.println(insertAttach(id, saveUrl, attachTitle, ext)); }catch(Exception e){ e.printStackTrace(); }finally{ out.flush(); out.close(); isFlag = false; } } /** * 输出打印上传失败语句的脚本 * * @param message 失败信息 * * @return 页面打印的脚本语句 */ public String alertMsg(String message){ StringBuilder sb = new StringBuilder(\u0026#34;\u0026lt;html\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;head\u0026gt;\u0026#34;).append(\u0026#34;\u0026lt;title\u0026gt;error\u0026lt;/title\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;meta http-equiv=\\\u0026#34;content-type\\\u0026#34; content=\\\u0026#34;text/html; charset=utf-8\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;/head\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;body\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;script type=\\\u0026#34;text/javascript\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;alert(\\\u0026#34;\u0026#34;).append(message).append(\u0026#34;\\\u0026#34;);history.back();\u0026lt;/script\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;/body\u0026gt;\u0026#34;).append(\u0026#34;\u0026lt;/html\u0026gt;\u0026#34;); return sb.toString(); } /** * 输出插入附件至编辑器语句的脚本 * * @param id 编辑器ID * * @param url 上传附件的地址 * * @param title 上传时设置的title属性 * * @param ext 上传文件的后缀名 * * @return 插入附件至编辑器的脚本语句 */ public String insertAttach(String id, String url, String title, String ext){ StringBuilder sb = new StringBuilder(\u0026#34;\u0026lt;html\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;head\u0026gt;\u0026#34;).append(\u0026#34;\u0026lt;title\u0026gt;Insert Accessory\u0026lt;/title\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;meta http-equiv=\\\u0026#34;content-type\\\u0026#34; content=\\\u0026#34;text/html; charset=utf-8\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;/head\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;body\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;script type=\\\u0026#34;text/javascript\\\u0026#34;\u0026gt;\u0026#34;); sb.append(\u0026#34;parent.KE.plugin[\\\u0026#34;accessory\\\u0026#34;].insert(\\\u0026#34;\u0026#34;).append(id).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;); sb.append(url).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;).append(title).append(\u0026#34;\\\u0026#34;,\\\u0026#34;\u0026#34;).append(ext).append(\u0026#34;\\\u0026#34;);\u0026lt;/script\u0026gt;\u0026#34;); sb.append(\u0026#34;\u0026lt;/body\u0026gt;\u0026#34;).append(\u0026#34;\u0026lt;/html\u0026gt;\u0026#34;); return sb.toString(); } /** * 输出允许上传图片类型的数组 * * @param filesType 允许上传的图片类型 * * @return 允许上传图片类型 */ public String[] toArray(String filesType){ if(filesType == null){ return null; } String[] types = filesType.split(\u0026#34;,\u0026#34;); String[] allowTypes = new String[types.length]; int i = 0; for(String type : types){ allowTypes[i] = type; i++; } return allowTypes; } } 图像压缩代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 package com.elkan.utils; import java.awt.Image; import java.awt.image.BufferedImage; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import javax.imageio.ImageIO; import com.sun.image.codec.jpeg.JPEGCodec; import com.sun.image.codec.jpeg.JPEGImageEncoder; /** * 对图片进行处理的方法 * * @author SENHUI */ public class ImageUtil { public static int ImgWidth = -1; public static int ImgHeight = -1; /** * 压缩图片 * * @param imgsrc * 源文件 * @param imgdist * 目标文件 * @param widthdist * 宽 * @param heightdist * 高 */ public static void resizeImg(String imgsrc, String imgdist, int widthdist, int heightdist) { try { File srcfile = new File(imgsrc); if (!srcfile.exists()) { return; } Image src = ImageIO.read(srcfile);\tImgWidth = src.getWidth(null); ImgHeight = src.getHeight(null); if(ImgWidth \u0026lt; widthdist){ widthdist = ImgWidth; }else{ ImgWidth = widthdist; } if(ImgHeight \u0026lt; heightdist){ heightdist = ImgHeight; }else{ ImgHeight = heightdist; } BufferedImage tag = new BufferedImage(widthdist, heightdist,BufferedImage.TYPE_INT_RGB);\ttag.getGraphics().drawImage(src.getScaledInstance(widthdist, heightdist,Image.SCALE_SMOOTH), 0, 0, null); FileOutputStream out = new FileOutputStream(imgdist); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(tag); out.close(); } catch (IOException ex) { ex.printStackTrace(); } } } 呵，源码发布就到此了，上面有都有比较详细的注释文档了，相信各位可以看个明白吧。现在大家有什么自定义的功能要开发的就拿去用吧，别忘记把你开发出来的东东分享下哦，我在此恭候你的大驾光临啊，嘻嘻…… 不管你对此文章满意与否都留下个印记吧，下次用得上时好来取呀，呵。对了最后再给大家留道作业吧，怎么样把上传的附件进行分类管理呢？比如：word放到word文件夹目录………(此功能已经实现，不过公布的代码里没有，大家思考下吧，看看谁的方法最优化，呵)\nPS: 对一些提问的回答\n为何在Struts2里面不能使用？ 答：在项目开发中一般配置Struts2的过滤映射是全部站资源，修改成只要过滤你的Struts2访问资源便可。 (现在源码公布了，你们可以把那些上传方法写到Action里面)\n到处都是定义上传类型, 是不是很累赘啊？ 答：在web.xml配置上传类型是当初发布时考虑到重用性的问题，再说默认的上传文件类型应该够用了吧，只要限定大小与保存路径便可了；在JSP页面初始化编辑器定义上传文件类型是为了上传前的JS脚验证，如果说这都很麻烦，那我也没办法了。\n能否添加代码高亮功能？ 答：当初改版这个编辑器时的出发点是为适合我们的项目，所以这个功能没有考虑，不过网上有没有代码高亮插件，可自行参考设计下。\n能否粘贴word文档里面的图片？ 答：这个功能还真是没有哦，我对WEB前端不是很熟悉，不过我倒是开发出表格合并的功能，目前还在测试阶段。如能开发这个图片粘贴的话就好了，不过好像要插件支持才行吧，唉，windows的东西不太好玩呀。\n","date":"2011-10-17T22:10:20+00:00","updated":"2011-10-17T22:10:20+00:00"},{"permalink":"/tech/myeclipse-chinese-tool.html","title":"MyEclipse6.5+ IDE汉化软件","content":"世界上的语言与文字都有千百万种，但始终还是觉得我们的方块汉字比较好看且比较有内涵。而在计算机领域一直都是被国外主宰，所以很多计算机上的程序都是英文版的，有时候用起来还真是不太方便的，于是便出现了一大批汉化版的程序，这些程序都受到了国人的偏爱。\n在JAVA界的开发工具中使用最多的IDE莫过于Eclipse与MyEclisep，而这两款IDE的开发者均为外国人，所以IDE的界面为英文也就不足为奇了。作为另个一款后起之秀Netbeans开发工具我想是比较受国内编程初学者的喜爱，为何？很简单它的界面支持中文。\n还是先转回我们今天的主题MyEclisep汉化程序吧，Eclipse的汉化就不用多说了，自己直接去官网下载个语言包便可以实现中文界面，但MyEclipse就没有那么简单了，以前曾在网上找到一个牛人写的汉化包，试用了下效果还不错，不过就是步骤有点麻烦，昨晚突发奇想能不能把它做个傻瓜化的汉化程序呢？想了想觉得可行度有70%左右，最终衡量下还是决定CODE，最终在大约3个小时后便成功做出这个汉化程序，界面效果如下：\n如果你觉得有需要就下载个回去用用看吧，下面来说说这个软件的使用方法：\n直接解压下载下来的压缩包，记得不要破坏目录结构不然就无法汉化了，双击MyEclipse汉化软件(透明).exe(这个需要最新版本JDK)或MyEclipse汉化软件(无透明).exe；\n浏览并选取MyEclipse安装根目录下的Common目录，这个要视你的安装位置而定；\n浏览并选取bundles.info(插件指定)文件，此文件目录下\\MyEclipse ...\\configuration\\org.eclipse.equinox.simpleconfigurator目录下；\n浏览并选取myeclipse.ini文件，些文件在\\MyEclipse ...目录下；\n点击开始汉化按钮后，如果成功便会出现下面的成功提示，现在你重启下MyEclipse程序看看，最好用-clean命令；\n看看汉化后的MyEclipse界面吧：\n可能是因为汉化包有点旧的原故吧，所以并不是完全汉化的，如果说你有比较好的汉化包，希望你能与大家分享下。最后要说的是，如果你觉得汉化的效果不理想又想还原英文界面的话，只要恢复对应文件夹目录下的bundles_backup.info与myeclipse_backup.ini文件重启下MyEclipse软件就可以了。\n好了汉化工作就到此结束了，现在大家想说些什么就跟帖拍砖吧。\n","date":"2011-05-16T13:28:20+00:00","updated":"2011-05-16T13:28:20+00:00"},{"permalink":"/tech/kindeditor-jsp-source.html","title":"开放JSP版KindEditor的附件JAR包源码","content":"3月份的时候写了个JSP版本的kindeditor编辑器的帖子，没有想到大家的响应会这么强烈。不过随着日月的增长，此版本的插件也就暴露出一些BUG，如：Struts2如何集成，web.xml文件中配置上传属性不便修改且繁琐，上传图片(附件)不能保存于其它盘…………。现在平时开发的项目中都是使用KE作为在线编辑器，为了能更好、更方便的使用此编辑器，在休息的时间对原先的代码进行重构再封装，除对上个版本出现的BUG进行外，还统一整体的命名规范，新增了一些功能。\n当前新版本插件的版本号为：kindeditor-plugin0.4RELEASE，JAR包中类的列表如下：\n此次重构所完成的功能主要有以下几点：\n重构上传附件页面的选择按，仿图片上传的选择按钮； 增加Struts2环境集成； 增加上传属性配置功能，方便站点布署修改(暂未开放)； 增加其它盘存储功能，可自由选择存放位置方便备份(暂未开放)； 增加上传图片的文字水印功能(暂未开放)； 更Kindeditor编辑版本为3.5.6； 上传附件分类管理 如果你要把这个KE插件应用到你的项目中，很简单，如是Servlet环境只须一个步骤即可，Struts2环境则需要两个步骤，具体如下：\nServlet环境：只需要在web.xml中配置如下的参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;KEUploadImgServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.elkan.kindeditor.servlet.plugin.KEUploadImgServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;IMGSAVEPATH\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/upload/image/\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 缺省上传图片大小 \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;MAXSIZE\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;1048576\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; 缺省上传图片类型 \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;IMGTYPES\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;jpg,jpeg,png,gif,bmp\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; 缺省不压缩图片 \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;MAXWIDTH\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;MAXHEIGHT\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; --\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;KEManageImgServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.elkan.kindeditor.servlet.plugin.KEManageImgServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;IMGSAVEPATH\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/upload/image/\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;KEUploadAttachServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.elkan.kindeditor.servlet.plugin.KEUploadAttachServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;ATTACHSAVEPATH\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/upload/attach/\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 缺省上传附件大小 \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;MAXSIZE\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;10485760\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; 缺省上传附件类型 \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;ATTACHTYPES\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;**\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; --\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;KEUploadImgServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/keplugin/KEUploadImg.servlet\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;KEManageImgServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/keplugin/KEManageImages.servlet\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;KEUploadAttachServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/keplugin/KEUploadAttach.servlet\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;welcome-file-list\u0026gt; \u0026lt;welcome-file\u0026gt;index.jsp\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;login-config\u0026gt; \u0026lt;auth-method\u0026gt;BASIC\u0026lt;/auth-method\u0026gt; \u0026lt;/login-config\u0026gt; \u0026lt;/web-app\u0026gt; Jsp页面上KindEditor JS脚本配置[Servlet版本]：\n1 2 3 4 5 6 7 8 9 10 11 KE.show({ id: \u0026#34;editorServlet\u0026#34;, resizeMode: 0, allowFileManager : true, imageUploadJson: \u0026#34;/KEPlugin/keplugin/KEUploadImg.servlet\u0026#34;, fileManagerJson: \u0026#34;/KEPlugin/keplugin/KEManageImages.servlet\u0026#34;, //缺省为 *.*表示所有类型文件 //accessoryTypes: \u0026#34;doc|docx\u0026#34;, accessoryUploadJson: \u0026#34;/KEPlugin/keplugin/KEUploadAttach.servlet\u0026#34; }); Struts2环境：先在web.xml中配置Struts2，如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemalocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;struts2\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;struts2\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.action\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; \u0026lt;welcome-file-list\u0026gt; \u0026lt;welcome-file\u0026gt;index.jsp\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;/web-app\u0026gt; struts.xml文件配置，如下：（如设置了拦截器，请设置拦截器允许通过类型为KEStruts2Plugin的ACTION）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026lt;!--?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?--\u0026gt; \u0026lt;struts\u0026gt; \u0026lt;constant name=\u0026#34;struts.i18n.encoding\u0026#34; value=\u0026#34;UTF-8\u0026#34;\u0026gt;\u0026lt;/constant\u0026gt; \u0026lt;constant name=\u0026#34;struts.action.extension\u0026#34; value=\u0026#34;action\u0026#34;\u0026gt;\u0026lt;/constant\u0026gt; \u0026lt;constant name=\u0026#34;struts.configuration.xml.reload\u0026#34; value=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/constant\u0026gt; \u0026lt;constant name=\u0026#34;struts.multipart.saveDir\u0026#34; value=\u0026#34;\\temp\u0026#34;\u0026gt;\u0026lt;/constant\u0026gt; \u0026lt;constant name=\u0026#34;struts.multipart.maxSize\u0026#34; value=\u0026#34;104857600\u0026#34;\u0026gt;\u0026lt;/constant\u0026gt; \u0026lt;package name=\u0026#34;KEPlugin\u0026#34; extends=\u0026#34;struts-default\u0026#34; namespace=\u0026#34;/keplugin\u0026#34;\u0026gt; \u0026lt;action name=\u0026#34;keUploadImg\u0026#34; class=\u0026#34;com.elkan.kindeditor.struts2.plugin.KEUploadImgAction\u0026#34;\u0026gt; \u0026lt;!-- 缺省不压缩图片 --\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;maxWidth\u0026#34;\u0026gt;\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;maxHeight\u0026#34;\u0026gt;\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;!-- 缺省上传图片大小 --\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;maxSize\u0026#34;\u0026gt;102400\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;!-- 缺省为jpg,jpeg,png,gif,bmp类型图片 --\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;imgTypes\u0026#34;\u0026gt;jpg,jpeg,png,gif,bmp\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;param name=\u0026#34;imgSavePath\u0026#34;\u0026gt;/upload/image/\u0026lt;/param\u0026gt; \u0026lt;/action\u0026gt; \u0026lt;action name=\u0026#34;keUploadAttach\u0026#34; class=\u0026#34;com.elkan.kindeditor.struts2.plugin.KEUploadAttachAction\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;attachSavePath\u0026#34;\u0026gt;/upload/attach/\u0026lt;/param\u0026gt; \u0026lt;!-- 缺省上传附件大小 --\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;maxSize\u0026#34;\u0026gt;10485760\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;!-- 缺省上传附件类型 --\u0026gt; \u0026lt;!--\u0026lt;param name=\u0026#34;attachTypes\u0026#34;\u0026gt;*.*\u0026lt;/param\u0026gt;--\u0026gt; \u0026lt;/action\u0026gt; \u0026lt;action name=\u0026#34;keManagerImages\u0026#34; class=\u0026#34;com.elkan.kindeditor.struts2.plugin.KEManageImgAction\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;imgSavePath\u0026#34;\u0026gt;/upload/image/\u0026lt;/param\u0026gt; \u0026lt;/action\u0026gt; \u0026lt;/package\u0026gt; \u0026lt;/struts\u0026gt; Jsp页面上KindEditor JS脚本配置[Struts2版本]：\n1 2 3 4 5 6 7 8 9 10 11 KE.show({ id: \u0026#34;editorStruts2\u0026#34;, resizeMode: 0, allowFileManager : true, imageUploadJson: \u0026#34;/KEPlugin/keplugin/keUploadImg.action\u0026#34;, fileManagerJson : \u0026#34;/KEPlugin/keplugin/keManagerImages.action\u0026#34;, //缺省为 *.*表示所有类型文件 //accessoryTypes: \u0026#34;doc|docx\u0026#34;, accessoryUploadJson: \u0026#34;/KEPlugin/keplugin/keUploadAttach.action\u0026#34; }); 此次还借助JQuery EasyUI和SyntaxHighlighter语法高亮插件写了应用示例，下面我们就先来预览下Kindeditor在EasyUI模式下的清爽身影吧，闪亮登场……\n应用示例首页 Servlet版本的KE Struts2版本的KE 附件上传页面 上传图片管理 KE编辑器预览效果 其它更多详细的应用功能，详细请见附件下载。最后要记得要支持国产技术发展呀，有意见请你拍砖吐槽。\nPS： 下载KindEditor应用示例下载 把下载的压缩包上解压到Tomcat服务器的webapps目录下，启动Tomcat服务器，打开浏览器在地址栏输入：http://localhost:端口号/KEPlugin/index.jsp 就可以看到上面截图的应用示例了，Congratulation!\n","date":"2011-05-05T09:32:12+00:00","updated":"2011-05-05T09:32:12+00:00"},{"permalink":"/tech/kindeditor-jsp-complete.html","title":"JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)","content":"在此之前我一直都是在用FCKEditor在线编辑器，当然也有用过其它在线编辑器如eWebEditor,tinyMCE,CuteEditor，jHtmlArea等等，但在最终项目发布的时候并没有采用它们，因为它们要不是皮肤呆板，就是配置太烦琐，或是功能太少、浏览器兼容性不好等等。去年一个偶然的机会让我认识了KindEditor这款在线编辑器，正如它的名字那样这是款友好的编辑器，它不仅体积小配置简单，而且功能与皮肤也是令人相当的振憾。还有个很重要的因素，它是我们国人的开发的免费工具，从产品发布至今更新脚步未曾停止哦。下面就会大家介绍下经过我完善后的KindEditor吧。\n目前官方网站已经将KindEditor更新到了3.5.2版，从3.4的版本开始官方就去除了一些不常用的功能改用plugin形式来丰富KindEidtor，这就为我们打造个性的插件奠定了基础。其实只要是你的JS基础够扎实，花点时间看看KindEditor的源码，你就完全可以在其原有的基础上完善出你所想要的功能。下面是我的完善记录：\n集合了日期、时间、在线预览和特殊字符插件,采用3.0皮肤；\n将图片上传与管理的JSP页面改写成SERVLET，同时去除JSON包；\n添加图片压缩功能，对超出的宽高压缩成指定的值；\n添加上传附件功能；\n添加图片、附件按日期文件夹分类管理的功能；\n添加上传图片、附件的title属性，缺省为原文件名；\n添加上传附件相关的初始属性\n修改从word粘贴样式，减少样式。\n关于如何使用我就不多说了，官方网站上有详细的API，文章最后我也会给出经我完善的KindEditor还有Demo，先来看看效果吧。\n完善后的KE目录 完整功能示 浏览服务目录 附件展示效果 与Extjs整合效果 最后要说的是这款编辑器真的很不错，相信你用过它后一定会喜欢上它的，呵呵，多多支持国内软件事业的发展吧。\nPS: 示例源码下载 ","date":"2011-03-24T21:17:53+00:00","updated":"2011-03-24T21:17:53+00:00"},{"permalink":"/tech/jquery-ajax-struts2.html","title":"关于Struts2与Jquery实现无刷新分页的不解问题","content":"我最近正在做一个无刷新的网站管理后台，并把它作为我的毕业设计主题，不过在代码实现上遇到了点小问题，想向大家请教一二。我的设计思路大概是这样的：将后台所生成的数据用JSON的格式输出，在前台借助JQUERY的AJAX功能将传过来的数据写出。这样的方式在实现数据的增、改、删功能上并不会很难，不过在数据的查询方面便麻烦了，如何实现数据的无刷新分页呢？我查阅网上一些网友的做法，不过普遍发现他们的代码有点繁琐也不符合我设计初衷。通过查看JQUERY的API我自己想出了一种可行的方案(目前已经实现部分功能)：在查询的页面中先创建一个无数据的表格样式，通过JQUERY的CLONE功 能在查询数据时复制这个表格的样式同时将后台传过的数据填充其中和移除那行无数据的样式表格。\n前台的JS相关代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 显示所查询的数据 function dataSource(){ $.ajax({ url:\u0026#34;${pageContext.request.contextPath}/jsonservlet\u0026#34;, type:\u0026#34;post\u0026#34;, data:{}, dataType:\u0026#34;json\u0026#34;, error:function(){alert(\u0026#34;服务器通讯失败，请稍后再刷新页面。 ^_^\u0026#34;);}, success:function(data){ insertTr(data); } }); } // 查询数据的分页跳转 function goPage(thePage){ $.ajax({ url:\u0026#34;${pageContext.request.contextPath}/jsonservlet\u0026#34;, type:\u0026#34;post\u0026#34;, data:{page:thePage}, dataType:\u0026#34;json\u0026#34;, error:function(){alert(\u0026#34;服务器通讯失败，请稍后再刷新页面。 ^_^\u0026#34;);}, success:function(data){ insertTr(data); } }); } // 填充表格中的每行数据 function insertTr(data) { //读取tr里数量 var r = $(\u0026#34;#datasource tr\u0026#34;).size(); var list = data.dataSource; $.each(list, function(i, r) { //克隆已有的表格样式及属性 var row = $(\u0026#34;#source\u0026#34;).clone(); //将数值填充至表格中 row.find(\u0026#34;#id\u0026#34;).text(r.id) row.find(\u0026#34;#name\u0026#34;).text(r.name); row.find(\u0026#34;#time\u0026#34;).text(r.time); //将此行添加到表格中 row.appendTo(\u0026#34;#datasource\u0026#34;); }); // 移除第一行，因为它只有样式没有数据 $(\u0026#34;#datasource\u0026#34;).children(\u0026#34;tr:first\u0026#34;).remove(); } 通过实践发现这个方案是可行的，不过出现了一个问题：在数据翻页时如何将当前的数据移除并将新数据填充到页面中呢？（即：在转到第2页时把当前第1页的数据移除并填充第2页的数据）我尝试了很多方法可仍是未能实现我想要的无刷新的分页效果，希望大家能帮我看看是哪里出问题了。谢谢。\nPS: (最后自行解决了，解决方案如下)\n1 2 var r = $(\u0026#34;#datasource tr\u0026#34;).size(); 只要在上面的代码后面增加如下的代码:\n1 2 3 4 if(r \u0026gt; 1){ $(\u0026#34;#datasource\u0026#34;).find(\u0026#34;tr:not(:first)\u0026#34;).remove(); } \u0026ldquo;代码下载\u0026rdquo; ","date":"2010-11-03T00:00:00+00:00","updated":"2010-11-03T00:00:00+00:00"},{"permalink":"/tech/jquery-ajax-struts1.html","title":"JQuery+Strusts1.x实现Ajax无刷新登录","content":"在当今技术发展日益成熟，人们除了追求技术创新与发展外，更多也关注到了与用户交互的便利性方面上。当程序员还在为前后数据交互刷新问题困惑时，AJAX 问世了，它以方便快捷的优越性博得了广大程序员的追捧。经过几年的发展，它也渐渐成为我们开发中必不可少的一件利器，下面我就来讲个Struts1 + Ajax的登录示例。\n所用的JS插件： JQuery1.3.2汉化版、JQuery.form2.43\n下面我们先来看看页面中核心的JS代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 function submitForm() { // 用jquery.form插件实现对表单数据系列化 var form = $(\u0026#34;form[name=AdminLoginForm]\u0026#34;); // 配置jquery.form中ajaxForm的参数 // success 操作成功时的回调函数 // resetForm 是否刷新表单 // dataType 接收服务器返回数据的类型, 有script, xml, json等 var options = { success: showResponse, resetForm: false, dataType: \u0026#34;script\u0026#34; }; // ajax发送表单数据到服务器 form.ajaxForm(options); return false; } //回调函数 function showResponse(responseText, statusText) { if (statusText == \u0026#34;success\u0026#34;) { alert(responseText); } else { alert(\u0026#34;由于通讯问题，请稍后再登录！\u0026#34;); } } 在上面的代码中我们可以发现通过JQuery和JQuery.form两款插件，我们只要短短的三行代码就可以实现与后台的数据交互。JQuery是一款功能很强大的JS插件，我个人也很喜欢，调用很方便，代码风格也不错。有空可以研究一下哦，呵呵……\n下面继续来看看struts的action的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public ActionForward execute(ActionMapping mapping, ActionForm form, HttpServletRequest request, HttpServletResponse response) throws Exception { // 输出的方式与编码格式 response.setContentType(\u0026#34;text/html; charset=utf-8\u0026#34;); PrintWriter out = response.getWriter(); // 获取表单数据 AdminLoginForm adminLogin = (AdminLoginForm) form; // 获取服务器产生的验证码 String validateCode = request.getSession().getAttribute(\u0026#34;validateCode\u0026#34;).toString(); try { // 判断用户输入的验证码是否正确 if (adminLogin.getVerifycode().equalsIgnoreCase(validateCode)) { // 用户名的状态 boolean isUser = false; // 验证用户名是否存在 if(!adminLogin.getUsername().equalsIgnoreCase(\u0026#34;elkan\u0026#34;)){ out.print(\u0026#34;你输入的用户名不存在，请重新输入！\u0026#34;); return null; }else{ isUser = true; } // 验证密码是否正解 if(adminLogin.getUserpswd().equalsIgnoreCase(\u0026#34;lisenhui2010\u0026#34;) \u0026amp;\u0026amp; isUser){ out.print(\u0026#34;登录成功！\u0026#34;); }else{ out.print(\u0026#34;密码错误，请重新输入！\u0026#34;); return null; } } else { out.print(\u0026#34;验证码输入错误请重新输入！\u0026#34;); return null; } } catch (Exception e) { out.print(e.toString()); } return null; } 最后还有下面的struts-config.xml的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;action-mappings\u0026gt; \u0026lt;action input=\u0026#34;/webstage/adminLogin.jsp\u0026#34; name=\u0026#34;AdminLoginForm\u0026#34; path=\u0026#34;/AdminLogin\u0026#34; scope=\u0026#34;request\u0026#34; type=\u0026#34;com.elkan.struts.actions.AdminLogin\u0026#34; validate=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/action-mappings\u0026gt; 说了那么多，下面先来看看通上面的代码所实现的效果吧：\n看到上面的效果，你是不是也想展示一下自己的身手呢，那就赶紧动手吧，相信有了上面的那些代码的提示做个DEMO应该不会很难吧，如果有什么问题的话可以留言给我。谢谢支持。\n","date":"2010-09-05T10:11:53+00:00","updated":"2010-09-05T10:11:53+00:00"},{"permalink":"/flinks.html","title":"友情链接","content":"如想要交换友情链接，请将本站信息加入到你的站点友情链接中：\n名称： 凡梦星尘空间站 说明： 再平凡的人也有属于他的梦想！ 站标： https://lisenhui.cn/imgs/avatar.png 网址： https://lisenhui.cn 并在评论区留下你的站点信息，格式参考如上，我会尽快在第一时间回复并添加友链，谢谢支持！ ❤️\n","date":"0001-01-01T00:00:00+00:00","updated":"0001-01-01T00:00:00+00:00"}]