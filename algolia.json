[{"objectID":"1731926169","permalink":"/tech/daocloud-proxy-for-docker-images.html","title":"DaoCloud道客提供的免费Docker镜像代理服务","content":"前段时间看到博友圈的小伙伴发表了篇名为：《 docker代理问题 》的分享，里面详细记录她是如何通过Cloudfare路由功能实现代理Docker镜像的服务，想要自己倒腾的小伙伴可以参考一二。当时看到她这篇文章，就想起年初时自己为Docker镜像代理而烦恼的情境，后来借助Google成功解决这问题，不过与前面这位博友的方法不同，是抱了某厂商的大腿直接使用，并没有自己去搭建和管理代理服务。\n注：“博友”是自己给一群爱好写博客的朋友们所起的简写描述，大家可千万别误会为是那赌博的群体呀。😂\n其实能够自己搭建代理服务也是甚好的，只是我们个人的精力有限呀，有时管理的事情太多了肯定是要有的放矢。而且个人也不太喜欢重复造轮子，往大说是为了减少碳排放保护地球，哈。所以我就偷懒了一下，直接寻找一个靠谱的厂商代理服务，直接套用即可。\n通过网络搜索的筛选和对比后，最终选择了道客作为自己的Docker镜像代理服务： public-image-mirror 。截止到现在已经平稳运行半年多啦，几乎所有的Docker镜像都能够在其代理服务上找到。这个服务是直接开源在Github上面托管的，关注的星星已经接近7千颗，管理员也是比较活跃的。而且大家如有特别的镜像使用需求，也可以提交PR来增加。选它的另外一点原因是，之前有关注到该公司的技术合作人 孙宏亮成为Docker核心项目代码维护者 ，加之该公司的技术中也是使用了Docker技术，综合判断这个项目的生命周期应该会相对稳定且长期些。\n注：这里也仅代表个人观点，在如今多变的经济形势下，也保不准哪天就会下线，大家还是祈祷它能够长命百岁吧，哈。\n与其他Docker镜像代理服务相类似，支持以下两种方式使用：\n方式1：添加域名前缀\n就是在使用Docker命令拉取镜像时，直接在镜像地址前面添加道客的代理服务域名，适合临时拉取或没有权限编辑配置文件时调用：\n1 2 3 4 docker.io/library/busybox | V m.daocloud.io/docker.io/library/busybox 或是\n1 2 3 4 docker.io/library/busybox | V docker.m.daocloud.io/library/busybox 方式2：修改配置文件\n为了不用每次拉取Docker镜像时，都要手敲上面那段代理域名，可以直接 …","date":"2024-11-18T18:36:09+08:00","updated":"2024-11-18T18:36:09+08:00"},{"objectID":"1731758555","permalink":"/life/make-my-favourite-food-through-taobao.html","title":"感谢万能淘宝让自己吃到喜欢的美食","content":"在客家人的餐桌上，很多食材都是可以用“酿”字来出炉，像酿豆腐、酿苦瓜、酿茄子等诸多美食，另外还有就是周一时自己突然嘴馋想吃的“酿粄”，不过其中有道关键的食材在菜场并没有见到过。于是想到那万能的淘宝网购，只是这菜名用普通话还真不知其称谓（学名），又是在度娘上面搜索一番，才知晓它的名字叫“荞头”，而且它的别称中尽是自己不认识的字，真是尴尬之至，原来一场美食旅行也可以让自己长了不少见识。\n学名：藠头（jiào），别名薤（xiè）、荞（qiáo）头等，为石蒜科葱属的一种多年生宿根草本植物。原产于中国，分布广泛，在朝鲜、日本以及东南亚等地均可见到，在部分欧洲及北美洲地区也有分布，在我国的种植的历史已经有3000~4000多年，几乎是与我国的历史文明一致。具备食用与药用价值，它甚至上过我们的国宴用来招待外国来宾。 突然才发现这“荞头”它算是根草本类植物，感情自己原来是喜欢吃草呢。😂\n在淘宝网上一阵搜索筛选后选定了其的一店家下单，还好没有踩雷收到的菜品与网上图片描述相差无异，而且给份量也是很足的，这年头能够信守诚信二字的商家值得称赞，所以收藏是必须的免得下回想吃又找不到。\n为了这道舌尖上的美食，周末也是起了大早去菜市场搜罗其他食材和配料， 吃好早餐后但开始动手准备，作这道美食还是有些费人工的，需要经过洗，切，炒，拌，煎等不同的工序后才能出炉上桌。具体的食材搭配如下：\n荞头：1kg 猪肉：1kg 花生米：300g 虾米：100g 糯米粉：1kg 面粉：600g 上述食材的处理方法各不相同，需要分别进行处理：\n荞头：\n将荞头摘除掉黄叶子部分并用清水洗净，把根茎和叶子两部分分离开，根茎需要切碎，叶子切成细小的段（也可根据自己的吃法调整切的长度），另外根茎也是需要下锅炒熟备用。\n猪肉：\n手工将猪肉切成细小的肉丁，这里不建议用机器切割（容易变成肉泥），手工的切出的口感会更好。同样也是需要下锅炒熟，可以根据个人口味需要加入调味品。\n个人觉得只需要添加食盐就可以，后续各种食材混合后，会激发出自然的美味。\n花生米：\n锅里水分烧干后转小火，把花生米直接放下去慢炒，直至闻到花生香味，且外衣的“红衣”可以撮破去除，注意要勤加翻炒，免得炒焦就不好。出锅后需要将它们捣碎，但注意不要太碎，类似肉丁的处理方式就可以。花生米的作用是增加香味同时让口感更好。\n虾米：\n用清水洗干净，控干水分后，用油稍微炸一下，转成 …","date":"2024-11-16T20:02:35+08:00","updated":"2024-11-16T20:02:35+08:00"},{"objectID":"1728990509","permalink":"/tech/wsl-running-unknow-error.html","title":"WSL运行时遇到未知异常错误无法使用","content":"现经常会使用WSL服务在Windows系统上搭环境进行新技术的探索，只是间隔了约2周时间没有用，结果今天临时想要验证某个服务时，发现WSL服务无法正常使用，尝试强制停止WSL进程，最后都把电脑重启好几次，但依旧很失望还是无法正常。着实也是把自己给惊到了，里面搭建的环境是否就全都作废丢失呢。最后在微软官方的帮助站点找到了解决办法，抱着活马当死马的心态尝试一把，庆幸是最终成功了。\n此次WSL服务报出的异常问题也是非常诡异，在进程管理中显示服务是正常在运行的，但当在Windows终端中输入wsl命令时，却提示正在完成升级，然后就直接报错退出，大致输出的错误信息如下：\n1 2 3 4 5 6 wsl --list WSL 正在完成升级... Could not write value to key \\SOFTWARE\\Classes\\Directory\\shell\\WSL. Verify that you have sufficient access to that key, or contact your support personnel. 更新失败(退出代码: 1603)。 错误代码: Wsl/CallMsi/Install/ERROR_INSTALL_FAILURE 然后在微软官方帮助站点上找到一篇类似问题： wsl \u0026ndash;install 报错：灾难性故障 ，里面提供相关的解决办法，大致的思路就是说注册表名称出错，只需要删除以下的WSL服务相关的注册表项，然后再重启下WSL服务重新查看列表，便可以看到之前搭建的环境依旧还在的。\n1 2 3 计算机\\HKEY\\_LOCAL\\_MACHINE\\SOFTWARE\\Classes\\Drive\\shell\\WSL 计算机\\HKEY\\_LOCAL\\_MACHINE\\SOFTWARE\\Classes\\Directory\\background\\shell\\WSL 计算机\\HKEY\\_LOCAL\\_MACHINE\\SOFTWARE\\Classes\\Directory\\shell\\WSL 注：如果你不确定删除是否有其它未知影响，可以将上述的注册表项直接重命名，等WSL服务恢复后再删除。 问题是解决好了，但回过头来想了许久，也不明白为何会遇到这样的情况，过去2周的时间里并没有安装或卸载过软件，或是对注册表进行操作，莫非这只是偶然的概率事件，只是自己运气非常不好，正好给碰上呢，真是丈二和尚摸不着头脑喽😅\n","date":"2024-10-15T19:08:29+08:00","updated":"2024-10-15T19:08:29+08:00"},{"objectID":"1725540833","permalink":"/tech/use-printf-encry-base64.html","title":"隐藏的换行符导致Base64加密解密失败","content":"平日里偶尔会在调用API服务时，需要对用户与密码认证信息进行Base64加密处理，一般都用网上的在线工具进行直接操作获取。但是在客户现场环境中并没有互联网访问权限，便只能是寻求其他方法来实现Base64加密操作。起初是使用Python中的base64模块进行加密，只是操作起来较麻烦些，因为不同客户环境不一样而且也不能拷贝外部文件进去，只能是在Python交互模式下手工敲些代码。可是长久以往并不是办法，后来便发现了Linux系统其实大部都自带Base64的模块，于是便开始探索如何在Linux系统中使用Base64模块进行加解密的操作方式。\n不过在尝试使用管道命令echo输出后调用base64命令进行加密，比如类似这样的操作命令：echo \u0026quot;ADMIN:123456\u0026quot; | base64，但当用加密认证信息访问API服务时，提示用户认证失败。通过对比之前使用Python的加密方式，发现两种方式加密后的字符串确实是不一样。参考结果如下：\n1 2 3 4 5 6 7 8 9 10 root@debian12:/# echo \u0026#34;ADMIN:123456\u0026#34; | base64 QURNSU46MTIzNDU2Cg== root@debian12:/# python Python 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import base64 \u0026gt;\u0026gt;\u0026gt; encry_pswd=\u0026#34;ADMIN:123456\u0026#34; \u0026gt;\u0026gt;\u0026gt; encode_pswd=base64.b64encode(encry_pswd.encode(\u0026#39;utf-8\u0026#39;)) \u0026gt;\u0026gt;\u0026gt; print(encode_pswd.decode(\u0026#39;utf-8\u0026#39;)) QURNSU46MTIzNDU2 可以看出来这里的两种方式加密的字符串看起来是很相似，但是仔细对比会发现末尾并不一样。一番探索后找到问题的“元凶”竟是因为在使用echo命令输出时，在字符串末尾会自动添加一个换行符，从而改变了加密内容，便导致加密后的字符串不一致。修复的方式就是在echo 命令后面添加一个-n参数，禁止输出时添加换行符。参考如下：\n1 2 root@debian12:/# echo -n \u0026#34;ADMIN:123456\u0026#34; | base64 QURNSU46MTIzNDU2 只是每次进行加密操作都要记得输入这个参数，着实还是有点麻烦，于是便想到了使用printf命令来实现，参考如下：\n1 2 root@debian12:/# printf \u0026#34;ADMIN:123456\u0026#34; | base64 QURNSU46MTIzNDU2 问题到此总算是完美解决，也推荐使用printf命令来实现Base64加密操作，不仅不再用担心忘记添加-n参数，而且printf命令还有更多丰富的功能可以引用。\n注：在此只是简单的加密用户认证信息，并不涉及到大量的信息输出，所以完全不用担心 printf 命令的效率问题。 ","date":"2024-09-05T20:53:53+08:00","updated":"2024-09-05T20:53:53+08:00"},{"objectID":"1725016271","permalink":"/tech/mysql-login-without-userpswd.html","title":"MySQL自带客户端直接免密登录操作","content":"如我们所熟悉的MySQL服务有很多优秀的界面型客户端工具，可以非常方便我们轻松地操作数据库。但是在某些情况下，比如在服务器终端操作时，我们只能通过MySQL提供的命令行操作，其中少不了的便是要输入用户和密码信息。而现在的安全要求对密码的策略也较为严格，导致我们设置的密码不仅长度长，而且还会比较复杂等，如果是要经常进行数据库访问操作的DBA或分析师来说，这无疑是个不好的交互体验。\n其实在Linux操作系统中也提供有一个功能，就是类似于那些界面型的MySQL客户端来一样，可以记住数数据库的用户密码信息，而且操作也是比较简单。只需要当前的用户的根目录下，创建一个名为 .my.cnf 的配置文件，并添加如下配置即可：\n1 2 3 4 5 [client] host=172.16.8.101 user=root password=\u0026#39;Admin@123\u0026#39; database=mysql 重点注意： 参考上面的配置可发现密码是用 单引号 括起来的，这是因为密码中可能会包含一些特殊字符，比如#、$等，如果不加单引号登录时会出现密码错误的情况，建议默认给所有密码都加上 单引号。 此时可以直接在Linux服务器的终端中敲入 mysql 命令来登录到数据库中，无需再输入用户名和密码信息。\n要是有多个数据库的连接信息想要配置，可以继续在该文件中添加新的section配置。为了方便识别和管理，可以给section起一个有意义的名字，比如说用需要访问的数据库名称来做名称，参考如下示例配置：\n1 2 3 4 5 6 7 8 9 10 11 [client] host=172.16.8.101 user=root password=\u0026#39;Admin@123\u0026#39; database=mysql [sys] host=172.16.8.101 user=root password=\u0026#39;Admin@123\u0026#39; database=sys 然后还需要创建个别名方便记忆和操作，需要当前用户下的.bashrc名称添加个新的alias配置，可以直接用下面一条命令来完成添加操作，请参考示例操作：\n1 echo \u0026#34;alias sys=\u0026#39;mysql --defaults-group-suffix=2\u0026#39;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc \u0026amp;\u0026amp; source ~/.bashrc 此时就可以直接在Linux服务器的终端中使用sys数据库名称伪命令登录到该数据库，然后开始其他所需要的操作。\n通过上述的一顿配置操作下来，便能在Linux服务器中通过默认的用户密码来登录到数据库进行操作，是不是很方便呢！\u0026#x1f604;\n警示：\n建议将.my.cnf配置文件的权限设置为600，不然登录时会出现权限拒绝的问题； 配置文件中所配置的密码信息，需要做好相关的安全保护措施，避免被他人恶意获取。 ","date":"2024-08-30T19:11:11+08:00","updated":"2024-08-30T19:11:11+08:00"},{"objectID":"1724069991","permalink":"/tech/delete-soft-link-on-linux.html","title":"Linux系统中删除目录软链接的注意项","content":"对于软链接的操作在Linux系统中还是较为常见，相当于是Windows系统中的快捷方式，平时经常会用它来做些类似mv命令重命名的操作，让些烦乱的文件管理更加的清晰些，比如源文件目录或文件名称太过冗余，可通过创建软链接进行简化，同时也是省去了文件的搬迁，大大提升了操作的效率。\n但此次遇到个奇怪的情况，就是当使用ln -sf命令更新软链接时，但不仅没有更新，而且还是在原软链接的源目录中生成一个奇怪的自链接目录，操作记录示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@debian12 soft-link]# tree -L 2 . ├── src │ ├── 1.txt │ └── 2.txt └── tar -\u0026amp;gt; src 3 directories, 2 files [root@debian12 soft-link]# mkdir src2 [root@debian12 soft-link]# touch src2/3.txt [root@debian12 soft-link]# ln -sf src2 tar [root@debian12 soft-link]# tree -L 2 . ├── src │ ├── 1.txt │ ├── 2.txt │ └── src2 -\u0026amp;gt; src2 ├── src2 │ └── 3.txt └── tar -\u0026amp;gt; src 4 directories, 4 files 临时想到的解决方案就是，要不使用rm命令删除原有软链接，再重新创建新的软链接，但由于习惯于使用Tab快捷键操作，结果把源目录的下的内容给删除，原因就是Tab快捷键时会在目录名称后面自动加上\\符号，导致“不知不觉”中就把目录下的文件清空，而非所预想的只是删除软链接。所以删除软链接时，特别是目录类型的软链接更是要注意这里的细节。\n而后也尝试了其他方案，发现使用ln -snf 命令能够成功更新已有软链接，对于这结果突然觉得有点无语，真的不知做何解释。以前都是使用ln -sf更新软链接是没有问题的，现在却是无法正确的执行，真是有点玄学的味道呀，哈！\u0026amp;#x1f604;\n以下是通过与ChatGPT交流后给出的回答，仅供参考（很遗憾AI的回答并没有解决问题）：\n使用 ln …","date":"2024-08-19T20:19:51+08:00","updated":"2024-08-19T20:19:51+08:00"},{"objectID":"1723551131","permalink":"/tech/java-security-cacerts-issue.html","title":"Java程序调用外网API时CA问题","content":"前面在配置一个Java应用程序的API调用功能，可当启用此功能参数后，发现API调用没能成功，跟进下后台的日志报错信息，找到如下三行关键栈日志：\n1 2 3 4 5 6 7 java.lang.RuntimeException: java.lang.RuntimeException: javax.net.ssl.SSLException: java.lang.RuntimeException: Unexpected errororithmParameterException: the trustAnchors parameter must be non-empty Caused by: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty Caused by: java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty 原来以为会是常见的问题很容易解决，结果没有想到网上搜索出来的方案有很多而且操作也是比较复杂，然而并不想花费太多时间来验证，所以都没有采用直接就放弃啦。\n重新思考可能发生的问题环节，回想起来当时构建Docker镜像的时候，使用的OpenJDK只是JRE解压版本（为了减小Docker镜像的大小），猜测大概是这个有相关的影响，找了其他非Docker环境下可正常运行的节点，首先是使用keytools命令检查了下其JDK里面的安全证书，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 keytool -list -keystore $JAVA_HOME/jre/lib/security/cacerts 输入密钥库口令: （直接回车键跳过） ***************** WARNING WARNING WARNING ***************** * 存储在您的密钥库中的信息的完整性 * * 尚未经过验证! 为了验证其完整性, * * 必须提供密钥库口令。 * ***************** WARNING WARNING WARNING ***************** 密钥库类型: JKS 密钥库提供方: SUN 您的密钥库包含 143 个条目 然后再切换回Docker环境中，检查了下解压版本JRE的安全证书，果然这里的密钥库是空的，但至于为何会是空的暂且不讨论，想的办法就是从系统中链接一个密钥库过去。正好使用的CentOS8的操作系统，找到自带的CA证书，直接创建个软链接过去，执行命令参考如下：\n1 ln -sf /etc/pki/ca-trust/extracted/java/cacerts $JAVA_HOME/jre/lib/security/cacerts 然后再尝试重新启动Java应用程序，发现API调用服务是可以正常的开始工作啦，这不知道算不算一种幸运的解法。不管怎么说问题是成功解决，所以特此记录并分享一下。\u0026#x1f389;\n不过需要注意的是，上面提到的CA证书文件并不是所有Linux发行版本系统中默认存在，请根据自己系统的实际情况直接查找。另外也可尝试从其它类似环境中拷贝过来，但需要具体测试才知道能否使用。（亲测是可正常使用，但如果是生产环境得谨慎些。） ","date":"2024-08-13T20:12:11+08:00","updated":"2024-08-13T20:12:11+08:00"},{"objectID":"1716203776","permalink":"/tech/how-to-restart-wsl2.html","title":"如何不关机重启WSL2恢复虚拟服务","content":"对于Windows系统WSL技术较熟悉的小伙伴对于WSL和WSL2两个版本间的架构差异应该都比较了解，有不少人可能都会吐槽WSL2其实是一种倒退，只不过今天我们不讨论这点，而是来分享下在使用WSL2服务遇到的问题，及亲测有效的解决方案。\n之前的分享中有提到过借助WSL2+Podman两者组合方案实现容器化环境搭建，后来在使用过程中却也是遇到了些问题。起初以为是Podman的技术原因还不成熟的原因，直到后来才发现是WSL2服务本身存在问题，进而导致容器环境无法正常使用。\n问题现象 平日里一般都会使用休眠来代替关机，之前未使用虚拟服务时也没有察觉出有何异常。只是有次开启了Podman里的容器，想在休眠恢复后再重新连接虚拟服务的容器服务系统，便遇到了无法访问的情况：终端命令一直卡住不动，没有任何报错和响应输出。\n解决方案 开始是只能无奈的关机重启再启动WSL2和Podman服务，只是这样会比较麻烦，得要重新启用需要使用的软件与文档。后来网上调研了些相关的处理办法，梳理出如下可用的方案（只需要4个步骤就可以恢复Podman的服务）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 1.停止虚拟服务 net stop vmms # 2.停止Liux子系统管理 net stop LxssManger # 3.停止WSL2虚拟服务 taskkill /f /im wslservice.exe # 4.启动Podman服务 podman machine start podman-vm # 5.进入WSL系统 podman machine ssh podman-vm 命令执行过程中的日志输出参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 C:\\Users\\用户名\u0026amp;gt;net stop vmms The Hyper-V 虚拟机管理 service is stopping. The Hyper-V 虚拟机管理 service was stopped successfully. C:\\Users\\用户名\u0026amp;gt;net stop LxssManager The LxssManager service is stopping. The …","date":"2024-05-20T19:16:16+08:00","updated":"2024-05-20T19:16:16+08:00"},{"objectID":"1710678802","permalink":"/tech/install-podman-container-on-win.html","title":"在Windows上安装Podman容器平台做虚拟化","content":"想起之前读大学的时候大家还在捣鼓如何在电脑上安装 Windows+Linux双系统，而如今微软早已发布了WSL（Windows Subsystem for Linux）的方案让两套系统可直接同时运行，真可谓是实现了鱼和熊掌同时可”兼得“。当然今天我们的主角并不是 WSL啦，只不过是需要基于此技术之上来进行操作，实现对我们想要使用的 Podman容器化管理平台支持。\n注：如电脑上还没开启 WSL功能的话，请自行搜索网上的教程启动，才能进行接下来的操作。\n先来简单说一下为何要捣鼓这个容器化的玩意儿吧，对于开发者来说它并不陌生，可以将复杂的开发环境打包成镜像进行分发来实现快速初始化，相信经历过电脑重装的同学都能深刻体会到一切重头再来的“痛苦”吧。除此之外对于很多刚接触Linux菜鸟来说，WSL虚拟的容器化技术也是为他们提供诸多的便利，再也不用重启操作在不同的操作系统间来回切换操作，也不需要担忧一不小心删除重要文件把系统搞崩掉。而我的初衷便是为能在Linux平台上部署些自己想了解的技术和产品，同时容器化能够很好的帮助我克隆和管理。\n但此次并没有选择大家都所熟悉的 Docker技术，在对比之后选取近期比较火热的 Podman技术，这点主要是从自已的初衷点出发考虑，也不想整个太臃肿的软件来满足这小部分的需求。\n下面直接引用红帽上对 Podman的说明来对它做个简单的介绍：\nPodman（全称 POD 管理器）是一款用于在 Linux® 系统上开发、管理和运行容器的开源工具。Podman 最初由红帽® 工程师联合开源社区一同开发，它可利用 lipod 库来管理整个容器生态系统。\nPodman 采用无守护进程的包容性架构，因此可以更安全、更简单地进行容器管理，再加上 Buildah 和 Skopeo 等与之配套的工具和功能，开发人员能够按照自身需求来量身定制容器环境。\n来源： redhat-what-is-podman 个人实践下来对它的理解就是：简单，上手快，资源消耗小。从操作性上来说，与Docker命令几乎是全兼容，而且也支持Docker的镜像，所以也不存在迁移工作之类问题。在Windows系统上使用Podman，相比较于Docker来说会更加轻便和快速。在此主要分享下个人的相关实践经验，帮助大家避免踩坑能更好的使用Podman。\n安装Podman 直接访问官方网站链接： …","date":"2024-03-17T20:33:22+08:00","updated":"2024-03-17T20:33:22+08:00"},{"objectID":"1709381127","permalink":"/tech/unmountd-mobile-disk-log.html","title":"记一次无法弹出移动硬盘的记录 ","content":"或许在当下云计算时代，已经很少有人会用到移动硬盘或U盘的经验，亦或者大多数人都没有弹出移动设备后再拨出的习惯。笔者因早年在使用U盘时经历过直接拨出U盘导致其报废的“惨痛”教训，因此对移出设备的操作是铭记于心，万不敢直接拨插移动设备。但就是这个只需点击一次移出设备的操作，很多时候就会让我们有些烦恼，因为它有时候总喜欢和你对着干。这不今天就遇上一件无法解释的诡异现象:移动硬盘无法弹出，尝试过之前的各种妙招后仍是无济于事，最后也只是能祭出万能的关机大法才算是得以解脱。\n仅以此文做个记录，也是给大家分享下当遇到无法弹出的怪兽时做个参考，下面的各项操作均是笔者亲测有效且实用的，大家可在遇到问题时，依照方法次序或选你熟悉的进行操作即可。\n首先简单的普及一下移动设备无法弹出的根本原因：*它正在被某些进程（软件）使用中，比如文件拷贝、杀毒软件扫描、磁盘修复等一些需要访问移动设备的操作，这也是为何强制拨出会有极大概率损坏设备的原因。所以想要移动设备能够正常的弹出，我们需要找出这些进程（软件），并让它们处于退出或终止状态，释放对移动设备的占用即可。 方法1：第三方软件 此方法是最为简单和快速的操作，就是通文件解锁软件（360xxx）自动扫描找出占用移动设备的进程，然后会将它们一个个终止处理，最后再点击弹出移动设备的操作即可。\n方法2：资源监视器 要是手头上没有方法1的软件，可使用Window系统自带的资源监视器来找到占用移动设备的进程，具体操作步骤如下：\n打开任务管理，找到性能选项卡，点击左下角的资源监视器链接 在弹出的对话窗口中，点击搜索句柄的文本框，输出移动设备的盘符搜索 选中搜索结果，单击鼠标右键，找到并点击结束进程，然后便可正常弹出 方法3：事件查看器 按Win+X组合键再按V字母进入事件查看器窗口，然后在左侧的自定义视图下打开管理事件，然后参考如下操作步骤，然后就可正常弹出移动设备。\n点击一下弹出移动设备的操作 在事件查看器窗口的操作菜单下点击刷新选项， 点击第一条事件信息，在常规选项卡中找到正在使用移动设备的进程号 打开任务管理器找到此进程，右击鼠标结束它 注：当你发现这里没有任何进程号的信息时，那么恭喜你，只能是用关机的办法来拨出移动设备。\n方法4：重新挂载磁盘 按Win+X组合键再按A字母进入CMD控制台，参考如下的操步骤输入命令，然后再点击弹出移动设备即可。 …","date":"2024-03-02T20:05:27+08:00","updated":"2024-03-02T20:05:27+08:00"},{"objectID":"1708827233","permalink":"/blog/add-friend-link-check-script.html","title":"为友情链接添加自动检测脚本","content":"友情链接是博客的重要组成部之一，很多博主日常也会时常进行链接的交换，即是发展自己的互联网友人圈子，也算得上是为自己的博客引流。不过在如今信息大爆炸的时代，也渐渐有些博主实在“有些乏力”来维护自己的站点，其中的缘由可能有诸多，最终便是出现我们偶尔会遇到的情况，某个站点突然之间可能就无法访问。为此便有想法给自己的站点添加个友情链接检测脚本，剔除掉那些已经失效的友情链接，让用户访问时的跳转体验更好加。\n方案设计 考虑到我们的博客站点是生成静态文件的部署方式，所以友情链接的检测频率也不会特别高，就是在每次发表新文章构建博客站点的时候检测一次。并结合Github Actions的CI流程可以实现自动化的处理，大致的流程如下：\ngraph TD; node1([fa:fa-play 开始 ]) --\u0026gt; node2[/站点内容更新or配置调整/] --\u0026gt; |fa:fa-upload Git提交\u0026amp;推送\u0026amp;触发GithubAction| node3[[fa:fa-scroll 调用脚本验证友链可访问性]] --\u0026gt; |fa:fa-trash-can-arrow-up 剔除无法访问的链接| node4[/fa:fa-list-check 生成新的友链配置文件/] --\u0026gt; node5[fa:fa-blog 构建构静态文件] --\u0026gt; node6([fa:fa-stop 结束 ]); 创建检测脚本 根据Hugo NexT主题中有关于友情链接的配置信息，我们可以获取到友链的具体URL地址，直接使用Get方法探查其可访问性，然后调整友链的状态标识，重新生成新的友情链接配置文件，具体的脚本代码可参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 …","date":"2024-02-25T10:13:53+08:00","updated":"2024-02-25T10:13:53+08:00"},{"objectID":"1699447040","permalink":"/tech/actived-github-2fa-auth.html","title":"重新激活Github的2FA认证","content":"近期有段时间没有登录 GitHub 仓库站点，今天查看邮箱发现 hugo-theme-next 项目上有新的 PR进来，便想上来查看下具体情况。结果发现Github官方已经全面启用2FA安全认证要求，只是之前自己“偷懒”并没有做这个功能的认证，原来还有可以使用密码方式绕过去的，但现在也关闭了此入口，难道真的要芭比Q啦。\n然后在Github帮助文档中找到有关于使用2FA的场景，官方描述如下：\nGitHub will only ask you to provide your 2FA authentication code again if you\u0026rsquo;ve logged out, are using a new device, are performing a sensitive action, or your session expires.\n翻译为：GitHub 仅在你退出登录后、使用新设备、执行敏感操作或会话过期时才会要求你再次提供 2FA 验证码。\n那也就是说其它设备登录过Github且没有退出或过期，还是有机会继续使用Github站点。抱着试试看的心态用手机打开浏览器（用的是iPhone手机平时后台都没有有关闭，没想到这时发挥大作用），发现果真上面Github站点还处于登录状态，跳转到 密码和认证 页面，找到 Authenticator app 设置项，发现旁边有个编辑的按钮，说明还有机会拯救。\n然后便参考官方的建议安装好Microsoft Authenticator手机APP，但在注册ID时发现它提供的扫码功能并不支持手机相册选取，只好再通过其他方式把手机截屏图片放到电脑上后再扫码注册，还好一切顺利。此时APP上便会显示出如下的动态验证码，把这个验证码输入到验证框内，完成验证才能算是正式生效。\n另外发现一款浏览器插件也很是实用： Authenticator ，可以尝试安装体验一下。\n当时看到验证码生成好，验证一下便以为是可以使用（确保一定要点击那个绿色的保存按钮才行），直接在电脑端的Github登录界面上输入，结果一直都是显示验证失败，最后尝试太多还被禁止登录😂。\n看上去Github此举是为了用户的安全保障，但是给用户增加了不少麻烦呀（大部分Github用户上面的项目都是开源，加上大家的Fork操作，也不用太担心有人存心恶意攻击吧），特别是那个备份还原码，万一真的弄丢想找回账户还真不容易的。而且世上也是没有绝对安全的系统，很多的系统设计就像人类打疫苗一样的道理，防范于未然而已。\n不过人家系统既然是这样的设计要求，那么我们也只能是遵守秩序，所以还没有开启F2A功能的小伙伴得抓紧啦，估计后续国内很多系统也会相应效仿吧。\n","date":"2023-11-08T20:37:20+08:00","updated":"2023-11-08T20:37:20+08:00"},{"objectID":"1698486728","permalink":"/tech/linux-tar-command-excludes-from.html","title":"Linux中使用tar压缩命令排除文件","content":"众所周知tar命令是在Linux系统中最为常用来解压缩文件的命令之一，之前大部分时候都直接用它来压缩备份或转移的文件内容，因此也未过多关注过它在压缩时的其它可选参数使用。但最近在转移文件遇到其占用空间比较大，考虑到里面有些内容并不是必须，于是想到如何来使用tar命令参数来实现，经过多次尝试，找到了个解决办法——使用exclude-from参数，可灵活控制不需要压缩文件，然后顺手做个记录分享。\n注：当排除的内容并不多时，也可以直接使用exclude参数会更方便些。\nexclude-from 参数的使用说明相对简单，其后面跟的是排除文件的路径。但是需要注意如下2种不同的情况：\n当排除文件的路径是相对路径时，压缩路径无论是相对路径还是绝对路径都可以； 当排除文件的路径是绝对路径时，压缩路径也必须是绝对路径。 接下来我们就准备个测试的文件夹和文件，整个目录结构如下，其中以exclude起头的文件夹或文件便是需要排除的内容：\n1 2 3 4 5 6 7 8 9 tar_excludes_demo/ ├── exclude_file.txt ├── exclude_folder │ └── tmp.txt ├── folder1 │ └── tmp.txt ├── folder2 │ └── tmp.txt └── readme.txt 根据参数说明的两种情况进行分类的测试验证：\n示例1 相对路径 我们先把需要排除的内容写到文本文件里面，如下：\n1 2 3 excludes_relative.txt tar_excludes_demo/exclude_file.txt tar_excludes_demo/exclude_folder 然后使用不同相对路径压缩办法测试下效果，加上v参数可以验证是否正确：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 任意目录压缩 tar --exclude-from /root/tar_demo/excludes_relative.txt -czvf tar_excludes_demo.tar.gz /root/tar_demo/tar_excludes_demo tar: Removing leading \u0026amp;#39;/\u0026amp;#39; from …","date":"2023-10-28T17:52:08+08:00","updated":"2023-10-28T17:52:08+08:00"},{"objectID":"1692433177","permalink":"/life/xiaomi-smart-band-8pro-experience.html","title":"继续小米手环的健康生活之旅","content":"其实吧现在人的生活压力还是比较大的，借助智能穿戴设备来观察自己的健康状态也是不错的选择。鄙人也是从小米手环1代发布时便开始关注自己的运动量和睡眠状态，随着时间和技术的发展也经历过更新换代。因为会经常在外健走运动的习惯，但是手环一直都是要和手机连接才能记录（位置）数据，所以正在纠结是否要换个手表设置算啦，正巧看到了8月14日雷布斯的小米手环8Pro发布会，而且还是现货出售，犹豫了片刻后便“冲动”的下了单😁。\n在简单上手了几天后，来说一下个人的使用感受吧：\n外观设计 确实此次小米手环8Pro的设计让人眼前一亮，改变了传统那种竖条的版式，换成类似手表的方形设计。而且它的外观上采用了金属质感，这不仅看起高端的质感，同样还是保持手环原有的轻盈感，使得佩戴体验更加舒适。\n屏幕像素 方形的屏幕设计在扩大显示区域的同时，也是提升分辨率达到了480*336可以实现336的PPI，达到了视网膜级的显示效果，即便是在太阳光照下依然能够显示非常清晰。\n息屏显示 延续小米手环8的息屏显示功能很实用，再也不用总是抬腕亮屏来查看时间，能像手表一样全天候显示时间、日期、运动数据等信息，还是比较实用的功能，再加上定时息屏和智能息屏设计，也可以为电池续航提升支持。\n独立GPS模块 保留了其它手环常规的功能，此次小米手环8Pro另一大亮点就是独立的GPS功能，终于可以在运动时不需要带手机出门，尽情的享受运动的快乐。虽然可能会让耗电速度有所加快，但是相比于手表那一天一冲还是要好一些，当前也是缺失不少高阶的功能，毕竟鱼和熊掌是不可能兼得，就个人而言还是更倾向于重量轻，续航时间长的手环做为健康记录的首选。\n提示：另外发现小米手环8 Pro还新增了3D运动指导动画（要是能配上声音就完美啦），会提示你在开始运动前要做好热身的指导，从而降低直接运动对身体带来的损害。 睡眠记录 对比了下原有小米手环6的睡眠记录，发现小米手环8Pro在算法有些不一样，比如在周末很多人都会有睡回笼觉的习惯，但是它总是会不记录你后面的睡眠时长，直接在你醒来后就结束了睡眠记录。而且你还不能像之前那样手动调整，不然就会把这一天所有的睡觉记录信息清除，只是一条单纯的记录信息，没有中间睡眠过程的详细信息。\n价格略高 现在官方的指导价格是399RMB，说实话这价位还是有点略高的，不过在前两天收到了用户调研问卷，里面提到是否觉得需要小游戏的功能，这似 …","date":"2023-08-19T16:19:37+08:00","updated":"2023-08-19T16:19:37+08:00"},{"objectID":"1687594242","permalink":"/life/did-your-phone-have-case-on.html","title":"一次意外的“坠机”引发了我对手机保护壳的深思","content":"原本是个开心的周末休息时光，但是手机的意外坠地带来的“伤痕”让我心情有点点不开心。曾经将它细心呵护保全一年多，没想到还是没有逃过磕碰的命运，都怪自己一时贪心想着拆卸下手机保护壳，好体验下手机真实的手感才会招此“横祸”。于是便写下此篇文章做个记录，及讨论下手机保护壳的必要性。先来提问下，你是否会时刻会你的手机戴上保护壳呢？\n现如今社会的人们都离不开手机，它也不再仅是电子产品这样简单，还更多的承担着重要的“职责”。所以说它的好坏也是会直接影响到我们的生活，如何保护好它变成为很有必要，比如手机保护壳就是其中一个重要的话题。\n对于手机保护壳，支持者们给出了很多有力的理由。他们坚信，保护壳是必要的，能够有效预防手机受损。急于感受手机轻巧、裸露的人们也要承认，自己偶尔会在手机跌落时心砰砰直跳。这种保护壳不仅可以防止刮擦、摔落、水渍等意外损伤，还能延长手机的使用寿命。毕竟，谁能忍受手机刚到手就因不慎掉落而遭受残酷的一击？\n然而，反对者提出了一些让人深思的观点。他们认为，手机保护壳是多余的。无论是增加手机的重量和体积，还是影响手机的散热和信号，甚至是遮挡手机原本的设计和颜色，都是他们反对的理由。这些人认为，手机应该以其自然之美展现在世人面前，不需要外界的保护伞。“看，这就是我的手机，如此光鲜亮丽！”他们那种洒脱的态度令人瞩目。\n在我的观点中，我认为这种双重角色的手机保护壳是有必要的。毕竟，手机对于很多人而言，已经不再仅仅是通讯工具，更是生活的一部分，它承载着我们的记忆、社交、工作和娱乐。在适当的时候，给手机穿上保护壳，就像是为自己的手机披上一件“防弹衣”，让我们的手机在面对各种可能的危险时，能够安然无恙。同时，我们也要在安全的环境中，给手机“休假”，让它光鲜亮丽地展现出美丽的外表。\n建议在安全的家中或者办公环境中，可以毫无拘束地拆卸保护壳，欣赏手机的设计之美，让它成为我们生活的一部分，体现个性与品味。而在外出旅行、户外运动或拥挤拥堵的场所，如公交车或地铁，我们可以将保护壳重新穿戴在手机上，这样即便手机不慎滑落，也能起到一层保护垫。这样的取舍，既能让我们享受手机设计之美，又能保障手机的使用安全，延长它的寿命。\n总之每个人都有不同的标准和偏好，没有绝对的对错。一方面，手机保护壳确实提供了一层安全保障，让我们避免无谓的损失和遗憾。另一方面，手机的美感和自然展现也是我们引以为傲的。因此，我 …","date":"2023-06-24T16:10:42+08:00","updated":"2023-06-24T16:10:42+08:00"},{"objectID":"1666523779","permalink":"/tech/use-powerful-css-selector-find-dom.html","title":"在JS中使用强大的CSS选择器来定位页面元素","content":"近期由于受到谷歌退出中国市场的影响，就连之前可以正常使用的翻译 API 也无法使用了。 无奈之下为不影响本站的加载速率，决定暂时关闭谷歌的在线翻译功能。\u0026amp;#x1f643;\n接着就发生了奇怪的现象，重新生成站代码发布完成后，自测是没有问题的，但是有网友反馈说站点访问加载不出来内容。听完自己也甚是一惊，难道是服务器出问题啦？\n连忙打开手机访问验证了下一切都是正常的，切换到电脑访问（用的是Edge浏览器）也是正常，难道真的是个别现象吗？然后又切换到火狐浏览器进行测试，结果还真是加载不出来内容，通过 F12 也快速定位到了的问题，是因为关闭了谷歌在线翻译功能后，按钮的注册事件失败，影响到了后续 JS 脚本的执行。\n看来发版的时候要多测试几款浏览器才行啦\n在 hugo-theme-next 主题最新版本中加入了右侧工具按钮的小功能，那自然是避免不了给按钮添加点击事件，来看下之前写的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 registerToolButtons: function() { document.getElementById(\u0026amp;#39;goto-comments\u0026amp;#39;).addEventListener(\u0026amp;#39;click\u0026amp;#39;, () =\u0026amp;gt; { window.anime({ targets : document.scrollingElement, duration : 500, easing : \u0026amp;#39;linear\u0026amp;#39;, scrollTop: document.getElementById(\u0026amp;#39;comments\u0026amp;#39;).getBoundingClientRect().top + window.scrollY }); }); /* 发生问题的代码 */ document.getElementById(\u0026amp;#39;goto-gt\u0026amp;#39;).addEventListener(\u0026amp;#39;click\u0026amp;#39;, () =\u0026amp;gt; { window.anime({ targets : document.scrollingElement, duration : 500, easing : \u0026amp;#39;linear\u0026amp;#39;, scrollTop: …","date":"2022-10-23T19:16:19+08:00","updated":"2022-10-23T19:16:19+08:00"},{"objectID":"1664872373","permalink":"/tech/automatic-upload-algolia-index-with-action.html","title":"结合 Github Action 实现自动上传 Algolia 索引","content":"起初本站的文章搜索功能使用是本地搜索支持，但后来发现有众多网友（包括 Hugo 官网文档搜索）都使用的是 Algolia 在线搜索引擎，便顺手也给自己的站点移植到该搜索引擎上面。既然提到搜索引擎自然是少了索引文件的维护，接下来就给大家分享下结合 Github Action 实现自动化的流程。\n索引内容 Algolia 采用较为松散的 JSON 数据结构支持，所以实现起来也相对比较轻松一些，也可以根据自己的需求进行个性化的设计。在此就博文查找而言，暂没有做复杂的设计，只是利列举了必要的字段信息，基于 Hugo 引擎的代码参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [ {{- range $index, $entry := where .Site.RegularPages \u0026amp;#34;Kind\u0026amp;#34; \u0026amp;#34;page\u0026amp;#34; }} {{- if $index }}, {{ end }} { \u0026amp;#34;objectID\u0026amp;#34;: \u0026amp;#34;{{ .Date.Unix }}\u0026amp;#34;, \u0026amp;#34;permalink\u0026amp;#34;: \u0026amp;#34;{{ .Permalink | relURL }}\u0026amp;#34;, \u0026amp;#34;title\u0026amp;#34;: {{ .Title }}, \u0026amp;#34;content\u0026amp;#34;: {{ .Plain | safeJS }}, \u0026amp;#34;date\u0026amp;#34;: {{ .Date.Format }}, \u0026amp;#34;updated\u0026amp;#34;: {{ .Lastmod.Format }} } {{- end }} ] 注意： 切记一定要给每个索引增加 objectID 参数，以确保索引的唯一性，而且后续的索引维护也是根据这个参数作为主键进行更新等相应的操作。 这里只是把博文显示的页面进行索引化，并没有对分类、标签、列表等做索引支持，查询的内容只针对文章页面本身就足够用啦。\n生成索引 Hugo 支持自定义文件的内容的输出，只需要几步简单的参数定义，比如在 config.yaml 配置文件中加入如下的设置：\n1 2 3 4 5 6 7 8 9 10 11 outputFormats: # 生成 Algolia 索引文件 AlgoliaIndexes: mediaType: application/json baseName: …","date":"2022-10-04T16:32:53+08:00","updated":"2022-10-04T16:32:53+08:00"},{"objectID":"1664458525","permalink":"/tech/implement-custom-switch-theme-color.html","title":"实现用户自定义主题深浅模式浏览站点","content":"如今大部的网站都实现了深浅主题2种不同模式的配色，比如说程序员大多喜欢深色模式，或许是需要长时间使用电脑，该模式能够一定程度上保护视力。从表面现象上来看，实现这一功能需要 CSS 和 JavaScript 两者搭配着一起使用，但当深入以后发现有些没料想的事情，且听我慢慢叙说。\n本博客主题是基于Hexo NexT移植过来的，在移植过程中就曾有注意在到在 _colors.scss 文件中存在一段 prefers-color-scheme: dark 媒体自适应代码，当时不太明白其中的具体的作用，只知道当配置文件中的参数 darkMode:true 便会增加这段代码渲染，但随着此次给主题增加深浅主题切换功能时，才发现其中的奥妙，也是让自己走了不少的弯路。\n在 MacOS 或 Windows10+ 系统中均支持配置深色和浅色两不的显示模式，前面提到的 prefers-color-scheme 正是可以感知系统的深浅模式配置，因此而产生相应的颜色变化。那么此时问题就出现了，如果选择了深色模式是不是就意味着，无法让站点站点显示出浅色效果呢？\n原本的想法就是希望通过 prefers-color-scheme 参数来调整配色，但通过一番的资料调查后发现，该参数居然不支持手动进行调整。那么就只好就此放弃，还是选择通过 CSS 选择器的方式，再加上对媒体查询/切换进行监听，从而实现自动根据系统主题色调整网页颜色模式。\n参考资源：\nedit-prefers-color-scheme-value-to-force-dark-mode how-to-override-css-prefers-color-scheme-setting forcing-dark-mode-with-prefs-color-scheme-media-query dark-mode-website-tutoria 确认好方案接下来就是流程细节的优化，考虑到用户切换主题后还是跳转到不页面浏览，那么就是需要使用到本地存储，将用户的切换主题的选择记录下来，以保持较好的用户体验。大致的流程设计如下：\ngraph LR; node1([fa:fa-play 开始 ])--\u0026gt;node2{系统或站点是否配置深色模式}--\u0026gt;|是|node3[变量设置为dark]--\u0026gt;node4{读取本地存储主题是否为浅色}--\u0026gt;|是|node5[变 …","date":"2022-09-29T21:35:25+08:00","updated":"2022-09-30T08:12:04+08:00"},{"objectID":"1663413219","permalink":"/tech/use-openresty-ghaction-remote-deploy.html","title":"Openresty+Github Action实现远程自动部署","content":"近期频发的收到云厂商关于服务器资源到期的提醒，当初为了躲避云厂商所谓的注册域名 IP 检测监控，无奈之下借着“新”用户的优惠政策，采购了一款最最实惠的云服务，周期为 1 年时间，如今也已是到了“寿终正寝”的时候啦， 因此不得已又要考虑给博客空间找新的部署服务器啦。后来得到热心朋友的资助，在其现有的云服务器上开辟了小空间提供给鄙人博客访问，真是感激万分呀！\n通常情况下云服务器上的安全策略都会管理的比较严格，为此原来想通过 SSH 远程执行部署站点方案便不太可行啦，其中主要的影响因素就是 Github Action 所提供的 CI/CD 服务，其执行时机器是完全随机分配的，那几乎就是等同于动态 IP， 而云服务器上面的安全组策略根本无法支持这么庞大的 IP 段设置，而且也不想劳烦朋友去调整这系统级别的安全设置，于是便想到通过 Nginx 来调用本地脚本进行远程部署的方案。\n方案的初步设想如下：\ngraph LR; node1([fa:fa-play 开始 ])--\u0026gt;node2[/撰写文章/]--\u0026gt; |fa:fa-upload Git提交\u0026amp;推送| node3[[fa:fa-blog Github Action构建构静态文件]] --\u0026gt;node4[/推送 Gitee 仓库/]--\u0026gt;node5[fa:fa-link curl远程调用] --\u0026gt;node6([fa:fa-stop 结束 ]); node5--\u0026gt;node7[[fa:fa-hdd 云服务器部署]]; subgraph http-client node4--\u0026gt; |fa:fa-download Git拉取更新| node7; end; style node7 fill:#f96; 中间增加了 Gitee 仓库的同步机制，部署的时间上可能会增加延迟，但部署成功率会更高些。\n注：考虑到国内访问 Github 经常会不稳定，所以干脆就做个仓库同步，将部署文件先推送到 Gitee ，再让云服务器去 Gitee 上面拉取部署代码，这样部署的稳定性会比较好。 在经过一番资料的查找后，最终确认方案是具备可行性的，技术上将选择 Openresty 增强版本的 Nginx 服务，通过 lua 代码来调用本地的脚本执行（特别感谢 @二花 网友帮忙调试lua代码 \u0026amp;#x1f44a;） 需要在 Nginx 配置文件上加入如下的代码：\n1 2 3 …","date":"2022-09-17T19:13:39+08:00","updated":"2022-09-17T19:13:39+08:00"},{"objectID":"1662038583","permalink":"/blog/use-custom-domain-active-vercel-waline.html","title":"使用自定义域名激活Vercel部署的Waline服务","content":"近期对于部分 Waline 评论插件的用户来说，或许是非常的困扰时期。先是服务商 LeanCloud 发布国内提供的服务，从8月份起需要绑定自有案例域名才能正常运行。而这两天 Vercel (Waline 官方提供的免费部署方案，也是大部用户的选择)旗下的 vercel.app 域名又遭受 DNS 污染攻击，在国内无法直接访问此域名，导致众多 Waline 用户的服务直接陷入“宕机”状态，真可谓是雪上加霜。\n有句话说的好：“只要思想不滑坡，办法总比困难多”。接下来就是给大家分享下，如何通过自定义域名的方式来解决上面遇到的2个问题，此方法仅供各位网友参考参考。 \u0026amp;#x1f604;\n确定方案 由于 vercel.app 域名已经被 DNS 污染，那么国内网络应该都是无法进行访问的，所以原本想直接通过已有域名 DNS 的 CNAME 对vercel.app域名转发的想法是不能实现的。通过多次验证后，确认如下 2 套方案：\n方案1： 有备案可用域名，直接转发Vercel DNS Server地址 方案2： 申请免费域名，配置 Vercel 提供的 DNS 服务器 方案1 DNS Server转发 在自有域名的 DNS 服务中添加一条记录，选择 CNAME 类型转发，记录值填写为：cname.vercel-dns.com，参考如下：\n然后在 Vercel 中找到 Waline 后端服务的项目，点击Settings标签卡，跳转页面后点击左侧的Domains菜单项，输入你自己定义的域名点击Add`按钮即可。\n方案2 申请免费域名 可以参考之前发布的文章： 创建属于你自己的org永久域名 ，不过这里不需要借助 DNSPOD 提供的解析服务，所以在申请域名时可以直接填写 Vercel 提供的 DNS 服务，默认地址为：\nns1.vercel-dns.com ns2.vercel-dns.com 域名申请下来后，访问 Vercel 的域名控制面板 Domains Dashboard 点击右上角的Add按钮选择你的 Waline 项目点击Continue按钮，再输入申请好的域名确认即可。\n评论搬迁 除了域名访问的问题外，还需要注意当使用 LeanCloud 国内版作为存储时需要有自定义的备案域名，要是没有的话就只好选择国际版本。那么就要对于已有的数据进行迁移，但 Waline 自带的导入 …","date":"2022-09-01T21:23:03+08:00","updated":"2022-09-01T21:23:03+08:00"},{"objectID":"1660224119","permalink":"/tech/github-action-ssh-key-invalid.html","title":"Github Action执行时遇到SSH key invalid format错误","content":"Github Action是款非常不错的CI/CD工具，自从它问世以来发展的速度真可谓是快，在 Github 的官方市场中几乎能找到所有你想要使用的Action脚本进行引用。本博客也是基于Github Action进行远程部署的，与常规的Github Pages服务不同，本站的静态文件是部署在国内某云厂商的静态服务器上面的，通过 tzzs/server-shell Action 集成，实现远程执行服务端的命令，来拉取最新生成的静态文件。\n具体的Github Action脚本用法参考如下：\n1 2 3 4 5 6 7 8 9 10 11 deploy-cloud: runs-on: ubuntu-latest steps: - name: Deploy Remote Cloud uses: tzzs/server-shell@v3 with: IP: ${{ secrets.REMOTE_HOST }} USERNAME: ${{ secrets.REMOTE_USER }} PRIVATE_KEY: ${{ secrets.REMOTE_PRIVATE_KEY }} SHELL: \u0026#34;sh /home/develop/myblog-deploy.sh\u0026#34; 这看上去也没有任何的问题，将代码推送到Github仓库也能正常运行。但诡异的事情在大概运行 1 周时间后便出现。在没有调整过 Action 脚本及 SSH 私钥的情况下，上面的部署步骤竟然执行失败，报出如下的错误信息：\n1 2 3 4 5 6 7 /usr/bin/ssh server sh /home/***/myblog-deploy.sh Warning: Permanently added \u0026#39;***\u0026#39; (ECDSA) to the list of known hosts. Load key \u0026#34;/home/runner/.ssh/deploy.key\u0026#34;: invalid format Permission denied, please try again. Permission denied, please try again. ***@***: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). Error: Error: The process \u0026#39;/usr/bin/ssh\u0026#39; failed with exit code 255 持着怀疑的态度再次检查了下最新仓库代码，确定只是发布了新文章并没调整过配置文件。然后又直接执行ssh -i命令测试了下 SSH 私钥，也是能正常的连接远程服务，这就有点纳闷的啦，到底是哪里出问题呢？\n经过一番网络大战（借助搜索引擎查找资料）后，发现有人提到说检查下 SSH 私钥的类型是否为 RSA 格式，打开的本地生成的id_rsa文件查看内容，果然不是RAS类型，参考如下：\n1 2 3 -----BEGIN OPENSSH PRIVATE KEY----- xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx -----END OPENSSH PRIVATE KEY----- 大概是早期生成SSH key没有留意直接使用了默认规则，然后使用如下的命令对私钥进行转换：\n1 ssh-keygen -m PEM -t rsa -f ~/.ssh/id_rsa 将新生成的私钥进行重新分发，再重新re-load失败的 Action， 果然任务就能正常执行成功。\n问题到此是解决了，不过对其的产生还是有些困惑，之前为何就没有这样的情况出现？又仔细过了一遍远程部署的脚本代码，发现执行时需要指定服务器操作系统版本 runs-on: ubuntu-latest ，而这里写的是使用最新版本，估计问题就是在此产生的，猜测可能是最新版本服务器操作系统的OPENSSH是版本较高不兼容所导致的，但没有做进一步的验证。\n总结一点，就是生成SSH私钥时还是尽量按照服务方的要求进行操作，如果没有，那么建议还是使用PEM格式的RSA类型较为通用，能够避免未知的风险。 \u0026#x1f604;\n","date":"2022-08-11T21:21:59+08:00","updated":"2022-08-11T21:21:59+08:00"},{"objectID":"1659876956","permalink":"/blog/upgrade-blog-use-new-theme.html","title":"博客站点升级使用 Hugo NexT 最新主题","content":"时隔 2 年的时间后，如今又再一次开始折腾自己的博客站点，看来是自己有点太躁动啦\u0026amp;#x1f602;。在上海疫情期间也真有点压抑的，为了消除这份不安的情绪，决定参考 Hexo NexT 从零开始全面重构 NexT 主题，也在独自奋斗的2个多月断断续续时间里完成主体功能所有移植工作（其实一直想有人参与进来共建，直接跑到人家 Hexo NexT 用户群“呼喊”，但也是没有浪花泛起，只好是自己继续独立前行）。 这不乘着周末的时间，把自己的站点也是升级到最新开发的主题，同时也是为后续想升级旧版本 Hugo NexT 的用户打个样吧。\n注意： 以下的操作记录，如果你已经熟悉 Hugo 使用，了解 Hugo NexT 主题相关配置，那么效果会更加好。 不熟悉也没有关系，你可以克隆 hugo-next-docs 项目进行参考，相信你会有所收获！ \u0026amp;#x270a; \u0026amp;#x1f604; 配置更新 首先声明一下配置文件已经和旧版本完全不兼容，因此在配置主题时无须参考原来的配置，只须根据新版本主题提供 示例配置文件 里面的注释说明调整自己站点信息即可，如站点名称，标题，头像，菜单，评论等个性化设置。\n主题默认提供的是单一配置文件的经典模式，可能很多人都会比较喜欢这样的简便风格，但个人还是更喜欢 Hugo 那种按目录进行分类管理的形式，不仅方便于环境的切换（默认使用develpment环境，直接执行hugo server命令即可），而且在本地开发时能有效的屏蔽某些配置参数泄漏，比如搜索引擎的KEY信息，整体的目录结构参考如下：\n1 2 3 4 5 6 config ├── _default ## 默认生产发布的配置文件 │ ├── config.yaml ## Hugo 引擎配置参数 │ ├── menus.yaml ## 站点菜单项 │ └── params.yaml ## 各类效果，组件参数配置 └── development ## 本地开发预览的配置文件（不上传到代码仓库） 当在本地运行 hugo server 命令预览站点时，会读取 development 文件夹里的参数配置。而当运行 hugo 命令生成全站静态文件时，会默认读取 _default 文件夹里的参数配置，这便实现开发环境与部署环境相互隔离，互不影响的完美效果！\n注： 如果是从 Hexo 迁移过来的用户，那么本主题的配置 …","date":"2022-08-07T20:55:56+08:00","updated":"2022-08-10T22:36:26+08:00"},{"objectID":"1659870772","permalink":"/flinks.html","title":"友情链接","content":"如想要交换友情链接，请将本站信息加入到你的站点友情链接中(可点击右上角图标直接复制)：\n1 2 3 4 - name: 凡梦星尘空间站 desc: 再平凡的人也有属于他的梦想！ avatar: https://lisenhui.github.io/imgs/avatar.png link: https://lisenhui.cn 并在评论区留下你的站点信息，格式参考如上，我会尽快在第一时间回复并添加友链，谢谢支持！ \u0026#x2764;\u0026#xfe0f;\n声明：为更好提升各位站友的访问体验，本站点在发布时会自动对友情链接的网站进行“活体”检测，因用的Github提供的服务器会有误杀的可能（比如贵站不支持全球访问的话），如不幸被“移除”可在下面的评论区中留言声明，后续会手动添加到白名单保护机制。\u0026#x1f64f; \u0026#x1f91d; ","date":"2022-08-07T19:12:52+08:00","updated":"2022-08-07T19:12:52+08:00"},{"objectID":"1655555998","permalink":"/tech/create-your-forever-org-domain.html","title":"创建属于你自己的org永久域名","content":"或许你也曾想拥有一个属于自己的域名，但又苦于囊中羞涩无力购买，亦或是在国内域名生效前都要实名备案。那么今天就给你带来一个好消息，你可以申请注册一个属于自己的 org 域名，而且不需要花费任何的费用，也不用进行备案就能使用（仅限国外服务器），就问你心动了有没有 \u0026amp;#x1f606;\n注意： 这里注册的并不是一级域名，而是属于二级域名，要是介意不用往下细看了。 方案 本篇接下来要介绍的方案是通过 eu.org + 腾讯云DSNPod 组合方案来打造属于你自己的个性域名，虽然注册的是个二级域名，但是其主域名长度比较短，且初看上去有点像是 edu 域名，所以不仅好记也有点像高等学府的味道。\neu.org 是欧盟组织下面的域名，EU代表欧盟，Paul Mockapetris在1996年创建了此域名的DNS服务器，计划是专门给无力承担费用的一些组织使用的。所以它对个人和组织是免费注册的，目前已经被谷歌，cf等一些大公司认可为顶级域名。 当然重点还是免费注册，大部分个人或组织都可以开心的白P，不过也担心 eu.org 的DNS能否负载的过来哟！ \u0026amp;#x1f606;\n注册用户 填写信息 点击 https://nic.eu.org/arf/en/contact/create/ 链接地址进入到注册环节，个人信息填写部分除电子邮箱是要真实的以外，其他信息可通过 地址生成器 模拟出来并填写，参考如下：\nName：全名（注意中间用空格隔开，不然检测会失败） E-mail：自己真实的邮箱（比如QQ邮箱），用于收取验证链接之类的 “I have read and I accept the domain policy”需要勾选起来 “Password”填写的是你的登录密码； “Confirm Password”是确认密码，这个等下就会用到的，请务必记下来 验证注册 提交好注册信息后，大约等个3~5分钟左右，你的邮箱就会收到一封如下图所示的验证链接邮件，若是没有收到邮件提醒，那么可以检查下是否在垃圾邮箱，或者直接搜索下邮件标题中包含 new EU.org contact 的邮件。\n如邮件内容提示的那样，需要访问其中的激活链接才能正式使用。 不过比较遗憾的是，该激活链接并不能直接点击，需要手动拷贝到浏览器的地址栏或是选中后使用鼠标右键跳转。\n在打开页面中，点击名称为 Validate 的浅蓝色按钮，便完 …","date":"2022-06-18T20:39:58+08:00","updated":"2022-06-18T20:39:58+08:00"},{"objectID":"1653897303","permalink":"/blog/make-nginx-support-http-ssl-request.html","title":"让 Nginx 将 HTTP 请求转发到 HTTPS 安全模式","content":"在某次博主的交流讨论时，忽然间发现自己站点原定让 HTTP 转发 HTTPS 的支持功能，实际上并不没有生效。如果是直接输入域名访问的话，那么会出现 400 的错误页面。当初为了让全站支持 HTTPS 也是耗费了不少精力，没想到却是这个结果。\n然后便是首先检查了下 Nginx 的配置，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server { listen 80 default_server; listen [::]:80 default_server; server_name lisenhui.cn; root /usr/share/nginx/blog; # SSL ssl on; #ssl off; ssl_certificate 1_lisenhui.cn_bundle.crt; ssl_certificate_key 2_lisenhui.cn.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { index index.htm index.html; } } 参考网上的说法，这里是要关闭 SSL 的配置让 HTTP 请求走非 SSL 模式，但又不符合自己的预期，也尝试通过 302 状态转发同样未成功。\n后来找到个资料上提示可使用 497 错误代码来转发，增加如下代码：\n1 error_page 497 https://$host:$server_port$request_uri; 497 代码是发送到 HTTPS 端口的 HTTP 请求 $host 是保留变量，代表正在运行 Nginx 的主机名 $server_port 是保留变量，表示在服务器部分中声明的侦听端口 $request_uri 是 reserverd 变量，代表完整的原始请求 URI（带有参数） 亲测，在 location 前面增加那段引用后，站点的 HTTP 请求就可以自动转发到 HTTPS 模式确保访问的安全性。\n参考：\nnginx-原始HTTP请求已发送到HTTPS端口 ","date":"2022-05-30T15:55:03+08:00","updated":"2022-05-30T15:55:03+08:00"},{"objectID":"1653044607","permalink":"/blog/repleace-jsdelivr-with-unpkg-as-cdn-vender.html","title":"用unpkg替换jsdelivr作为本站CDN提供者","content":"前几天就有看到网友在讨论 jsdelivr 服务被墙的消息，可能是刚开始的缘故吧，当时发现自己的站点倒还算是正常的，只也没坚挺几天也面临加载 jsdelivr 资源的失败问题。一番排查下来，发现受影响的部分还是比较小的，至少当时站点的 CSS 文件没有托管到 CDN 上，只要更换受影响部分的 CDN 链接引用便是。\n只不过是更换到哪个 CDN 会更有保障些呢？这还真是个苦恼的问题，自己并不太懂前端的技术，起初建站的时也就是想着将公有部分的 JS 和 CSS 资源通过 CDN 来引用效率会更高而已，也未曾想过会有今天这个遭遇。然后碰巧看到评论插件 waline （之前也是使用 jsdelivr） 使用了 UNPKG 作为 CDN 提供者，便决定跟随大众的路线走吧。\n但接着又出现了个苦恼的问题，就是 UNPKG 并没有提供直接查询资源的引擎，对于自己这个前端小白来说真是有苦恼呀。经过一番尝试后，总算是找到一个解决办法，步骤大致如下：\n1.访问 npmjs 站点检索 点击打开 npm 公司的站点： npmjs ，在搜索框中输入需要使用的资源名称，比如jquery，然后点击右边的版本号标签卡，参考如下图所示的3步操作。\n此时便会在地址栏中得到个相应的访问地址，类似： https://www.npmjs.com/package/jquery/v/3.6.0 2.切换到 unpkg 浏览资源 将上一步得到地址中的 package 后面的字符截取下，便成类似 jquery@3.6.0 这样的组件名称 + 版本号，把它加到下面这个地址后面：\n1 https://unpkg.com/browse/jquery@3.6.0/ 注： 切记最那个 / 字符一定要加上，不然就会找不到资源。\n此时便可以浏览对应组件的资源，如下图所示，也能按需切换版本号查看。\n确定需要使用的资源后，点击文件链接进入查看内容，此时页面右上角会有个按钮，拷贝那个按钮上的链接就是资源的 CDN 访问地址，参考如下：\n1 https://unpkg.com/jquery@3.6.0/dist/jquery.js 将它更换到你所需要使用的位置即可。\n上述就是本站替换的 jsdelivr 服务的方法，但后面对比发现，其实 jsdelivr 和 unpkg 的路径相对还是比较规范的，而且两者之间的资源也是相差无异，所以一般情况下不需要前面这么麻烦的操作，直接在 IDE 里面批量替换下就好，遇到有问题时再参考前面的方法进行修复。\n1 2 3 4 \u0026lt;!-- jsdelivr 资源路径 --\u0026gt; https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.js \u0026lt;!-- unpkg 资源路径 --\u0026gt; https://unpkg.com/jquery@3.6.0/dist/jquery.js 仅以此文先记录下来，后续在新版本的主题中再结合着看如何进一步优化调整有关于 CDN 的设置参数，免得下回还得因 CDN 等服务不稳定而“大动干戈”。\n","date":"2022-05-20T19:03:27+08:00","updated":"2022-05-20T19:03:27+08:00"},{"objectID":"1650537587","permalink":"/tech/virtualbox6-cup-clock-not-started.html","title":"VirtualBox6.x版本CPU时钟Bug导致虚拟机无法开机","content":"下午在启动平时常用的虚拟环境时，发现进度条卡在中间老半天都不会动，情况不太正常，以前启动时间最多也就是 10 几分钟就能看到桌面。点击键盘的方向键看打印的日志，一直在重复如下图所示的 Bug 信息，即使后面等待了半个多小时进入系统后，这个日志信息也不断的在终端界面上输出。\n见此觉得很是纳闷呀，也没有对虚拟机的设置和里面的系统做过任何参数调整，为何突然就这样不可使用啦。然后尝试了下其他的虚拟机环境，但是都正常成功的启动，这下子就更加郁闷无语啦。先是测试了重新导入新的镜像文件现象依然存在，然后又试了下网上的各种方法，如修改启动脚本，调整CPU分配，关闭开机服务等都没有效果。后来找做运维的朋友咨询了下，建议可以尝试下使用 VMWare 能否正常启动，于是乎便开始下载软件，安装，配置等各种折腾起来。最后导入到了 VMWare 环境中，点击虚拟机启动，成功的进入到了系统，各项功能也能正常运转。真是神奇！！！\n难道后续要切换使用 VMWare 环境使用虚拟机，但在尝试导入 Windows 平台虚拟机时失败了。那看来还是得想下办法能否修复上面遇到的问题，便又在网络上开始漫游希望能否找到解决办法。在寻找的过程中突然想到，为何不去 VitualBox 官方网站试试，然后在官网中输入 CPU 作为关键字，还真找到了篇类似的问题，总结下来就是这是 VirtualBox 6.x 版本的 BUG 影响，建议回退到之前的旧版本。然后在官方的归档库中找到了 5.x 的最新版本测试了下，之前遇到的问题果真就不存在。\n至此问题算是解决了，但真的不明白为何会突然这样，之前也是使用 6.x 版本也没有出现过该问题，莫非说是特定的时间触发的 Bug 产生，真有点丈二和尚摸不着头脑，只能是写文记于此吧。\n参考：\nNested virtualization BUG: soft lockup - CPU#4 stuck for 22s! ","date":"2022-04-21T18:39:47+08:00","updated":"2022-04-21T18:39:47+08:00"},{"objectID":"1649044414","permalink":"/tech/sshlogin-localvm-slowly-mobaxterm.html","title":"使用Mobaxterm登录本地虚拟机很慢","content":"近期因本地虚拟机有问题但重新搭建了个新环境，结果在使用 MobaXterm 工具登录终端时发现每次都要等待个 4 ~ 5 秒才可以进入，操作检验不是很好，不明白为何本地环境连接会是这么的慢，所以还是得想办法分析下。\n看有些网友也有类似的困惑，提示说可能是 SSH 登录时要通过 DNS 来寻址的原因。参考文章上说法找到 /etc/ssh/sshd_config 把里面的 UseDNS 配置项设置为 no，但是发现其已经是关闭的状态。那会是什么原因引起呢？\n提到 DNS 突然想到不会是本地 Host 文件的问题吧（个人习惯使用 hostname 连接服务器），于是尝试直接把 MobaXterm 的连接地址换成服务器 IP 地址，满怀希望的点击登录按钮，可惜结果还是要等待一会才能进入，真是有点抓狂啦。\n稍微“冷静”下来想下，发现现在还是没有确定问题的发生原因，究竟是 MobaXterm 工具还是服务器配置的问题呢？于是使用最简单的 SSH 命令，结果非常惊喜，无论是通过 IP 还是 hostname 方式连接都无须等待，可立马就进入终端操作。那么已经可确认就是 MobaXterm 工具原因。\n于是检查 MobaXterm 的登录配置，个人习惯使用已经配置好的用户名登录，但似乎也是没有问题呀。\n然后点击下旁边的 Passwords 标签卡发现里面也是存储 2 个密码，难道说就是这个原因？\n果断的删除了 Passwords 里的这两 2 个密码记录，再次登录虚拟机的服务器，终于得到自己想到的结局。 🙊\n结论 不知为何产生这个现象，就是 Passwords 中的那 2 条密码记录，暂时还是没有了解清楚，后续要也是遇到类似的情况，可以参考上述的方法，或许能够帮助到你。\n","date":"2022-04-04T11:53:34+08:00","updated":"2022-04-04T11:53:34+08:00"},{"objectID":"1647958423","permalink":"/tech/use-travisci-remote-deploy-site.html","title":"TravisCI 远程部署站点服务","content":"背景 之前一直都是将自己的博客站点托管在 Github Pages 服务上面，但无奈国内的访问速度确实是让人堪忧，时不时还会出现打不开现象，确实影响到访问查看的体验。另外近期腾讯云的 ICP 备案又开始各种检查“臊”操作，一旦发现域名解析 IP 地址不是其云服务的话就会终止 ICP 备案，那后果可想而知肯定是域名会被终止访问引起一连串的不可预知问题（毕竟重走 ICP 审批流程也是非常的烦恼）。于是便只好订阅了腾讯云的轻服务产品，把站点静态内容托管在其上面。\n问题 于是乎便又重新搭建新环境的各种折腾，先是安装各类基础软件，如： Hugo、Git、Nginx等等，此处的细节就不在展开了，大家在网上都能找到相关环境的指导文章。 然后便考虑如何在这个环境下根据文章发布时的推送，自动生成新的静态站点内容。后来还是选择了 Travis CI 平台来实现自动化部署（可参考之前写的教程 Travis CI自动部署教程 ）。\n顺便说下，个人使用下来觉得 Travis CI 比 Github Action 要更加稳定些，至少在个人仓库的使用中。\n基本流程是如下：\n其中在使用 SSH 命令远程执行操作时会涉及到私钥的加密保护，之前一直接使用 Windows 生成加密文件操作都没有问题，不知道为何此次使用 Travis CI 的新版本后，生成的加密文件在解密过程中一直出现如下的错误：\n问题 1：\n1 2 3 4 $ openssl aes-256-cbc -K $encrypted_39c1b18630f7_key -iv $encrypted_39c1b18630f7_iv -in .travis/id_rsa.enc -out id_rsa -d iv undefined The command \u0026amp;#34;openssl aes-256-cbc -K $encrypted_39c1b18630f7_key -iv $encrypted_39c1b18630f7_iv -in .travis/id_rsa.enc -out id_rsa -d\u0026amp;#34; failed and exited with 1 during . Your build has been stopped. 另外在腾讯云的服务器上执行 git pull 命令时，也会出现如下的告警及错误信息：\n问题 2：\n1 2 3 $ …","date":"2022-03-22T22:13:43+08:00","updated":"2022-03-22T22:13:43+08:00"},{"objectID":"1644654730","permalink":"/tech/use-sublime-txt-build-hugo-site.html","title":"使用Sublime Text搭建Hugo使用环境","content":"自从捣鼓 Hugo 建站以来也有好长一段时间啦，但是之前的使用环境比较的 “松散” ，比如编辑博客文章用的是 Sublime Text 文本工具，再通过 CMD 命令行工具调用 Hugo执行本地预览，最后再 使用 Git Extension 图形工具将博客文章发布到 Github Pages 供网友们浏览。 从整个操作流程上来看还是可以的，只是在过程中要切换不同的工具操作，而恰好看到 Hugo 官网上有个 Sublime Text 的 插件 ，于是乎有了重新整合 Hugo 使用环境的想法，哈。\n安装插件 根据上面所说的操作流程，整理需要在 Sublime Text 上安装的插件有如下4款：\nGit MarkdownEditing Hugo Snippets Hugofy 直接在 Sublime Text 使用 Ctrl+Shift+P 快捷键输入 pci 选择第一项，逐一输入上述插件名称安装。\n快捷键设置 这里 Git 和 Hugo Snippets 是没有快捷键可使用的，只能通过 Ctrl+Shift+P 快捷键 + 关键字来执行相关的命令，参考如下：\nCtrl+Shift+P + git(关键字)： 会显示出 Git 的命令，如add, commit, push等常用操作功能； Ctrl+Shift+P + snippet hugo(关键字)： 会显示出 Hugo 的语法，移动上下键选择便可插入代码块； 而 MarkdownEditing 在文档编辑过程中，除自动识别语法字符外，比如当输入 _ 字符会自动补全可直接写文档。另外也提供了一些快捷输入的组合按键，参考如下：\n功能说明 组合键 标题 Ctrl+1~n 粗体 Alt+B 斜体 Alt+I 插入图片 Win+Shift+V 链接 Ctrl+Alt+V 引用 Ctrl+Shift+. 取消引用 Ctrl+Shift+, 注释 Ctrl+Shift+/ 代码块 mdc+Tab 注： 除引用较为特殊外，其他组合键都是可以连按两次进行取消的,很遗憾没有表格快捷方式。\n最后就是要创建 Hugofy 启动站点服务的快捷方式，不过在此之前需先配置下站点路径等参数，打开 Preferences -\u0026gt; Package Settings -\u0026gt; Hugofy -\u0026gt; Settings - Users 选项，参考如下配置调整自身实际情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { // 站点根目录的上一级 \u0026#34;Directory\u0026#34;: \u0026#34;C:\\\\Users\\\\senhui.li\\\\Documents\\\\GitRepos\u0026#34;, \u0026#34;Server\u0026#34;: { // 生成草稿 \u0026#34;DRAFTS_FLAG\u0026#34;: true, // 服务端口 \u0026#34;PORT\u0026#34;: 1313, // 不需要添加主题参数 \u0026#34;THEME_FLAG\u0026#34;: false }, // 站点存放的目录名称 \u0026#34;Sitename\u0026#34;: \u0026#34;elkan1788.github.io\u0026#34; } 接着打开 Preferences -\u0026gt; Key Bindings 选项，加入你想设置的快捷键，参考如下：\n1 2 3 4 { \u0026#34;keys\u0026#34;: [\u0026#34;ctrl+alt+h\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;hugoserver\u0026#34; } 那么此时只要按下 Ctrl+Alt+H 组合键，后台就会启动 Hugo 站点服务，打开浏览器即可访问站点。\n总结 自此以后便可以在 Sublime Text 的全家桶中“畅游”，喜欢就快来加入吧，给众多网友分享下你的宝贵经验。\n","date":"2022-02-12T16:32:10+08:00","updated":"2022-02-12T16:32:10+08:00"},{"objectID":"1644294673","permalink":"/tech/use-sublime-txt-build-hugo-site.html","title":"Sublime Text安装插件失败","content":"近期因公司之前分配的电脑出了点毛病，无奈只能重新换个新电脑，所以环境也得从头进行搭建。而一直使用的 Sublime Text 是绿色版本，直接拷贝过来后启动，编辑等操作都是正常的，但在尝试安装新的插件时就遇了如下的问题。\n错误信息：There are no packages available for installation\n然后检查安装目录下的 channel_v3.json 文件是正常的，只好尝试打印系统日志来看追踪下问题，使用 Ctrl + ~ 快捷键打开终端，输入如下的代码开启：\n1 sublime.log_commands(True) 注： 千万记得在调试完成后关闭日志输出\n再次尝试安装插件时，便发现提示系统找不到指定的路径异常，一看那个路径才恍然大悟，然后来是之前电脑的安装位置，那只要更新下配置文件路径就好啦。\n打开 Preferences -\u0026gt; Package Settings -\u0026gt; Package Control -\u0026gt; Settings 选项修改 channels 的参数值，保存后便可以成功安装插件啦。\n1 2 3 4 5 6 7 { \u0026#34;bootstrapped\u0026#34;: true, \u0026#34;channels\u0026#34;: [ \u0026#34;C:/xxxx/channel_v3.json\u0026#34; ] } 最后发现 channel_v3.json 文件也好久没有更新了，便顺道访问官方文件 channel_v3.json 拷贝进行更新。\n参考：\n官方文件地址： https://packagecontrol.io/ ","date":"2022-02-08T12:31:13+08:00","updated":"2022-02-08T12:31:13+08:00"},{"objectID":"1625824386","permalink":"/blog/make-next-theme-pithy2.html","title":"优化Hugo Next主题的过程2","content":"背景 自上次优化NexT主题并分享到Github仓库中 hugo-theme-next 后，也是受到了不少NexT主题喜爱者的使用和邮件反馈。于是决定还是要花点心思来维护它，便把自己之前一些想法也重新加入到NexT主题中，同时对部分插件的功能做了更新。\n此次优化后发布的版本代号为3.x，原因是整体结构和之前的变化较为大（主要是在配置方面的体现），为此也重写主题的相关介绍等信息，目前正在申请加入官方的主题列表中( 点击预览 )，欢迎大家的使用和反馈。\n中英文切换 或许大家觉得这个功能有点软肋，原因就是个人博客的流量并不会很大。但流量小并不是意味着没有流量，所以我们还是可以增加个中英切换的功能，来助力我们推广自己的博客空间。而且Hugo引擎在多语言化这块的开发也比较简单，不过现在是手动模式，也就意味着你在发表文章写两份。增加中英文切换功能后的效果参考如下：（就是在左上角添加了切换入口）\n后续考虑是否可能引入自动翻译的模式来加载，可以减少写文章耗费的时间。\n重构配置 结合上面的中英双语切换功能，对于主题的配置内容管理来说就会变的比较混乱，个人不喜欢在一个文件中写满太多的配置参数。而这块的想法正好Hugo引擎的设计不谋而合，它天然就支持按分类的管理方式来独立配置不同的参数。\n同时也对本主题中使用的各服务组件配置做了分类，这样显示更加清楚明了，也便于后续参数的调整及优化。\nAddthis分享 主题中原来使用的BShare插件，但在某一天突然就发现其无法正常引用。真是感叹在继百度分享插件后，又一国内分享插件的落幕。所以后来就找到了国外一款比较流行的插件addthis，通过一番倒腾研究终于成功集成，用于替换原来的BShare插件。\n在主题中启用也比较简单，分如下2步：\n到addthis官方网站上去注册个账号（ 点击注册 ），然后获取到个人的ID号，类似这样的：ra-6049e46e9ee54287； 在配置文件中找到Share配置项，设置Enable = true和AddthisId = \u0026amp;quot;Your AddthisPubid\u0026amp;quot;两个参数； 实现的效果如下：\n本地搜索优化 之前本地搜索生成的索引文件是覆写到robots.txt，但在中英双语的情况下便无法支持两种不同中英文索引，所以需要改造原来的生成索引方式。而这也是再一次感受到Hugo引擎的强大之处，它完全可以支 …","date":"2021-07-09T17:53:06+08:00","updated":"2021-07-09T17:53:06+08:00"},{"objectID":"1618393400","permalink":"/tech/replace-files-in-springboot.html","title":"替换SpringBoot里的文件","content":"现在使用Spring Boot架构的应用开发来说是非常的普遍，统一化的打包部署确实带来不少便利，但当遇到问题时也是会比较棘手。或许你会觉得很惊讶，但如果说这是产品部署运维过程中遇到的难题需要修改Spring Boot应用程序，你就会觉得困难也是不奇怪的。本文就来分享下如何使用jar命令应对线上部署产品时，要临时替换Spring Boot应用中的Jar包的操作。\n在测试环境部署某个产品应用时，在最后启动时遇到失败，查看并分析启动日志，发现了如下的堆栈日志信息：\n看到此MySQL驱动的类名，当时心中已经有了答案，估计肯定是因为高版本的MySQL驱动程序不兼容低版本的MySQL Server所引起的。接下来使用如下的 jar 命令进一步确认下便是：\n1 2 $ jar -tvf semxxx.jar | grep mysql mysql-connector-java-8.0.12.jar 当前测试环境使用的 VM 集成镜像，里面很多组件版本相对比较低，但一直使用都没有问题也未曾再升级。\n从上面错误的堆栈日志中有看到DruidDataSource字样，猜测此开发使用了Druid数据库连接池，那还是很有希望的，因为Druid数据库连接池有个自动适配数据库驱动程序类的能力特性，但愿开发在写代码时没有使用硬编码的形式。\n网上搜索了一些关于 jar 命令如何打包有主运行程序的JAR包后，便着手开始替换MySQL程序的工作。相关步骤如下：\n解压产品打包好的spring-boot应用程序 1 $ jar xf semantic-xxxx.jar -C tmp/ 删除lib目录下的MySQL高版本驱动 1 2 $ cd ./tmp/BOOT-INF/lib/ $ rm -rf mysql-connector-java-8.0.16.jar 添加低版本的MySQL驱动包 1 2 $ cd ./tmp $ cp ~/mysql-connector-java-5.1.34-bin.jar ./BOOT-INF/lib/ 修改classpath.idx文件中的JAR列表 1 2 3 $ cd ./tmp/BOOT-INF/ $ vim classpath.idx $ # 把那个高版本驱动程序JAR名称修改成低版本的名称即可 重新打包Jar 1 2 $ cd ./tmp $ jar cfM0 semantic-xxxx.jar . 最后就是重新启动应用程序，“万幸”我们的程序员们没有写硬编码，启动成功，如愿进入到了产品的操作界面，功能使用也一切正常。\n参考文章：\njar命令修改 springBoot打包成的jar 直接替换Springboot jar包中的文件 springboot项目jar包发布的，如何线上修改jar包 ","date":"2021-04-14T17:43:20+08:00","updated":"2021-04-14T17:43:20+08:00"},{"objectID":"1616212133","permalink":"/tech/join-istio-translation-org.html","title":"加入Istio官方翻译组织的历程记录","content":"作为曾经的程序猿，自己也一直“享受”着来自开源社区的那些无私分享。这些开源项目对自己的影响和启发还是很大的，之前就有想过如何去回馈开源社区，也开贡献过自己的一些项目，参与过一些开源项目，但都还是仅限国内的项目。不久前正好看到 Jimmy Song 在微信朋友圈发布 《Istio 官网翻译工作组成立暨志愿者招募》 的动态，没有任何的犹豫，下班后便联系 Jimmy 申请加入翻译工作，并在随后的时间完成自己的首次翻译，也成功被合并到了 Istio 官方仓库的主分支当中。如果你也有和我一样的想法，那么欢迎您也来一起加入，期待。\n接下来给大家一起分享下，加入Istio官方翻译组织的历程，为后续想加入（或是参与其他开源项目）的小伙伴们做个引路参考，如有不明白之处，可以在文章下的评论区，发表你的建议或意见，谢谢。\n翻译的全流程概览如下：\n准备工作 俗话说： “磨刀不误砍柴功。” 在正式参与项目合作之前，还是有不少的准备工作需要做的。 当然如果您是资深的开源玩家，那么这些对您来说都是轻车熟路，可以直接跳过本篇文章，参与到实际的项目合作中去。\n科学上网 在技术方面，谷歌可以说是一直都在领导者位置，只是可惜国内情况，并不能让我们愉快的使用这份“珍贵”的资源，所以你得学会如何使用VPN进行访问谷歌站点，因为后续的任务登记在Google docs中。 不过这个能力需要您自给自足，您可以通过网络寻找到很多不错的资源。\nGithub账号 作为全球知名的 Git 代码仓库管理与共享平台，相信您早已注册有账号，如没有账号也没有关系，现在您就可以通过 Github 在线注册快速获取，开启您的“新世界”大门。\nGit环境与工具 Git安装还是比较简单的，可直接到官方网站 Git Downloads 下载与您电脑系统对应平台版本安装。同时也可以安装个图形化的客户端，个人一直使用的是 Git Extensions 工具，它集成Git的命令操作与相关概念，可以帮您提高 Git 使用效率。当然如果您是一名 Geeker，那仍然可以追求命令行的速度，两种方式任君选取。\n关于 Git 和 Github 的更多详细使用，初学者可以参考下 Github新手详细教程 这篇文章。\nHugo运行环境 Hugo （基于Go语言）是当下主流的静态站点生成引擎之一，Istio 的官方站点便是基于此引擎构建的，因此您也需要熟悉下对 …","date":"2021-03-20T11:48:53+08:00","updated":"2021-03-20T11:48:53+08:00"},{"objectID":"1614228745","permalink":"/tech/add-sync-gitee-action.html","title":"使用Github Action自动同步仓库到Gitee","content":"背景 作为程序员出生的你，肯定知道备份的重要性。再说现在大环境背景下，美国的政治关系还是比较混乱的，而对于存放在Github上面的项目，也不再是技术自由的国度啦。所以说我们的代码还是有必要进行“双”备份的，接下来就是介绍下，如何使用Github上面的Action功能，将Github上面的代码同步备份到国内的Gitee仓库站点。\n准备工作 在一次无意间浏览到了yanglbme的贡献的一个 Git Page Action 代码，经过简单的尝试验证，感觉还是挺好用的，便在自己的博客项目中加入相应的Github Action。大部分的步骤在上面那个站点都有介绍，在此就大概小结一下要注意的点。\n准备SSH密钥 在你的本地使用ssh-keygen命令生成用密钥时，千万不要使用密码，在执行ssh-keygen -t rsa -C \u0026amp;quot;youremail@example.com\u0026amp;quot;命令时，直接不断敲下回车键即可。\nGitee相关 建议Github和Gitee使用同一个密钥，他们的设置方法如下：\n1.Github: Settings -\u0026amp;gt; SSH and GPG keys 2.Gitee: 安全设置 -\u0026amp;gt; SSH 公钥 另外还有一个重点就是，一定要关注Gitee的公众号： giteecom，不然后面Github workflow执行就会失败的。\nGithub加密设置 切换到Github，然后在当前项目下「​Settings -\u0026amp;gt; Secrets」中进行添加[Repository secrets]，分别为:\nGITEE_PASSWORD: Gitee登录的密码 GITEE_RSA_PRIVATE_KEY: 前面生成的SSH密钥的私钥\nGit workflow准备 在你的Github的仓库中，添加个.github/workflows/目录结构，创建个名称为sync-2-gitee.yml文件，填充如下的文件内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 name: Sync on: push: branches: [main, hugo] jobs: sync-2-gitee: runs-on: …","date":"2021-02-25T12:52:25+08:00","updated":"2021-02-25T12:52:25+08:00"},{"objectID":"1613979759","permalink":"/tech/git-extensions-push-fail.html","title":"GitExtensions推送Github失败记录","content":"问题现身 555~，今天体验了一把安装最新程序的“快感”！！！\n在使用Git Extensisons推送最新写的文章到Github时，遇到了个SSH KEY认证无效的莫名错误。事情的发生是这样的：今天在首次打开Git Extensions软件时，它非常友好的弹出更新提示窗口，然后就手不自觉的点击了下确认按钮。结果更新好后，在推送文章到Github时就发生了如下面一样神奇的错误阻拦：\n1 2 3 4 5 6 FATAL ERROR: No supported authentication methods available (server sent: publickey) fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 看到这个错误真是一脸的发楞呀，没有修改过任何SSH KEY相关的配置，咋就没有相应的权限进行操作了呢？\n开始脑子里想到的是，难道是本地的SSH KEY被清理了？但检查了文件后发现一切正常，而且使用git push命令操作也是正常的。真是百思不得其解，暂时只能参考报错的提示出来尝试操作修复。\n初步解决办法 根据报错窗口的提示，使用Putty工具把本地的SSH KEY生成Private模式，操作如下：\n然后把这个Private KEY加载到推送的流程中，再次点击推送按钮就会看到操作成功提示信息。\n问题定位 虽然解决完这个推送的问题，但还觉得事情有点奇怪和蹊跷。于是想到了Git Extensions的配置是否有变化，经过一番查找测试后，确认是由于官方当前默认在Windows使用Putty作为客户端，把它调整为OpenSSH方式，问题便不再出现。\n总结 在非必要的情况下，还是不太建议升级软件版本，稳定的环境比用不到的新功能更具价值。\n","date":"2021-02-22T15:42:39+08:00","updated":"2021-02-22T15:42:39+08:00"},{"objectID":"1611462070","permalink":"/tech/github-personal-profile-card.html","title":"Github个人信息卡片","content":"Github上总是会有一些新奇的东西出现，这不无意间又发现了个有趣的玩法，可以用它来作为你的个人开发者名信片展现。具体展现效果如下：\n操作起来也不繁琐，类似以前的pages服务那样，只准备个特定的仓库就可以，具体操作如下：\n1. 申请公开仓库 在Github上面申请个与你用户名同名的公开仓库，然后你就会发现收到来自Github的“赞美”提示信息，如下：\n仓库创建好后，会默认准备好一个README.md文件，后续你在这上面写相关的信息即可。\n２. 个人介绍信息 接下来就是你在README.md上面添加个人信息，写法上支持标准的markdown语法编辑，同时也是支持各种表情图标，可以按你个人的意愿添加任意内容。顺便提下，可以使用Github API展现你自己仓库相关的代码提交，质量，打分等信息，效果见开篇的介绍。\n3. 示例 自己简单的编写下，仅供各位看观参考，哈。\n1 2 3 4 5 6 7 8 \u0026lt;img align=\u0026#34;right\u0026#34; src=\u0026#34;https://github-readme-stats.vercel.app/api?username=elkan1788\u0026amp;show_icons=true\u0026amp;icon_color=CE1D2D\u0026amp;text_color=718096\u0026amp;bg_color=ffffff\u0026amp;hide_title=true\u0026#34; /\u0026gt; ### Hello, World! :tada::tada::tada: - :building_construction: Working at @Kyligence - :house_with_garden: Living at Shanghai - :orange_book: [《Apache Kylin权威指南（第2版）》](https://item.m.jd.com/product/12566389.html) - :monocle_face: Try to find it out. 喜欢的话，那就赶紧行动起来吧。\n","date":"2021-01-24T12:21:10+08:00","updated":"2021-01-24T12:21:10+08:00"},{"objectID":"1601634771","permalink":"/blog/make-next-theme-pithy.html","title":"优化Hugo Next主题的过程","content":"背景 经过一番考虑还是把个人博客从Hexo引擎迁移到Hugo引擎，博客主题依旧还是沿用NexT。其实本来还担心又要折腾弄个全新的博客主题，后来Github上看到兰陵子分享的 NexT 主题，就直接拿过来引用。但在部署后发现还是有些地方需要改善，在此记录下改造优化的过程。如果正好你也喜欢这个主题，那么欢迎拿去使用，也欢迎交流反馈。\n评论功能 评论功能是博客空间一项较为重要的功能，作为博主与读者交流的重要桥梁，那自然是不可或缺。之前一直使用的是LiveRe，最近发现访问不太稳定，另外还不支持游客评论模式，于是乎考虑使用Valine来做评论支持，不过最后还是把两个都实现了。\nLiveRe LiveRe (来必力)是韩国最大第三方社交评论系统，自打多说评论下线后一直都是使用它做博客的评论框。个人开发者可以到官网网站注册个City免费版本即可，它的集成也是很简单，直接在博客的JavaScript页面中加载如下的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 {{ if and (.IsPage) (isset .Site.Params \u0026amp;#34;comment\u0026amp;#34;) (eq .Site.Params.Comment \u0026amp;#34;LiveRe\u0026amp;#34;) }} \u0026amp;lt;script type=\u0026amp;#34;text/javascript\u0026amp;#34;\u0026amp;gt; (function(d, s) { var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === \u0026amp;#39;function\u0026amp;#39;) { return; } j = d.createElement(s); j.src = \u0026amp;#39;//cdn-city.livere.com/js/embed.dist.js\u0026amp;#39;; j.async = true; e.parentNode.insertBefore(j, e); })(document, \u0026amp;#39;script\u0026amp;#39;); \u0026amp;lt;/script\u0026amp;gt; {{ end }} 然后在想出现评论框的位置，定义个Div元素，参考如下：\n1 2 3 {{ if and (isset .Site.Params \u0026amp;#34;comment\u0026amp;#34;) (eq …","date":"2020-10-02T10:32:51+00:00","updated":"2020-10-02T10:32:51+00:00"},{"objectID":"1601312553","permalink":"/tech/install-cdh-issues-notes.html","title":"安装CDH6过程中几个入坑记录","content":"其实CDH环境部署安装并非是什么难事，正所谓是熟能生巧嘛。但正好不巧的就是太久没有操作过，便是会遇到一些“奇奇怪怪”的问题，而后花费些功夫才能解决好，事后也就顺道把它们记录下来，避免以后再犯。\n1. CDH的元数据库初始化脚本 想必安装过CDH环境的人员都知道，在CM安装完成后，有个脚本名称为：scm_prepare_database.sh，按官方说法是用于初始化CDH元数据库的，所以大家肯定是都会按步就搬的执行。但不知道大家有没试过想它背后是否真的有产生过什么工作？换句话说就是不执行此脚本会有什么问题？\n在过往安装CDH环境的经验中，一般都是会把CM和MySQL数据库安装在同一台机器上（非生产环境）。但这次恰好是在云上环境搭建，所以MySQL直接使用的是云上服务，结果在安装好CM，执行好scm_prepare_database.sh脚本后，启动CM并没有出现预期的成功消息。查看启动日志发现如下错误：\n提示scm.cm_version表不存在，难道是之前执行scm_prepare_database.sh脚本有问题？于是乎又重新执行一次该脚本，确定输出结果是成功的，但CM启动仍然是失败的。当时就真是纳闷了，这个CM的元数据库是在哪一步初始化的呢？\n经过一番尝试和验证后，确认scm_prepare_database.sh脚本并不会初始化CM的元数据库，只是生成db.properties文件，同时会创建一个指定名称的数据库，而真正初始化的操作是在CM首次启动时执行的。\n结论： 安装完成CM并不一定需要执行scm_prepare_database.sh脚本，可以手动创建数据库及配置db.properties文件。\n2. MySQL5.7+版本问题 前面第1步中遇到的问题，其实在后来分析日志时发现，根本原因是CM在执行数据库初始化时，有些DDL语法不支持导致初始化工作并未完成。部分错误日志如下：\n但是CM的提示信息并不友好，并未告知CM元数据库初始化是否完成，导致定位问题有点难度挑战，后来是手动调整DDL语法才得以完成初始化工作。\n这里总结出一个经验，就是正常情况下CM元数据库会生成54张表，可以以此为判断CM初始化工作是否完成。\n另外就是MySQL GTID的问题，导致建表一直失败：\n1 2 错误代码： 1786 Statement violates GTID …","date":"2020-09-28T17:02:33+00:00","updated":"2020-09-28T17:02:33+00:00"},{"objectID":"1600382532","permalink":"/blog/stop-use-chinese-domain-notice.html","title":"停止使用原中文域名公告","content":"从今天起正式启用lisenhui.cn作为本博客空间唯一域名。\n早上的时候收到了域名服务商的通知短信，提示域名需要续费。才发现不知不觉中，原来工作后注册的第一个域名，已经陪伴自己走过了7个年头啦。当时也就是觉得中文域名比较特别，然后就自己的名字注册了李森辉.cn的域名。\n不过现在还是决定弃用这个中文域名，因为考虑到中文域名其实也还不成熟，在这些年使用的过程就总是遇到各种问题，虽然后来都找到办法绕过去解决，但是终究不太方便。\n因此带来的影响，只能说是后续再慢慢修正吧。（不过本站的流量也是一般啦）\n","date":"2020-09-17T22:42:12+00:00","updated":"2020-09-17T22:42:12+00:00"},{"objectID":"1597486929","permalink":"/blog/move-site-2-hugo-plan.html","title":"博客引擎迁移至Hugo计划","content":"近期发现自己的个人博客空间突然之间不能访问，一番查证后发现原来是之前使用的page服务商已经停止提供服务。无奈只好重新迁移回到Github Pages。但这就是又得到重新准备Hexo的相关开发环境，还得辛苦的调试才能成功。而恰好这时在网上有看到过Hugo静态站点引擎的文章，一款基于Go语言开发的极速框架，开发环境部署也简便快速。另外近期原有的域名也快到期了，正好就一起把博客空间整理整理吧。\n访问Hugo官方网站，翻看了下官方的文档，确实是使用比较容易简单。但发浏览已有主题时，并没有找到自己博客空间现正在用的NexT主题，那是不是意味着又得重新来倒腾一回！\n不过还好最后在Github找到有人已经移植了Hexo NexT主题： hugo-theme-next ，所以后续的迁移计划便是基于此展开，整体的思路和计划如下：\n考虑到都是使用业余时间来完成，所以时间线拉的比较长一些，也不知道当中遇到的问题能否顺利解决。先不管这么多啦，凡事都是得先有个Flag嘛，后续努力的把Flag实现就好啦。\n","date":"2020-08-15T10:22:09+00:00","updated":"2020-08-15T10:22:09+00:00"},{"objectID":"1571684691","permalink":"/tech/install-linux-chinese-fonts.html","title":"在Linux上安装中文字体","content":"背景 平时一般都很少在Linux服务机器上使用UI桌面，但也还是有机会遇到，这不今天便遇到Linux版本的火狐浏览器显示中文乱码。无论怎么调试浏览器的相关设置，都没有办法凑效，甚是有点郁闷。\n安装字体 在前面调试浏览器设置，在字体设置那栏就发现没有适合中文显示的字体库，那就是意味着安装个字体就可以解决问题啦。从Windows系统中找了个微软雅黑字体库（msyh.ttc,msyhl.ttc,msyhbd.ttc），并上传到Linux服务器的指定目录下： /usr/share/fonts\n注：可以在此目录下创建个文件夹存放微软雅黑的3个字体库文件，方便管理\n然后再通过yum命令安装字体管理工具，如下：\n1 yum install -y fontconfig mkfontscale 最后验证一下字体安装是否成功，命令如下：\n1 2 3 4 5 6 7 [root@quickstart fonts]# fc-list :lang=zh Microsoft YaHei,微软雅黑:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei UI,Microsoft YaHei UI Light:style=Light,Regular Microsoft YaHei UI:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei,微软雅黑,Microsoft YaHei Light,微软雅黑 Light:style=Light,Regular Microsoft YaHei …","date":"2019-10-21T19:04:51+00:00","updated":"2019-10-21T19:04:51+00:00"},{"objectID":"1553195091","permalink":"/tech/unable-create-tmp-file-in-hdfs-nodes.html","title":"不能在HDFS Data节点上创建临时文件","content":"在新创建的Hadoop边缘节点上，尝试通过Hive CLI模式进行数据插入操作，结果没有出现意想中的成功信息，反倒是捕获到如下的异常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FAILED: SemanticException [Error 10293]: Unable to create temp file for insert values File /tmp/hive/kylin/9c84de0a-fca2-4d3c-8f72-47436a4adb83/_tmp_space.db/Values__Tmp__Table__1/data_file could only be replicated to 0 nodes instead of minReplication (=1). There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1720) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3440) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:686) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:217) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:506) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2226) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2222) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2220) ERROR: Current user has no permission to create Hive table in working directory: /user/kylin 从异常提示信息上来面，初步判定为对/user/kylin目录没有权限（有点奇怪明明就是kylin用户为何会没有权限操作），简单直接的把其权限降低到777后，错误仍然是存在。接着尝试切换到Hive的Beeline连接方式，重复上原来的插入语句，操作成功了！那上面的错误是何原因引起的呢？\n借助强大的Google搜索查找了一番，结果各说纷纭：有说是HDFS存储空间不足，有的说是集群节点的防火墙未关闭，有的说是DataNode服务异常 等等。网上的方案都尝试过了，问题仍然是没有解决。由前的防火墙联想到会不会是IP引起的问题 。\n因为集群是本地虚拟机搭建的，而恰巧又配置了双网卡，而边缘节点连接的是集静态IP地址。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 eth0 Link encap:Ethernet HWaddr 08:00:27:B2:38:58 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:797 errors:0 dropped:0 overruns:0 frame:0 TX packets:944 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:98791 (96.4 KiB) TX bytes:84770 (82.7 KiB) eth1 Link encap:Ethernet HWaddr 08:00:27:B5:9D:6A inet addr:192.168.56.104 Bcast:192.168.56.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:3523935 errors:0 dropped:0 overruns:0 frame:0 TX packets:443589 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:5073146719 (4.7 GiB) TX bytes:163351146 (155.7 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:342031 errors:0 dropped:0 overruns:0 frame:0 TX packets:342031 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:405110832 (386.3 MiB) TX bytes:405110832 (386.3 MiB) 接着检查了下/etc/hosts的文件配置，结果真是默认设置10.0.2.15地址为集群IP，将其修改为静态IP地址并重启Hadoop集群的所有服务，再次通过Hive CLI模式连接Hive，执行之前的插入语句一切正常。\n总结 配置Hadoop集群要特别注意IP地址的分配，建议还是通过HostName形式来避免IP地址问题。另外当已有案例不能协助解决问题时，可仔细检查环境的配置情况。\n","date":"2019-03-21T19:04:51+00:00","updated":"2019-03-21T19:04:51+00:00"},{"objectID":"1549368772","permalink":"/about.html","title":"关于我","content":" 希望是无所谓有，无所谓无的，这正如地上的路。\n其实地上本没有路，走的人多了，也便成了路。\n鲁迅\n绰号\n凡梦星尘(elkan1788)\n留言箱： elkan1788@139.com 历史正文\nCSDN Blog ITEye Blog1 ITEye Blog2 GitHub Page 奔波于大都市中求生的一枚攻城狮/码农，“ 完美 ”是对代码的基本要求。\n（ 转眼间码农生活已成过往，但对代码的追求亦不曾放弃！)\n文静的外表下藏有颗“ 叛逆 ”的心，不怕世俗之见敢于突破束缚，喜欢去追求真正的自由路。\n心中怀揣着的梦想，希望有一天终能够把它实现。\n稍微啰嗦了几句，望勿给君扰之，感谢支持！\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻： 点击即加入 ","date":"2019-02-05T20:12:52+08:00","updated":"2019-02-05T20:12:52+08:00"},{"objectID":"1533732893","permalink":"/tech/win10-quick-operations.html","title":"Win10常用的快捷操作方式","content":"常言道“工欲善其事，必先利其器。”\n不过从Mac再过渡回来到Windows确实是有诸多的不习惯，但仍是要学会克服，无它，工作是生存的根本技能。于是从网络上扒了下关于Win10快捷键的分布，还是挺有趣的。记录也下部分常用快捷键，如下：\n操作手势 1.双指单击触摸板，模拟鼠标右键，即弹出菜单\n2.三指单击触摸板，弹出搜索框\n3.四指单击触摸板，弹出操作中心，即模拟Win+A\n4.三指同时上划，弹出多任务界面，即模拟Win+Tab\n5.三指同时下划，将所有窗口最小化，即模拟显示桌面\n6.三指同时向左/右划，快速切换任务，即模拟Alt+Tab\n7.双指同时向左/右划，切换上一个/下一个项目，用于浏览图片或“开始”等横向排版程序的滚动\n快捷键 1.创建新的虚拟桌面：Win + Ctrl + D\n2.关闭当前虚拟桌面：Win + Ctrl + F4\n4.多桌面切换：Win + Ctrl + 左/右\n5.快速打开搜索：Win + Q\n6.快速打开Win10设置栏: Win + I\n7.临时查看桌面： Win+，\n8.最小化所有窗口：Win+M\n9.打开位于任务栏指定位置程序的新实例：Win+Shift+数字键\n10.最大化窗口(传统桌面)：Win + 向上键\n11.最小化窗口(传统桌面)：Win + 向下键\n12.将窗口最大化到屏幕的左侧(传统桌面)：·Win + 向左键\n13.将窗口最大化到屏幕的右侧(传统桌面)：Win + 向右键\n14.前进：Alt + 向右键\n15.后退：Alt + 向左键\n16.截图（保存到内存）：Win + Shift + S 以上快捷操作都是亲自验证后可用，仅供参考，后续的有新发现会持续更新，欢迎关注，谢谢。\n","date":"2018-08-08T12:54:53+00:00","updated":"2018-08-08T12:54:53+00:00"},{"objectID":"1520849513","permalink":"/tech/axure-lightbox-shade.html","title":"Axure教程：动态面板内容超出界线显示","content":"问题 随着用户需求的不断更新，产品原型的设计也在不断迭代升级，那么是必会让整体的设计复杂增加，各中组件相互影响的因素就更多。这不现在就遇到在动态面板上显示一个隐藏的元件时，结果下拉的组件显示不完全了，真的好是郁闷，如下图所示：\n从问题的表象可以分析出主要的关键点如下：\n隐藏的元件图层位置，并不是最顶层，导致显示位置不对 动态面板的大小，限制了隐藏元件显示的区域 解决方案 尝试过多次解决方案后，找到了个最优的办法，只要2个步骤即可，具体操作如下：\n顶层设置 定位到显示隐藏元件的点击事件，在显示的时候同时将其至为顶层，如下图所示：\n面板自适应 定位到隐藏元件所在的面板，在面板的属性上，将自动调整为内容尺寸打勾，如下图所示：\n效果预览 操作完以上2步后，即可查看到如下的效果：\nOK，至此已经实现我们想要解决的问题，遇过问题可以多点点Axure的各种设置，会有预想不到的效果，哈~。\n","date":"2018-03-12T10:11:53+00:00","updated":"2018-03-12T10:11:53+00:00"},{"objectID":"1514573103","permalink":"/tech/axure-datalist-table.html","title":"Axure教程：实现表格数据展示","content":"通常在系统管理后台中，使用列表（表格）形式展示数据是最为常见的方式。而在使用Axure设计产品原型时想实现这个数据列表却不太容易，或许常见的做法就是使用矩形拼凑起来，还有就是直接使用表格控件来布局。但是这都不太方便，首先就是布局麻烦，其次就是数据修改比较麻烦。接下来给大家介绍下如何使用表格+中继器控件实现数据列表。\n其实在实际的原型设计过程中，都会在表格+中继器的基础上增加个矩形框一起使用。这也是迫于无奈，在Axure上面表格无法实现单元格的合并。因此通常表格只能把表格做为数据列表中的表头，然后再利用中继器的数据填充功能来展示数据部分。当遇到一些需要合并的单元格时，矩形框便发挥了它的强大作用。下面就着重来讲下中继器如何来显示数据：\n创建中继器，双击进入中继器删除里面的初始内容\n创建与表格相同列数的矩形框，高度可自定义，宽度保持与表格对应列相同，给每个元件起个名字（配备自己喜欢的风格，后续数据就会复制当前的样式）\n选择中继器，在属性(Properties)中找到Repeater，创建与表格列数相同的列并起名（建议保持与上一步的名称相同），最后填充示例数据 注：可以直接在Excel中编辑数据，然后直接拷贝到中继器里面\n选择中继器，添加个Case用于绑定数据与矩形框的关系 设置隔行换色效果，选择中继器，在Style中找到Item Background勾选Alternating然后配对奇偶行的前景色 注：如果在中继器里面使用矩形框，一定要把其背景色设置为无，不然隔行换色就不起效果，这个教训惨痛的。\n这些便是关于在Axure中实现表格数据实现，如遇到一些复杂的要求，可以以此为参考，自由的发挥想象。\n整体的效果如下：\nPS:\n示例源文件下载： 数据表格.rp ","date":"2017-12-29T18:45:03+00:00","updated":"2017-12-29T18:45:03+00:00"},{"objectID":"1513369363","permalink":"/tech/axure-lightbox-shade.html","title":"Axure教程：实现动态的遮罩层","content":"今天在做产品原型设计时，遇到了个关于动态显现遮罩层的难点。\u0026ldquo;无奈\u0026quot;为追求高保真的效果，还是花了点心思做个原型实现。待做好回过头来看看的话，其实这个效果的难度也不大，只是看个人意愿是否想做而已。Axure本身就提供了模板的功能，也就是说只要实现一次但可以一劳永逸。下面就一起来看看这个遮罩层实现过程和效果吧。\n做前端开发的同学都知道，在HTML实现一个遮罩层，只需要添加个浮动的DIV即可轻松实现。那么在Axure中如何去实现它呢？\n如上图所示，可以将这个遮罩层的实现分为如下2部分：\n主体内容，即遮罩层要盖住的部分 遮罩层组件，即遮罩层+其它装饰部分（在Demo中只是增加了个Loading的动画图片来区分） 所以遮罩层的实现思路就清晰啦步骤如下：\n准备一个与你所想要遮盖内容大小相同的矩形框，注意要减去边框的大小，示例：主体内容大小为600x400，边框宽度为1px，那么遮罩层的大小为598*398且是无边框的\n设置遮罩层的填充色，还有相对的透明度\n加强遮罩层显示的动画效果（Axure上所支持的效果并不多，如不能够满足，可以采用文字描述阐明效果要求）\n接着用3个按钮来做不同效果的展示：\n打开遮罩层 关闭遮罩层 自动演示 那么现在来看看最终的实现效果如下，请看下面的大屏幕 在线查看 ：\n如果想要做全屏的遮罩层就更加的简单啦，只在要显示组件上增加个灯箱的效果即可。\nPS:\n示例源文件下载： 遮罩层效果.rp ","date":"2017-12-15T20:22:43+00:00","updated":"2017-12-15T20:22:43+00:00"},{"objectID":"1509040252","permalink":"/tech/nifi-windows-local-cluster.html","title":"Apache Nifi在Windows环境下搭建伪群集及证书登录","content":"前些时间做了关于Apache Nifi分布式集群的搭建分享，但很多时候要搭建分布式集群机器资源是个问题，而现在的单机的配置还是相当不错的，故现在就做个关于Windows上搭建个伪分布式集群的分享，同时通过另外一种方式实现Apache Nifi的授权认证。\n系统环境及软件版本 Windows8.1\nJDK1.8.0_131\nNifi-1.4.0\nNifi安装目录 WEB端口 xxx\\nifi-ncm 9443 xxx\\nifi-cluster01 9444 xxx\\nifi-cluster02 9445 (其它版本可参考此篇文章) 另在测试中发个问题，使用Apache Nifi内嵌的Zookeeper搭建伪集群里启动总是提示端口占用的问题，故放弃只采用了单结点启动。\nNifi的服务证书 生成本地Nifi服务证书 解压nifi-toolkit-1.4.0-bin.tar.gz文件后，通过CMD进入bin目录，执行以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 D:\\DevelopTools\\nifi-toolkit-1.4.0\\bin\u0026amp;gt;tls-toolkit.bat standalone -n \u0026amp;#34;localhost( 3)\u0026amp;#34; -C \u0026amp;#34;CN=Admin, OU=ApacheNIFI\u0026amp;#34; -o \u0026amp;#34;..\\target\u0026amp;#34; 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandaloneCommandLine: No nifiPropertiesFile specified, using embedded one. 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: Running standalone certificate generation with output directory ..\\ target …","date":"2017-10-26T17:50:52+00:00","updated":"2017-10-26T17:50:52+00:00"},{"objectID":"1508672549","permalink":"/tech/ninfi-cluster-deploy-with-kerberos.html","title":"Apache Nifi集群搭建及用kerberos实现用户认证","content":"最近这段时间在接触数据流式处理方面的事宜，用到了Apache NIFI现把安装配置中学习的一些经验分享下。此篇文章主要是针对集群及用户权限方面，关于 Apache NIFI 的介绍就不做过多的说明，直接引用官方的首页的说明如下图所示：\nApahce NIFI的单机运行是相当的简单，易用，完全就是傻瓜式的。下载解压，进行bin目录执行nifi.sh start 打开浏览器输入http://127.0.0.1:8080/nifi即可看到一个简洁漂亮的WEB UI。那么接下来我们要配置的是它的集群模式，官方说明NIFI采用的是0主节点模式，集群中的每个节点在数据集上执行相同的任务，但是每个节点都在不同的数据集上运行（详细的说明请查看 官方文档 ），并且内置了Zookeeper服务，如下图所示：\n系统环境及软件版本 CentOS7\nJDK1.8.0_91\nNifi-1.4.0\nKerberos5\n(其它版本可参考此篇文章)\nHostName IP Services centos7-master 192.168.56.100 Kerberos5 Server, Nifi Cluster Manager centos7-cluster01 192.168.56.101 Kerberos5 Client, Nifi Cluster 搭建Kerberos5服务 安装KDC服务及配置 进入到Master机器，执行以下命令安装KDC服务：\n1 yum -y install krb5-server krb5-libs krb5-workstation 注：测试中发现krb5-auth-dialo组件是不可用的，也无需安装\n修改KDC默认配置 进入/etc目录找到/etc/krb5.conf文件打开并修改，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # Configuration snippets may be placed in this directory as well includedir /etc/krb5.conf.d/ [logging] default = FILE:/var/log/krb5libs.log kdc = …","date":"2017-10-22T11:42:29+00:00","updated":"2017-10-22T11:42:29+00:00"},{"objectID":"1508343216","permalink":"/tech/ambari-monitor-status-issues.html","title":"关于Ambari中服务运行正常UI却显示服务停止的问题","content":"很多时候环境的维护的确是件头痛的事件，这不本来在Ambari的Dashboard页面显示正常服务的监控，实然间出现了个奇怪的现象： 在机器查询服务的运行进程是正常的，可偏偏Ambari的UI界面却显示状为停止，但端口检查又显示正常的。如下图：\n本也可以放任不管的(反正服务运行正常就好)，但无奈强迫症的\u0026quot;毛病\u0026quot;又犯了，非得把它消灭掉心里才舒服。尝试了几次都没能成功，后来回想下好像同事有手动启动的某些组件，难道是这个原因。使用ps检查了这些组件的进程用户，发现确实如此，强制杀死这些组件，然后使用Ambari UI重启它们，可最终的结果还是没变。\n真是挺郁闷的，此时也只好借助google啦，然后找到一篇类似问题的文章，里面提及到了运行时的xx.pid权限问题，真是一语点醒梦中人，赶紧的查看下这些组件的pid文件权限，果然如此，因为之前的启动是用超管用户，而实际上这些组件有对应的用户维护。删除这些xxx.pid文件，再在Ambari UI上重启这些服务，一切恢复正常，漂亮的绿色界面又回来啦。\n参考引用：\nservice-is-running-but-ambari-shows-serice-is-stop ","date":"2017-10-18T16:13:36+00:00","updated":"2017-10-18T16:13:36+00:00"},{"objectID":"1508261584","permalink":"/tech/hive2-jdbc-connector-issues.html","title":"HiveServer2因JDBC版本引起的问题","content":"之前一直都是用HDP来搭建和管理Hadoop环境，在安装完成调试时也未曾出现过棘手的问题，但这次在Centos6x系统上布署好后却是遇到奇怪的问题：\n表面上看来Hive服务是正常运行的，进程运行正常，页面UI也正常，日志也没错误输出。简单的建表的语句都能执行，可偏偏在导入本地/HDFS数据时，便就抛出异常啦。错误的堆栈信息如下：\n1 com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;OPTION SQL_SELECT_LIMIT=DEFAULT\u0026#39; at line 1 另外一个问题在使用Ambari提供的HiveView UI进行HDFS数据导入提示文件不存在，错误信息如下：\n1 org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path \u0026#39;\u0026#39;/tmp/xxx/xxxxx.csv\u0026#39;\u0026#39;: No files matching path hdfs:/... 简单描述下所使用的环境：\nHive - 1.2.1000\nMySQL - 5.6.17\nMySQL JDBC - 5.1.17\n问题一\n从报错的信息可以明显知道是语法错误的问题，不过麻烦的是它没有打印出有问题的SQL语句，通过google找到了遇到相同问题文章，其中指出这是MySQL JDBC驱动5.1.17版本以下的BUG，只需要更新JDBC驱动的版本即可。那么似乎问题变得简单啦，找到新的JDBC驱动文件，执行如下操作:\n拷贝驱动文件 1 2 3 4 5 6 # 拷贝到Amabri Server的资源目录 mv mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar ln -s -f /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java.jar # 拷贝到share目录 mv mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java-5.1.44.jar ln -s -f /usr/share/java/mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java.jar 重新设置Ambari驱动引用 1 ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 删除Ambari Agent上面的旧的驱动，并重启 1 2 3 4 # 注意做好备份和删除的路径 rm -rf /var/lib/ambari-agent/tmp/mysql-* # 重启服务 ambari-agent restart 在Ambari UI上重启Hive组件服务 理论上有这些操作便可解决问题了，可在运行数据导入后仍是出现同样的问题，说明上面的文件更新操作没有成功，切换到Hive Master机器上找到lib目录下的驱动文件，解压后发现版本确实没有变化，那么只能手动强制替换了，把Hive Master，Slave机器上的驱动全替换成最新版本，然后再次重启Hive组件服务，接着就出现个新问题。\n问题二\n单纯的从上述的日志无法确定问题的本身，因为可以确切的确定文件是存在于HDFS之上的。所以还是切换到Hive服务日志上面，找到下面的一段日志：\nERROR [HiveServer2-Background-Pool: Thread-4456]: hdfs.KeyProviderCache (KeyProviderCache.java:createKeyProviderURI(87)) - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider !! ERROR [HiveServer2-Background-Pool: Thread-4456]: metadata.Hive (Hive.java:copyFiles(2853)) - Failed to move: org.apache.hadoop.security.AccessControlException: Permission denied. user=admin is not the owner of inode=xxxxx.csv at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkOwner(FSPermissionChecker.java:250) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:227) 从这段日志明显的看出是用户权限的问题，不过这边有点不解，为何Ambari Hive View不直接使用超级用户进行操作，现在只能是强行的更改文件的所属者，命令如下：\nhdfs dfs -chown hdfs:hadoop /tmp/XXX/XXX.CSV 至此所有问题都修复完成，重新执行导入操作，一切运行正常，数据成功导入。\n参考引用：\nhive-metastore-not-working-syntax-error-option-sql ","date":"2017-10-17T17:33:04+00:00","updated":"2017-10-17T17:33:04+00:00"},{"objectID":"1504982742","permalink":"/tech/azkaban-execute-jobs.html","title":"Azkaban所支持的Job类型及示例","content":"在官方文档的介绍中，了解到Azkaban所支持的工作类型还是很丰富的，如：Command，HadoopShell，Python，Java，Hive，Pig等等。不过在此我们主要具体只来讲解下Python与Java的工作类型任务，其它工作类型的话，比如Commnad，Hive，HadoopShell相对比较简单就不做详解，有需要的话可以自行实践一下。\n不管提交哪一种任务，Azkaban默认都是通过上传压缩包来管理，那么在此建议大家养成一个习惯，不要所执行的文件(代码)打包到Azkaban的工程包里面。这样带来的好处是显而易见的，比如：\n工程创建的速度快，不需要上传执行部分文件\n避免了修改MySQL中的max_allow_packet参数以解决工程文件上传失败的问题\n在分布式布署环境中，当执行Task免去了在不同节点中拷贝工程包的麻烦\nJava工作任务 由于工作业务场景中，大部分的代码都是Java来编写的，这也正是选择Azkaban的重要原因。与常见的Java程序并无太大的差异，唯一的不同便是程序入口的方法不一样。需要在入口的类中增加个**run**方法，即这方法是启动整体个Task的关键。示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package io.github.elkan1788.azkabantasks; import azkaban.utils.Props; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Azkaban java job example * @author elkan1788@gmail.com */ public class JobMain { private static final Logger logger = LoggerFactory.getLogger(JobMain.class); private int fileRows; private int fileLine; /** * Dynamic parameters set */ public JobMain(String name, Props …","date":"2017-09-09T18:45:42+00:00","updated":"2017-09-09T18:45:42+00:00"},{"objectID":"1504880982","permalink":"/tech/azkaban-install-use-share.html","title":"定时调度任务器Azkaban安装","content":"背景与介绍 在大数据繁杂的ETL或其它数据处理过程当中，有些任务是需要定时执行的，虽然Linux自带了cron命令功能，但是仍不能满足最大的一点就是它不能提供集中式的管理和可视化的编辑。其实在大数据的生态当中已集成有个定时调度框架Oozie，只是实践下来发现其学习成本不低，布署的过程也较复杂。在尝试过其它分布工调度框架后（如阿里的宙斯Zeus），还是选择了社区较多人使用的Azkaban。\nAzkaban3相对于上个版本所做的更改还是比较大的，感兴趣的话可以到其官方网站 Azkaban 了解下。接下来主要还是分享下Azkaban3的安装布署，下面是Azkaban3的系统架构设计图：\n图中的3个组件便是Azkaban3的重要组成部分：\nMySQL关系数据存储数据 Web Server GUI管理服务提供者 Executor Server 分布式节点服务布署 数据库初始化 建议使用MySQL5.6及以上版本的数据库，首先创建一个名为azkaban的数据库：\n1 mysql\u0026amp;gt; CREATE DATABASE azkaban DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 指定某个数据库用户，为其赋予对azkaban数据库具有SELECT,INSERT,UPDATE,DELETE的操作权限：\n1 mysql\u0026amp;gt; GRANT SELECT,INSERT,UPDATE,DELETE ON azkaban.* to \u0026amp;#39;azkaban-dba\u0026amp;#39;@\u0026amp;#39;%\u0026amp;#39; WITH GRANT OPTION; 最后就是导入创建表的SQL语句，官方提供的建表语句比较分散，为此特地整理了份完整的建表语句 Azkaban Create Tables 密码: 8ne8 :\n1 mysql\u0026amp;gt; source /opt/download/azkaban-create-tables.sql 注意：由于Azkaban3的项目发布是通过上传文件实现的，因此需要把MySQL中允许上传包大小的能数调整下，此参数位于[mysqld]下：max_allowed_packet=64M，根据实际情况修改适合大小。\n其实有个办法可做到不修改此参数 ，就是打包Azkaban项目时尽量不要包依赖文件放进来，通过相对路径的引用即可。\nWeb …","date":"2017-09-08T14:29:42+00:00","updated":"2017-09-08T14:29:42+00:00"},{"objectID":"1503157226","permalink":"/tech/use-travis-ci-push-hexo-blog.html","title":"使用Github，Travis CI自动布署Hexo博客到Coding，OSChina服务器","content":"通常我们都是在本地用hexo deploy发布博客文章到远程的Pages服务器，可别忘记了我们是还需要提交代码的，所以是不是觉得有点麻烦还得分开两步进行操作。这时突然想起是否可用Travis CI工具来完成这个布署的操作呢？答案是肯定的，整体的流程大致如下：\n在本地(又或者Github网站)上编辑文章 提交文章到Github服务器 Travis CI收到通知，同步最新的Github代码，并执行用户自定义好的Travis脚本生成静态博客 最终再把生成好的博客推送到指定的Pages服务器 只是这其中有点比较麻烦的问题就是如何保护我们的私钥，还好Travis CI已经为我们准备好啦，那么就开始我们的捣腾之旅吧。\n准备Travis Client工具 准备Ruby环境 Ruby的安装请移步搜索引擎，在此只是提示下建议使用2.0以上的版本，另外就是注意更新gem的镜像地址： Ruby China 。\nTravis CI账户 如有需要可以单独注册账号，建议直接使用Github Token登录即可。 接下来就是需要生成个Github Token，在Github的个设置面板中找到，或者是直接点击 Github Tokens 进行创建，如下图所示：\n保存好刚刚创建的Token，然后使用Github授权登录Travis CI并跳转至控制面板 Travis Profile ，选择需要创建的项目(即你的博客项目)如下图所示\nTravis Client安装 Travis Client安装非常的简单，命令如下：\n1 sudo gem install travis -v 1.8.8 --no-rdoc --no-ri 安装成功后，使用如下命令检查，安装成功会有版本号的输出。\n1 travis version 使用如下命令检验上一步所生成的Github Token，并登录Travis CI成功后会返回欢迎信息。\n1 2 travis login -g fb25xxxxxxxxxxx Successfully logged in as xxxx! SSH私钥加密 切换到博客的根据目录，创建一个名为.travis的目录，并把用于Coding和OSChina的私钥拷贝至此，使用如下的命令生成Travis能识别的加密文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 travis …","date":"2017-08-19T15:40:26+00:00","updated":"2017-08-19T15:40:26+00:00"},{"objectID":"1502994018","permalink":"/tech/pymssql-azure-mssql-datasource-connect.html","title":"pymssql连接azure云的MSSQL数据库","content":"码好代码在测试环境做好测试后，满怀信心的去布署上线到生产环境，结果就是一堆的异常，具体查看了后发现是连接数据库的问题，异常信息如下：\n1 2 3 4 (40532, \u0026#39;Cannot open server \u0026#34;1433D\u0026#34; requested by the login. The login failed.DB-Lib error message 20018, severity 20:\\n General SQL Server error: Check messages from the SQL Server\\n DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed\\n\u0026#39;) 难道是环境安装的有问题，切换了下测试环境又没有问题，好吧，只好再次求助Google，最后找到了原因，应该是微软云自己做的规则，在用户名中加入主机名称就好了，参考如下：\n1 2 import pymssql conn = pymssql.connect(server=\u0026#39;yourserver.database.chinacloudapi.cn\u0026#39;, user=\u0026#39;yourusername@yourserver\u0026#39;, password=\u0026#39;yourpassword\u0026#39;, database=\u0026#39;AdventureWorks\u0026#39;) @yourserver 就是这个关键字\n参考：\n使用 Python 查询 Azure SQL 数据库 Cannot open server \u0026ldquo;1433D\u0026rdquo; requested by the login ","date":"2017-08-17T18:20:18+00:00","updated":"2017-08-17T18:20:18+00:00"},{"objectID":"1502891455","permalink":"/tech/mac-install-pymssql-module.html","title":"在Mac/Linux系统下安装pymssql模块","content":"在非Windows环境下去访问，连接 MSSQL 数据，本身就是件苦差事来的。自写Python程序以来在ORM方面都是使用pyxxx的模块，果不其然连接 MSSQL 也有个模块叫pymssql，只是实际使用中并不是特别的顺利。如笔者所处的环境就是如此，开发环境为OSX 10.11，发布环境为CentOS 6.4，按官方的安装步骤实行下来，Linux 环境是OK的，只是 Mac 环境下安装失败，错误的堆栈信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Running setup.py install for pymssql ... error Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \u0026#34;import setuptools, tokenize;__file__=\u0026#39;/private/tmp/pip-build-KA5ksi/pymssql/setup.py\u0026#39;;exec(compile(getattr(tokenize, \u0026#39;open\u0026#39;, open)(__file__).read().replace(\u0026#39;\\r\\n\u0026#39;, \u0026#39;\\n\u0026#39;), __file__, \u0026#39;exec\u0026#39;))\u0026#34; install --record /tmp/pip-A3wRBy-record/install-record.txt --single-version-externally-managed --compile: setup.py: platform.system() =\u0026gt; \u0026#39;Darwin\u0026#39; setup.py: platform.architecture() =\u0026gt; (\u0026#39;64bit\u0026#39;, \u0026#39;\u0026#39;) setup.py: platform.libc_ver() =\u0026gt; (\u0026#39;\u0026#39;, \u0026#39;\u0026#39;) setup.py: Detected Darwin/Mac OS X. You can install FreeTDS with Homebrew or MacPorts, or by downloading and compiling it yourself. Homebrew (http://brew.sh/) -------------------------- brew install freetds MacPorts (http://www.macports.org/) ----------------------------------- sudo port install freetds ...... /usr/bin/clang -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/opt/local/include -I/opt/local/include/freetds -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c _mssql.c -o build/temp.macosx-10.6-intel-2.7/_mssql.o -DMSDBLIB _mssql.c:18924:15: error: use of undeclared identifier \u0026#39;DBVERSION_80\u0026#39; __pyx_r = DBVERSION_80; 在安装pymssql之前有个关于的组件为FreeTDS，所遇到的问题也就是出现在此组件上面。 在Linux和OSX环境下的安装命令分别如下：\n1 2 3 4 5 # Linux yum install freetds-devel.x86_64 # Mac brew install freetds 在Mac环境中需要注意freetds的版本引起的问题，可以正常使用的版本为0.91，修正后的安装命令如下：\n1 2 3 brew uninstall --force freetds brew install freetds@0.91 brew link --force freetds@0.91 另外还得需要安装一个Python模块，安装命令如下：\n1 pip install cython 上述环境准备就绪后，便可以顺利的安装pymssql模块，执行如下安装命令：\n1 pip install pymssql 写个简单的测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python # -*- coding: utf_8 -*- # coding=utf8 import pymssql server = \u0026#34;192.168.1.2\u0026#34; user = \u0026#34;sa\u0026#34; password = \u0026#34;123456\u0026#34; conn = pymssql.connect(server, user, password, database=\u0026#34;platform\u0026#34;) cursor = conn.cursor() cursor.execute(\u0026#34;SELECT * FROM Table\u0026#34;) row = cursor.fetchone() while row: row = cursor.fetchone() print row conn.close() OK，全部搞定，继续码代码去。\n参考如下：\npymssql-isseues432 mac-pip-install-pymssql-error ","date":"2017-08-16T13:50:55+00:00","updated":"2017-08-16T13:50:55+00:00"},{"objectID":"1502810019","permalink":"/tech/hue-rdbms-mysql-chinese.html","title":"Hue中集成MySQL数据显示乱码","content":"Hue is a Web applications that enables you to easily interact with an Hadoop cluster. Hue applications let you browse HDFS, Jobs, run Hive, Pig and Cloudera Impala queries, manage the Hive Metastore, HBase, Sqoop, ZooKeeper, MapReduce jobs, and create and schedule worklows with Oozie.\n更加关于HUE的介绍及演示可访问其官方网站： http://gethue.com 在此主要解决的是在HUE过程中集成MYSQL管理时，遇到了数据库开发中常见的中文乱码问题。先来看看集成MySQL的配置描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ########################################################################### # Settings for the RDBMS application ########################################################################### [librdbms] # The RDBMS app can have any number of databases configured in the databases # section. A database is known by its section name # (IE sqlite, mysql, psql, and oracle in the list below). [[databases]] # sqlite configuration. ## [[[sqlite]]] # Name to show in the UI. ## nice_name=SQLite # For SQLite, name defines the path to the database. ## name=/tmp/sqlite.db # Database backend to use. ## engine=sqlite # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ ## options={} # mysql, oracle, or postgresql configuration. [[[mysql]]] # Name to show in the UI. nice_name=\u0026#34;MY SQL DB\u0026#34; # For MySQL and PostgreSQL, name is the name of the database. # For Oracle, Name is instance of the Oracle server. For express edition # this is \u0026#39;xe\u0026#39; by default. name=mysql # Database backend to use. This can be: # 1. mysql # 2. postgresql # 3. oracle engine=mysql # IP or hostname of the database to connect to. host=localhost # Port the database server is listening to. Defaults are: # 1. MySQL: 3306 # 2. PostgreSQL: 5432 # 3. Oracle Express Edition: 1521 port=3306 # Username to authenticate with when connecting to the database. user=USER # Password matching the username to authenticate with when # connecting to the database. password=PASSWORD # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ # options={} 这段配置很简单理解起来也难，可实际运行过程中就遇到了两个难题，先是显示出现乱码问题，另外就是配置中给的文档链接地址是**404**，真是尴尬啦。追溯下来最后到找到关于 sql-mode 设置，想下应该是支持MySQL的命令吧，然后就在配置最后一段加入如下的命令：\n1 options={ \u0026#34;init_command\u0026#34;:\u0026#34;SET NAMES `utf8`\u0026#34;} 实验了一下，乱码问题OK，中文显示正常。\n其实要不生产环境的话就不用如此的折腾，最简单的办法就是更新my.ini配置，你懂的。\n","date":"2017-08-15T15:13:39+00:00","updated":"2017-08-15T15:13:39+00:00"},{"objectID":"1502633954","permalink":"/tech/python-output-conosle-intime.html","title":"Python在命令行即时输出","content":"在程序遇到问题需要DEBUG时，通过会增加一些**print**语句输出。于是乎按惯例也在Python的代码中加入print调试，然后输入python xxxx.py，满怀信心的期待着调试信息的满屏滚动，结果是过了好阵子才显示出来。为何会这样呢？\n根据网友建议增加个-u参数就OK，后来查了下原因：Python在默认情况会先把print输出到缓冲中，待缓冲满或程序后才会输出。所以可以在运行Python程序时加入此参数是非常的有用。\n1 python -u xxxx.py 除此之外还支持别的参数，参考如下\n-B 参数，在import时候，不产生pyc或者pyo文件 -c 参数，直接运行python语句 -i 参数，运行完python脚本文件以后打开一个python环境，方便查看运行结果 -m 参数，将模块按照脚本执行 -V 参数，输出Python的版本 -O 参数，产生一个优化的pyo文件（和-B 参数一起使用无效） -v 参数，会输出每一个模块引用信息，包括从何处引用的，以及何时被清除的 -u 参数，在print记录时候很有用，使用这个参数 会强制 stdin, stdout 和 stderr变为无缓冲的，会立刻输出出来，而不是等缓冲区满了才会打印数据。 参考:\nPython命令行参数学习 ","date":"2017-08-13T14:19:14+00:00","updated":"2017-08-13T14:19:14+00:00"},{"objectID":"1502461021","permalink":"/tech/python-pip-install-chinese-mirror.html","title":"Python pip中国镜像服务器地址","content":"今天在安装一个Python模块\u0026ndash;\u0026gt;pymysql结果等待时间特别的长，最后超时失败啦，起初是以为是网络带宽问题，让IT调整后仍是失败，随后尝试查找国内的镜像，还有真人也遇到过相同的问题。镜像列表如下：\n1 2 3 4 5 6 https://pypi.douban.com/simple/ 豆瓣 http://mirrors.aliyun.com/pypi/simple/ 阿里 http://pypi.hustunique.com/simple/ 华中理工大学 http://pypi.sdutlinux.org/simple/ 山东理工大学 http://pypi.mirrors.ustc.edu.cn/simple/ 中国科学技术大学 https://pypi.tuna.tsinghua.edu.cn/simple 清华 然后在安装模块时，使用如下的命令：\n1 pip install xxxx -i https://pypi.douban.com/simple 网友还介绍了把镜像地址写入到配置文件的方法，但尝试没有成功，不明白其中的原因，待跟进。\n参考：\nPython pip 国内镜像大全及使用办法 ","date":"2017-08-11T14:17:01+00:00","updated":"2017-08-11T14:17:01+00:00"},{"objectID":"1501689875","permalink":"/tech/use-hexo-rebuild-blog-site.html","title":"使用Hexo重新构建个人博客站点","content":"其实在Github Page上面也是混迹许久啦，虽然现在各种Blog网站层出不穷，但是作为IT界的程序猿还是喜欢自己动手捣鼓捣鼓，成功固然是欣喜失败也会不气妥。 Github Page刚出道时使用的是Jekyll，简单的解释其实就是一个静态化网站的工具，这不现在又兴起一个名为Hexo(**Nodejs**实现)的工具。两者的目标皆是一致的，只不过对比下来发现Hexo上手确实要容易些，加者它能轻松的在本地实现调试，故有想法想再次折腾一翻，构建个Hexo版本的个人博客。\n介绍另一款静态网站工具 Gor ，它是鄙人一直崇拜的大拿 Wendal 的杰作，熟悉GO语言的朋友有可以关注下。\n动手前先对Pages服务做了个简单的调查，别无它意，就是现在Github用户越来越多且服务器又在国外的，生活在天朝的我们你懂的啦。惊喜的发现目前国内的Git服务商都提供了Pages实现，最后选择了 Gitee 和 Coding 作为新博客落脚点，其中Coding作为首先/默认服务，Gitee为备选的服务，作此选择的原因很简单：Coding不但提供了自定义域名，而且还附带了https免费证书，真是漂亮。\n对于Hexo环境的搭建在此就不在累述啦，官方文档给出了详细的说明(操作也是相当的简单)请移步： https://hexo.io/zh-cn/docs/index.html 。搭建好后可以在官方网站提供的 主题 页面中选择自己所喜爱的风格，个人选择的是较热门的 NexT ，喜欢它的简单，轻爽。\nNexT配置使用也是很简易的，下面就个人在搭建过程中遇到的问题做个简单的归纳：\n1.插件的的安装 Hexo相当的灵活提供丰富的插件支持，根据个人的需要可自行安装，个人的安装记录如下：\n1 2 3 4 5 6 7 8 9 # 生成RSS npm install hexo-generator-feed --save # 生成Site map为爬虫服务准备 npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save # 压缩站点文件 npm install hexo-all-minifier --save # 发布至Git服务器 npm install hexo-deployer-git …","date":"2017-08-02T16:04:35+00:00","updated":"2017-08-02T16:04:35+00:00"},{"objectID":"1501525973","permalink":"/tech/hexo-hello-world.html","title":"Hexo blog Hello World","content":"Welcome to Hexo ! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub .\nQuick Start Create a new post 1 $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing Run server 1 $ hexo server More info: Server Generate static files 1 $ hexo generate More info: Generating Deploy to remote sites 1 $ hexo deploy More info: Deployment ","date":"2017-07-31T18:32:53+00:00","updated":"2017-07-31T18:32:53+00:00"},{"objectID":"1500391423","permalink":"/tech/nodejs-apidoc-generator.html","title":"APIDoc自动生成接口文档","content":"对于项目开发常见的前后端分离模式来说，中间在后端完成接口开发交付对接时，前端人员往往苦于没有接口文档会经常\u0026amp;quot;跑去\u0026amp;quot;骚扰后端人员，真是苦不堪言哪。要是此时有个文档化的说明那就轻松多啦，现在后端流行的文档生成利器有Swagger，它虽然方便，但是也有弊端得写在的后台的代码中，而且启动整个后台项目才能访问。或许有时还真不太方便的，另外就是项目初期要对接口做个规划也无法用这个方法，难道就没有别的办法了嘛？\n最后在浩瀚的网络中还是找到个不错的工具—— Nodejs APIDoc ，非常的强大，支持当前流行的开发语言，如Java,PHP,JavaScript,Python,Ruby等等，下面就来简单的介绍下它的使用方法。\n安装模块 前面的介绍中已经说了它是基于NodeJS环境，所以你必须先有个NodeJS环境，然后就是安装下APIDoc模块，参考命令如下：\n1 npm install apidoc -g 工程配置文件 接下来创建个工程文件夹，并入个工程的配置文件，参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;XXXX开放接口平台\u0026amp;#34;, \u0026amp;#34;version\u0026amp;#34;: \u0026amp;#34;1.0.1\u0026amp;#34;, \u0026amp;#34;description\u0026amp;#34;: \u0026amp;#34;XXXX开放接口平台，设计所有与第三方服务对接的接口服务。请注意所有的接口数据交互格式为JSON格式。\u0026amp;#34;, \u0026amp;#34;title\u0026amp;#34;: \u0026amp;#34;XXXX开放接口平台\u0026amp;#34;, \u0026amp;#34;generator\u0026amp;#34;: { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;XXXX\u0026amp;#34;, \u0026amp;#34;time\u0026amp;#34;: \u0026amp;#34;2017-07-18 15:46:55\u0026amp;#34;, \u0026amp;#34;url\u0026amp;#34;: \u0026amp;#34;https://xxxx.com\u0026amp;#34;, \u0026amp;#34;version\u0026amp;#34;: \u0026amp;#34;1.0.1\u0026amp;#34; } } 接口文档 所有相关的准备工作完成后，那么此时我们就需要来写关于接口描述的文档，这个具体要看你今后实际项目的开发语言，建议尽量选择相同的，在此我就以Java为示例，不需要具体的代码，只需填充代码注释部分的内容，参考如下：\nhello-api.java\n1 2 3 4 5 6 7 8 …","date":"2017-07-18T15:23:43+00:00","updated":"2017-07-18T15:23:43+00:00"},{"objectID":"1496426603","permalink":"/tech/kylin-integrate-with-zeppelin.html","title":"Kylin集成Zeppelin展示数据","content":"实际上kylin自带的WEB UI已经集成了建议的图形报表，有常见的线形，柱形及饼图，用于数据的初步展示是完全够用的。如果要更加丰富的展示，那可以考虑使用别的工具，现在就试试官方推荐的Apache Zeppelin。\n打开 Apache Zeppelin官方网站 ，选择下载**zeppelin-0.7.1-bin-netinst.tgz**，版本其它的插件可以后续再安装。下载并解压到你想要运行的目录，然后拷贝conf/zeppelin-site.xml.template为conf/zeppelin-site.xml 修改对应的绑定地址和商口号。接着就是安装kylin插件， 命令如下：\n1 bin/install-interpreter.sh --name kylin --artifact org.apache.zeppelin:zeppelin-kylin:0.7.1 安装完成后使用如下命令启动zeppelin：\n1 2 bin/zeppelin-daemon.sh start # stop 停止 至此就可以打开浏览器然后访问zeppelin的WEB UI， 如下图所示：\nOK, 接下来就是创建与Kylin的连接，在Zeppelin中叫做Interpreter, 点击页面右上角的anonymous选择它如下图所示：\n同样的点击右上角的Create按钮，参考下图填写的数据填写你的真实数据：\n保存好后，点击左上角的Notebook\u0026ndash;\u0026gt; + Create new note如下图所示：\n把下面的SQL语句写入到notebook中：\n1 2 3 4 5 6 select fact.part_dt, lookup.categ_lvl2_name, count(distinct seller_id) as sellers from kylin_sales fact inner join kylin_category_groupings lookup on fact.leaf_categ_id = lookup.leaf_categ_id and fact.lstg_site_id = lookup.site_id group by fact.part_dt, lookup.categ_lvl2_name order by fact.part_dt desc 点击右边的开始按钮即可完成查询，出来一个表格数据 ，然后选取你所需要的图形报表形式，数据便会自动的渲染，点击settings可以有更多的调整。\n关于Zeppelin其它应用还需要慢慢了解，后续再跟进。\n参考：\ninterpreter-installation kylin ","date":"2017-06-02T18:03:23+00:00","updated":"2017-06-02T18:03:23+00:00"},{"objectID":"1495657133","permalink":"/tech/sqoop-import-data-to-hive.html","title":"Sqoop工具导入数据到Hive小记","content":"最近正在捣鼓构建数据仓库的事宜，正好有部分维度表的数据需要来自于RDBMS的数据，在HADOOP环境最流行的莫过于Apache的Sqoop工具，按官方的文档操作下来也很顺畅的，不过当要应用到业务场景上时问题便出现了。\n在Hive上面创建了一个Dimension表并用ORC格式储存（关于Hive ORC存储的介绍参考 Hive:ORC File Format存储格式详解 ），然后在执行Sqoop导入便会抛出下面的异常：\n1 FAILED: SemanticException Unable to load data to destination table. Error: The file that you are trying to load does not match the file format of the destination table. 经过几番测试后发现，Sqoop默认导入的数据格式为TXTFILE，所以当建表时使用TXTFILE存储格式就能正常的导入数据，但这不是我们所想要的，又查看了一下文档，发现其在1.4.5版本后提供了一个hcatalog命令是可以支持ORC File Format，参考命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 sqoop import --connect jdbc:mysql://master01:3306/data_pipeline --username dw --password-file hdfs:///user/hdfs/dw.txt --table dim_calendar --split-by ek_cal_id --compress --fields-terminated-by \u0026#34;,\u0026#34; --lines-terminated-by \u0026#34;\\n\u0026#34; --hcatalog-database default --hcatalog-table dim_calendar --map-column-hive cal_date=DATE,ts=TIMESTAMP --hcatalog-storage-stanza \u0026#39;stored as orc tblproperties (\u0026#34;orc.compress\u0026#34;=\u0026#34;SNAPPY\u0026#34;)\u0026#39; 从上面命令可以看出后续可以自由的定义存储格式及压缩格式，不过这边还有个问题会有个告警，如下：\n1 2 WARN hcat.SqoopHCatUtilities: Column cal_date had to be cast to a less precise type DATE in hcatalog WARN hcat.SqoopHCatUtilities: Column ts had to be cast to a less precise type TIMESTAMP in hcatalog 这个问题暂时没有办法解决，HIVE好像还支持这两种类型的数据格式，后面再跟进一下看看。\n执行Sqoop命令时一下要记得切换到同时安装有Sqoop Client与Hive Client的集群机器上，不然就会出现数据导入失败的情况。\n参考：\nSqoop使用手册 Hive:ORC File Format存储格式详解 Hive创建表时添加中文注释后乱码问题 SQOOP Import to Snappy ORC qoop Hive table import, Table dataType doesn\u0026rsquo;t match with database ","date":"2017-05-24T20:18:53+00:00","updated":"2017-05-24T20:18:53+00:00"},{"objectID":"1495091423","permalink":"/tech/linux-daemon-supervisor.html","title":"Supervisor介绍与使用","content":"很多时候我们自己开发的或别的服务都没有后台的守护进程，那么进程很容易就会被不小心的杀死，此时就需要有个程序去监控和维护这些程序服务。网上搜罗了一番后发现Supervisor组件正好能实现我们想要的，同时还支持对这些程序的统一管理，Nice!\n1 Supervisor is a client/server system that allows its users to monitor and control a number of processes on UNIX-like operating systems. 看完 官方网站 对Supervisor的定义描述，便立马觉得要实验一下。好在Linux系统中天生就是支持Python的，那么只要安装好PIP就可以得到你想要的一切。\n1.安装 pip：\n1 easy_install pip 2.安装 Supervisor:\n1 pip install supervisor 3.配置文件\n1 echo_supervisord_conf\u0026amp;gt;/etc/supervisord.conf 3.1 配置文件详解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [unix_http_server] file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用 ;chmod=0700 ; socket 文件的 mode，默认是 0700 ;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=0.0.0.0:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 [supervisord] logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log logfile_maxbytes=50MB ; 日志文件大 …","date":"2017-05-18T07:10:23+00:00","updated":"2017-05-18T07:10:23+00:00"},{"objectID":"1495040543","permalink":"/tech/maven-deploy-center-sign-failed.html","title":"发布jar到Maven时遭遇gpg签名失败","content":"有许久没维护自己开源的项目了，此次在修复BUG发布时遭遇失败，检查后发现原因是因为gpg签名失败，没办法换了MAC电脑有些操作不熟悉是有点郁闷的。\n关于如何将自己的JAR共享到Maven中央仓库，网上有很多的资源，大家可以自行尝试一下，其实也不难的，完全没必要担心英语的问题。\n分享一个别人整理的GitBook: 发布到中央仓库 1 2 3 [INFO] --- maven-gpg-plugin:1.6:sign (sign-artifacts) @ mpsdk4j --- gpg: 签名时失败： Inappropriate ioctl for device gpg: signing failed: Inappropriate ioctl for device 上面就是GPG在签名时遇到的问题，单纯从字面上来看是说对于此设备有个不适合的ioctl，不明白是何东西。最后一步步探究下来发现是因为管理GPG的服务器不能用的缘故，在网上找了个新的服务器重新上传如下：\n1 2 3 4 gpg --keyserver hkp://pgp.mit.edu --send-keys DAB131AA5564DCF176 #如果不放心的话，可以使用下面的命令检查一下 gpg --keyserver hkp://pgp.mit.edu --recv-keys DAB131AA5564DCF176 好啦，重新打包release jar包， 很开心的看到了SUCCESS的结果，收工。\n","date":"2017-05-17T17:02:23+00:00","updated":"2017-05-17T17:02:23+00:00"},{"objectID":"1494930103","permalink":"/tech/github-push-failed.html","title":"Github push失败：Could not resolve hostname","content":"平时最常用的git push命令突然间居然不可以用（错误日志如下），脑子首先蹦出的想法就是：难道Github又被墙了么！以前出现过类似这样的现象，需要通过指定hosts来加速访问。\ngit push 执行后返回的错误日志：\n1 2 3 4 ssh: Could not resolve hostname github.com:elkan1788: nodename nor servname provided, or not known fatal: Could not read from remote repository. Please make sure you have the correct access rights 首先用最简单的SSH命令检测一下，结果如下：\n1 2 3 4 5 6 ssh -T git@github.com Hi elkan1788! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. ssh -T git@git.oschina.net Welcome to Git@OSC, 凡梦星尘! 那说明git sever都是正常的，那为何push会失败呢？ 网友方法都一一试过，像指定hosts, 更新ssh key，添加DNS: 8.8.8.8等等。最后没有办法暂时把ssh更换成https模式， 执行git push输入用户与密码提交成功。 可是根本的问题并没有解决，最后想要不重新clone项目试试，于是乎重新创建目录，clone项目修改文件提交，结果是成功了。\n此时只能说是太诡异了，仔细回想下是否改动过配置呢？但确定是没有的，不过想起了上次编绎源码安装时更新了软件，难道是这个问题，输出git的版本如下：\n1 2 git --version git version 2.11.0 (Apple Git-81) 果不其然git是被更新了，但目前没有找到问题的确切的根源，主要的解决办法就是重新clone项目，问题自行解决， 后续有更新再跟进下。\n","date":"2017-05-16T10:21:43+00:00","updated":"2017-05-16T10:21:43+00:00"},{"objectID":"1494851661","permalink":"/tech/zookeeper-unload-data-exception.html","title":"Zookeeper崩溃后无法加载事务日志","content":"今天在生产的HDP环境中，遇到一件非常诡异的事情。明明搭建了2台zookeeper集群，却是莫明其妙的不见了，而且HDP服务还不报错，认真的检查过环境还是没有找到异常的信息，真是说不明白了。\n言归正传， 还是说说后面遇的问题吧： 生产环境zookeeper崩溃，查看日志发现是磁盘空间已经写满。起初以为是很简单的操作，删除无用的日志文件释放磁盘空间（这是不得不吐槽下HDP的日志文件是超多的，奈何生产环境又不敢不预留长些的时间），然后重启zookeeper满心欢喜的等待着服务恢复正常。然而这次没有看到成功的提示，异常不断各服务连接zookeeper都失败了。这时真的是郁闷了，空间明明已经是充足的。异常信息如下：\n1 2 3 2017-05-15 11:02:24,421 - INFO [main:FileSnap@83] - Reading snapshot /hadoop/zookeeper/version-2/snapshot.5ff3bc 2017-05-15 11:02:26,492 - ERROR [main:Util@239] - Last transaction was partial. 2017-05-15 11:02:26,494 - ERROR [main:QuorumPeer@530] - Unable to load database on disk 网上一阵搜索，期待可以找到相关的案例分享，案例倒是找到了不过，那些只是遇到问题并没有完全解决， 案例如下：\nZOOKEEPER-1621 数据文件读取异常 此时真是有点无语了，在着手查看zookeeper的源码时，同时切换成百度搜索引擎查找案例(大家都比较喜欢用Google，你懂的)，没想到还真的找到解决办法了，网友分享的案例：\nZooKeeper启动报错Last transaction was partial. 解决方法 1 2 3 4 5 6 7 8 原文如下： ZooKeeper 在硬盘满后，无法再次启动，抛出Last transaction was partial. Bug见：https://issues.apache.org/jira/browse/ZOOKEEPER-1621 首先我的环境是单节点，ZooKeeper的版本是3.4.8。 因为是单节点，ZooKeeper无法启动影响非常大，多节点也有可能出现同时硬盘都写满的情况，如果问题在线上发生，后果不堪设想。 折腾了一下，发现，把ZooKeeper安装目录下的data/log/version-2下的，大小为0（异常的）日志，删除掉后，再重启 ，问题解决！ 检查了一下对应的目录就真的发现了一个大小为0的log文件，删除然后启动zookeeper， OK输出日志正常，通过zookeeper client连接查看数据恢复正常。终于悬着的心可以放下来了，不过之前那个zookeeper莫名的消失问题还是没有找到原因。此次的经验教训就是以后类似这些重要的目录一定要做热备份，在大数据环境中zookeeper的生要性可想而知，还好此次是有惊无险。\n","date":"2017-05-15T12:34:21+00:00","updated":"2017-05-15T12:34:21+00:00"},{"objectID":"1492458751","permalink":"/tech/offline-install-hdp-ambari-notes.html","title":"离线安装HDP2.6(1)-Ambari Server","content":"1.参考文档 FYI: HDP Install Documents HDP Install Manual 2. 硬件环境 首先是要准备3台机器,安装最新的CentOS7.2，机器的配置参考要求如下：\nCPU Memory Disk Remark 4核 26G 200G 主节点/1台 4核 16G 200G 从节点/2台 3. HDP安装文件 下载离线安装的文件：\nFile Name Download Link ambari-2.5.0.3 http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3/ambari-2.5.0.3-centos7.tar.gz HDP-2.6.0.3 http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/HDP-2.6.0.3-centos7-rpm.tar.gz HDP-UTILS-1.1.0.21 http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz 4. SSH免密登录 配置免密码登录，注意这里主要是指master机器登录到其它cluster机器。所以最好先给机器指定好特定的hostname标识分开，参考如下：\nIP Host Name 192.168.1.1 test-hdp-master01 192.168.1.2 test-hdp-cluster01 192.168.1.3 test-hdp-cluster02 需要注意一点是，在CentOS7中过修改 /etc/hosts 文件已经无法实现机器名称的修改，需要使用新的命令： hostnamectl set-hostname test-hdp-master01\n然后在master机器上使用ssh-keygen -t RSA 密令生成SSH密钥，再使用命令 ssh-copy-id -i ~/.ssh/id_rsa.pub root@test-hdp-cluster01 拷贝到其它两台cluster机器，最后使用SSH登录命令检查是否安装成功，同时 …","date":"2017-04-17T19:52:31+00:00","updated":"2017-04-17T19:52:31+00:00"},{"objectID":"1464525261","permalink":"/tech/ssh-login-without-password.html","title":"Linux使用SSH免密码登录","content":"现在分布式集群非常的流行, 经常在不同的机器上面切换来回那是家常便饭. 如果每次切换都需要输入用户名与密码, 那就是要崩溃的节奏啊. 好在SSH-KEY给我们提供了便利, 只要在master生成一个PUB_KEY, 然后拷贝到clusters中, 以后便可以直接使用ssh hostname即能快速,方便的切换到需要操作的机器上面.\n先说下机器的环境:\n2台服务器均为Centos 6.7 x86_64 系统\n主节点master, IP地址: 192.168.8.200\n从节点cluster01, IP地址: 192.168.8.201\n下面首先在主节点上生成一个SSH-KEY, 在终端输入ssh-keygen -t rsa, 这里使用默认的存放的目录, 无密码, 连续按2次回车键即可, 如下图所示:\n然后将生成的PUB_KEY文件, 使用cat管道命令输出名称为authorized_keys的文件, 再用scp命令拷贝一份到节点服务器上面(此时是要输入密码的), 如下图所示:\n如无法执行scp命令, 请执行安装命令: yum install -y openssh-clients\n登录节点服务器, 在用户根目录下执行下面的命令:\n1 2 3 chmod 700 .ssh/ chmod 600 .ssh/authorized_keys 那么到这一步我们便可以实现SSH免密码登录的功能. 回到主节点服务器, 用ssh hostname就可以切换到想到操作的节点机器上面, Good Luck.\n注意:\nauthorized_keys 文件一定要在主节点服务器上生成, 不然是无效的, 即拷贝了PUB_KEY文件到节点服务器也仍是需要密码登录.\n如果是比较新的sshd, 可以用ssh-copy-id hostname的命令快捷的实现上面的步骤, 不过记得要先安装openssh-clients.\n参考:\nLinux下SSH免密码登录 Linux教程:SSH免密码登录的方法 ssh设置免密码登陆仍然需要密码 SSH免密码登录详解 原理:\n为了更好的理解SSH免密码登录原理，我们先来说说SSH的安全验证，SSH采用的是”非对称密钥系统”，即耳熟能详的公钥私钥加密系统，其安全验证又分为两种级别。\n基于口令的安全验证 这种方式使用用户名密码进行联机登录，一般情况下我们使用的都是这种方式。整 …","date":"2016-05-29T12:34:21+00:00","updated":"2016-05-29T12:34:21+00:00"},{"objectID":"1454070861","permalink":"/tech/git-commands-collect.html","title":"Git 操作命令收集","content":"都说好性不如烂笔头, 一点也没有错呀. 虽然学习Git已经有1个多年头, 但是有些时候那比较少用的命令总是一时想不起来.所以还是决定把它写到blog里面, 不仅把经验分享出去, 而且也便于自己查找, 此博文会持续累加.\nGit命令别名(非常实用) 1 git config --global alias.co checkout 解读: 用co替代checkout, 除此之外, 还可以把一些组合的命令用别名设置, 例如:\nAlias Name Description co checkout ci commit br brach l log \u0026ndash;oneline 回退到首次提交(估计很少人会遇到) 1 git update-ref -d HEAD Tag操作\n查看标签\n1 git tag -l 创建标签 1 git tag -a 1.0.1-Release -m \u0026#34;Release 1.0.1 version\u0026#34; 删除标签 1 git tag -d 1.0.1-Release 远程推送 1 git push --tag 远程删除 1 git push origin :refs/tags/1.0.1-Release Git学习推荐:\n廖雪峰-Git教程 ","date":"2016-01-29T12:34:21+00:00","updated":"2016-01-29T12:34:21+00:00"},{"objectID":"1453565312","permalink":"/tech/mpsdk4j-intro-mapaccount.html","title":"mpsdk4j的点滴记录--MPAccount","content":"mpsdk4j是在实际的生产项目中抽离出来的开源分享项目,它的成长至今也算是有不少的经历吧, 最近一直忙于工作与生活上的事情疏忽了对它的关心. 自去年下决心对它重构并建立了QQ交流群( 486192816 )后, 逐渐的有不业界朋友前来关注, 在此非常感谢他们的支持. 都说用过方知其好, 可实际情况确不是这么乐观呀,在大家的使用过程中发现mpsdk4j有不少欠缺与不足的地方. 之前一直想在元旦发布的2.b.1版本也拖延至今还没有交工, 在此对大家说声抱歉, 以后定会嘉勉.下面还是先进入此次的主题\u0026amp;ndash;初识mpsdk4j之MPAccount. (注: 对于有微信开发基础与项目经验的可略过)\nmpsdk4j自发布之时起的目标就是要做到原生态,简单易用. 不过在实际的交流过程中发现一个普遍的现象, 就是对初次接触微信开发的朋友来说,mpsdk4j的使用还是有点难(这也是为何要写这一篇博文的原因之一). 那么接下来我们就先简单的认识下微信公众平台开的所需要的元素, 以及它们与mpsdk4j之的映射关系.\n微信公众号属性 序号 属性 示例 备注 1 公众号原始ID gh_20e50b3b4r9u 以gh_开头的(不明白其含义) 2 公众号昵称 mpsdk4j 用户自定义的公众号别名 3 用户唯一凭证(应用ID) wxa822bd879532187 以字母wx开头的,其含义大概是微信的拼音首字母 4 用户唯一凭证密钥(应用密钥) 613d3ce897hgf71a875d1342c8325f3d 32位的随机字符串 5 AES 加解密密钥 JwAsfZH4p9iuuvfxjry6cLtlOgZAd853kJQ5hNv5OI4 43位的随机字符串 6 开发者服务令牌 weixindev 用户接入微信开发者服务时的自定义令牌 7 公众号类型 S D: 订阅号, S: 服务号, E: 企业号 (预留字段) 8 是否认证 true true: 通过认证, false: 未通过认证 (同上也是预留字段) mpsdk4j中的代码映射关系 那么在mpsdk4j中我设计了一个对象, 位于io.github.elkan1788.mpsdk4j.vo包中其名字叫MPAccount, 直译过来是微信公众号的意思. 它将上面的8个公众号属性对应的代码如下:\n1 2 3 4 5 6 7 8 9 …","date":"2016-01-23T16:08:32+00:00","updated":"2016-01-23T16:08:32+00:00"},{"objectID":"1453237880","permalink":"/tech/mapdb-write-read-sync.html","title":"MapDB 同步读写示例","content":"MapDB 是一个快速、易用的嵌入式Java数据库引擎. 最主要的特点之一就是支持磁盘存储,直接把内存中的Hash Map同步写入到磁盘. 另外特别惊喜的是它支持ACID事务,MVCC隔离, 且有全职的开发者支持.\n看完官方的文档与示例后,基本上可以确定它符合业务场景的使用要求.另外发现官方正在重构3.x的版本, 但应该不会这么快发布吧.用google搜索了下关于MapDB的使用案例, 也不是很多. 可能是本来官方的文档就齐全有关吧,API也不复杂,跟着官方的文档走一遍就可以上手了.\n动手测试了简单的示例后, 突然冒出一个疑问, 如何实现同时操作磁盘上的一个数据库, 以及同一个HashMap呢? 这里需要明白的, MapDB存储到磁盘上的数据库文件,并非只是存放了一个HashMap, 这有点类似数据库里可以有多张表的概念相同. 那么数据库是可以支持多连接的, MapDB是否也同样支持呢?(理想确实很丰满,但现实太骨感了!)\n初步检验的结果是, MapDB并不支持同时访问磁盘上的同一文件. 那么也就是只能创建一个长连接, 直到业务功能处理完成再关闭它. 幸运的是它支持对已经存在或是运行中的同一个HashMap进行读写操作. 下面来看看简单的示例代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 import org.mapdb.BTreeMap; import org.mapdb.DB; import org.mapdb.DBMaker; …","date":"2016-01-19T21:11:20+00:00","updated":"2016-01-19T21:11:20+00:00"},{"objectID":"1435581261","permalink":"/tech/redis-install-settings.html","title":"Redis 安装与配置","content":"Redis 是一款依据BSD开源协议发行的高性能Key-Value存储系统（cache and store）。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。 更多介绍 系统环境: Linux 3.10.0-229.el7.x86_64 x86_64 x86_64 x86_64 GNU/Linux(Centos7.1)\n1.下载\n1 2 $ wget http://download.redis.io/releases/redis-3.0.1.tar.gz 解压安装 1 2 3 4 $ tar -zxf redis-3.0.1.tar.gz $ cd ./redis-3.0.1 $ make \u0026amp;\u0026amp; make install 配置Redis服务 1 2 3 4 $ cp ./redis-3.0.1/utils/redis_init_script /etc/rc.d/init.d/redis $ mkdir P /etc/redis $ cp ./redis-3.0.1/redis.conf /etc/reddis/6379.conf 启动Redis 1 2 3 4 $ service redis start $ ps -ef|grep redis $ root 8687 1 0 12:06 ? 00:00:00 /usr/local/bin/redis-server *:6379 redis.conf参数说明 daemonize：是否以后台daemon方式运行\npidfile：pid文件位置\nport：监听的端口号\ntimeout：请求超时时间\nloglevel：log信息级别\nlogfile：log文件位置\ndatabases：开启数据库的数量\nsave * ：保存快照的频率，第一个表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。\nrdbcompression：是否使用压缩\ndbfilename：数据快照文件名（只是文件名，不包括目录）\ndir：数据快照的保存目录（这个是目录）\nappendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。\nappendfsync：appendonlylog如何同步到磁盘（三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步）\n","date":"2015-06-29T12:34:21+00:00","updated":"2015-06-29T12:34:21+00:00"},{"objectID":"1334949080","permalink":"/tech/nutz-jdoc-chinese.html","title":"Nutz源码Jdoc在IDE中补全提示时出现乱码解决办法","content":"接触Nutz也有一段时间，随着对它使用的不断深入了解，才越发觉它的强悍与作者的设计巧妙，特别喜欢它那个JUnit测试报告，而且更新的速度也挺快的，到现在的1.b.44版本，ssh所拥有的功能可以说它也已经完全具备了。对于程序员来说学习一种新技术最快捷的办法就是Demo+API，这两样也是必备之需哪。Nutz在这方面做的也是相当的不错，比如在Demo方面有人贡献出了整个CMS的源码(非常感谢作者的分享哪，从里面学习了不少知识)，API方面提供了常见的CHM格式和JAR包。不过这个JAR的API在实现应用中却是出了点小问题，下面就来详细说说。\n我的开发环境：\n操作系统：Window7\nJava虚拟机：JDK1.7\nIDE工具：Netbeans7.1\n项目编码格式：UTF-8\n用Netbeans创建一个简单的WEB工程，把从GOOGLE CODE下载来的Nutz相关文件里面抽取出开发所必须的创建了一个新的库引用，这些操作和显示都正常，但当用代码自动补全时，发现了个问题，代码补全出来的JDOC居然是乱码的，如下图所示：\n咦，这是怎么回事呢？？重新检查了自己的工程编码属性，确定是UTF-8没有错哪，如下图所示：\n试着打开源码查看，却是得到提示信息说“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？”\n难道说Nutz生成JDOC时使用的是GBK编码来的，看来只好连接GitHub库下载个库看看。下载下来查看工程的编码格式也是UTF-8，这就奇怪了\u0026amp;ndash;乱码从何产生呢？？看来只好自己生成个JDOC看看了，在UTF-8环境中生成JDOC要注意编码格式的设置，如下图所示，\n生成好JDOC后，直接修改Netbeans库的源码和JDOC连接，打开创建的工程使用代码自动补全提示一切正常.\n问题算是解决了，不过引起这个问题的原因还真得思考下，编码格式的不同所造成的影响还真是郁闷哪。上面提到在没有修改前打开源码提示信息“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？” 按照信息所描述是不是将Nutz的源码修改成GBK编码格式也可以呢？于是写了个编码格式轮换输出小程序测试了下，结果说明猜想是正确的，呵~\n其实这个小程序不单只是可以转换Nutz的源码，它还可以转换任何项目的编码格式(仅支持JAVA文件)，注意是由UTF-8转换成GBK编码格式哦，那么接下来就慢慢体验 …","date":"2012-04-20T19:11:20+00:00","updated":"2012-04-20T19:11:20+00:00"},{"objectID":"1332627680","permalink":"/tech/java-hard-rsr232.html","title":"Java程序与RSR232串口通讯小练手","content":"一直以来都是在学习J2EE方面的应用系统开发，从未想过用JAVA来编写硬件交互程序，不过自己就是喜欢尝试一些未曾接触的新东西。在网上搜索了些资源，了解到JAVA写串口通讯的还是蛮多的，那么便着手准备开发调试环境。软件程序开发环境搭建不成问题，可这硬件环境就有点犯难啦。更何况自己用的是笔记本哪来的串口呀，再说要是真拿这串口硬件来自己也不会弄，随即想到了虚拟机，觉得这东西应该也有虚拟的吧，果真跟自己的猜测一样还真有这东西，顺便也下载了个串口小助手做为调试之用。\n下面就先看看软件环境的搭建：\n下载comm.jar、win32com.dll和javax.comm.properties。 (附件提供下载) 介绍：comm.jar提供了通讯用的java API，win32com.dll提供了供comm.jar调用的本地驱动接口，javax.comm.properties是这个驱动的类配置文件 拷贝javacomm.jar到X:\\jre\\lib\\ext目录下面; 拷贝javax.comm.properties到X:\\jre\\lib目录下面; 拷贝win32com.dll到X:\\jre\\bin目录下面; 更新下IDE里面的JDK环境，如下图： 接着是硬件虚拟环境安装虚拟串口，这里我用的是VSPD6.0(附件提供下载)，安装好后启动VSPD添加我们所需要的端口，注意这里是按组的方式添加的，例如COM1和COM2是一组同时添加，以此类推。\n所有环境都准备好后，先来简单认识下comm.jar的内容。单从comm API的javadoc来看，SUM提供给我们的只有区区以下13个类或接口，具体如下：\n1 2 3 4 5 6 7 8 9 10 javax.comm.CommDriver javax.comm.CommPort javax.comm.ParallelPort javax.comm.SerialPort javax.comm.CommPortIdentifier javax.comm.CommPortOwnershipListener javax.comm.ParallelPortEvent javax.comm.SerialPortEvent javax.comm.ParallelPortEventListener (extends …","date":"2012-03-24T22:21:20+00:00","updated":"2012-03-24T22:21:20+00:00"},{"objectID":"1326450080","permalink":"/tech/nutz-ke-lhg-my97.html","title":"国内技术强强联手之Nutz+KindEditor+LHGDialog+My97DatePicker","content":"有段时间没关注过国内IT技术发展情况了，前些天在学习国内的一个开源技术Nutz时想练个手，但一时又不知写些什么好，想了一会还是选择了自己的“老友”KindEditor。对它虽不敢说是透彻的了解(个人的JS水平有限，呵~)，但至少也能很熟练的运用。官网很早便推出了大家期待已久的KE4，不过我一起都没有更新，正好这次拿它来历练下，嘻~。可是想到前面写的那些KE应用示例都是单调的，上次的那个还好有EasyUI做衬托，不过这个UI框架对于小小于的练手项目来说还是庞大了点。于是又便开始寻思着找别的UI看看，突然间起了以前用过的LHGDialog弹出窗口组件还蛮不错的，便去它官网逛了一圈。没有想到还真是让人喜出望外呀，LHG现也更新为4的版本了，那效果的炫丽真是让人颇然心动。下面就先来欣赏下花费2个多小时的劳动成果吧（现在是真相时间），呵呵……\n在此不得不称赞下Nutz的高效简约之美，和以前的KE版本一样还是把上传部分的JSP页面翻译成后台JAVA代码，唯一不同的就是那些相同功能的实现代码精简了好多呀，官网示例中的两个JSP文件被有压缩成了一个只有不到400行的JAVA后台代码，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 …","date":"2012-01-13T10:21:20+00:00","updated":"2012-01-13T10:21:20+00:00"},{"objectID":"1321611680","permalink":"/tech/whosip-tool.html","title":"IP地址查询Web接口调用","content":"今天刚好有个站点上要用到一个IP地址显示的功能，随即便想想应该有免费的接口可用吧，百度一下找到了太平洋网站提供的API，那么接下来便是Code Time。\n看完了它的参数说明和调用方式后，选择了其中的jsFunction方式，现在把经验分享出来给大家参考，具体的代码和效果如下：：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;!DOCTYPE html PUBLIC \u0026#34;-//W3C//DTD HTML 4.01 Transitional//EN\u0026#34; \u0026#34;http://www.w3.org/TR/html4/loose.dtd\u0026#34;\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;ip查询\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/1.7.0/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; $(function(){ $(\u0026#34;\u0026lt;span id=\u0026#39;ipShow\u0026#39;\u0026gt;\u0026lt;/span\u0026gt;\u0026#34;).appendTo(\u0026#34;body\u0026#34;); $.getScript(\u0026#34;http://whois.pconline.com.cn/jsFunction.jsp?callback=jsShow\u0026amp;ip=61.235.82.163\u0026#34;); }); function jsShow(location){ $(\u0026#34;#ipShow\u0026#34;).html(location); } \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 效果如下：\n具体参数如下：\n有不明白的地方，可以留言讨论。\n","date":"2011-11-18T10:21:20+00:00","updated":"2011-11-18T10:21:20+00:00"},{"objectID":"1318889420","permalink":"/tech/kindeditor-jsp-struts2-servlet.html","title":"JSP版本的KindEidtor在线编辑器第二季：Servlet+Struts2集成版","content":"前段时间我在论坛上发布了一篇名为 《JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)》 得到了大家的积极响应，不过令我觉得有点遗憾的是，有很多人都不是真的讨论技术问题，而是向我索取源码，说实在的自已的劳动成果就这样白白奉献出来，觉得有点对不起自己了，要知道我们国内的技术员都是没有金钱后盾啊。唉，最近都太忙了就没有怎么太在意这件事，今晚刚好有空过来看看。看了那么多人留下的印记后，觉得自己也应该要无私一下才是吧，咱老毛说的对：要像雷锋同志学习，呵呵…… 其实在上面我已经说过了，这个JAR里面的功能我只是把官网的JSP代码改编而已，废话就先不多说了，下面直接上码吧，可要接稳了哦。\n图片上传功能代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 …","date":"2011-10-17T22:10:20+00:00","updated":"2011-10-17T22:10:20+00:00"},{"objectID":"1305552500","permalink":"/tech/myeclipse-chinese-tool.html","title":"MyEclipse6.5+ IDE汉化软件","content":"世界上的语言与文字都有千百万种，但始终还是觉得我们的方块汉字比较好看且比较有内涵。而在计算机领域一直都是被国外主宰，所以很多计算机上的程序都是英文版的，有时候用起来还真是不太方便的，于是便出现了一大批汉化版的程序，这些程序都受到了国人的偏爱。\n在JAVA界的开发工具中使用最多的IDE莫过于Eclipse与MyEclisep，而这两款IDE的开发者均为外国人，所以IDE的界面为英文也就不足为奇了。作为另个一款后起之秀Netbeans开发工具我想是比较受国内编程初学者的喜爱，为何？很简单它的界面支持中文。\n还是先转回我们今天的主题MyEclisep汉化程序吧，Eclipse的汉化就不用多说了，自己直接去官网下载个语言包便可以实现中文界面，但MyEclipse就没有那么简单了，以前曾在网上找到一个牛人写的汉化包，试用了下效果还不错，不过就是步骤有点麻烦，昨晚突发奇想能不能把它做个傻瓜化的汉化程序呢？想了想觉得可行度有70%左右，最终衡量下还是决定CODE，最终在大约3个小时后便成功做出这个汉化程序，界面效果如下：\n如果你觉得有需要就下载个回去用用看吧，下面来说说这个软件的使用方法：\n直接解压下载下来的压缩包，记得不要破坏目录结构不然就无法汉化了，双击MyEclipse汉化软件(透明).exe(这个需要最新版本JDK)或MyEclipse汉化软件(无透明).exe；\n浏览并选取MyEclipse安装根目录下的Common目录，这个要视你的安装位置而定；\n浏览并选取bundles.info(插件指定)文件，此文件目录下\\MyEclipse ...\\configuration\\org.eclipse.equinox.simpleconfigurator目录下；\n浏览并选取myeclipse.ini文件，些文件在\\MyEclipse ...目录下；\n点击开始汉化按钮后，如果成功便会出现下面的成功提示，现在你重启下MyEclipse程序看看，最好用-clean命令；\n看看汉化后的MyEclipse界面吧：\n可能是因为汉化包有点旧的原故吧，所以并不是完全汉化的，如果说你有比较好的汉化包，希望你能与大家分享下。最后要说的是，如果你觉得汉化的效果不理想又想还原英文界面的话，只要恢复对应文件夹目录下的bundles_backup.info与myeclipse_backup.ini文件重启 …","date":"2011-05-16T13:28:20+00:00","updated":"2011-05-16T13:28:20+00:00"},{"objectID":"1304587932","permalink":"/tech/kindeditor-jsp-source.html","title":"开放JSP版KindEditor的附件JAR包源码","content":"3月份的时候写了个JSP版本的kindeditor编辑器的帖子，没有想到大家的响应会这么强烈。不过随着日月的增长，此版本的插件也就暴露出一些BUG，如：Struts2如何集成，web.xml文件中配置上传属性不便修改且繁琐，上传图片(附件)不能保存于其它盘…………。现在平时开发的项目中都是使用KE作为在线编辑器，为了能更好、更方便的使用此编辑器，在休息的时间对原先的代码进行重构再封装，除对上个版本出现的BUG进行外，还统一整体的命名规范，新增了一些功能。\n当前新版本插件的版本号为：kindeditor-plugin0.4RELEASE，JAR包中类的列表如下：\n此次重构所完成的功能主要有以下几点：\n重构上传附件页面的选择按，仿图片上传的选择按钮； 增加Struts2环境集成； 增加上传属性配置功能，方便站点布署修改(暂未开放)； 增加其它盘存储功能，可自由选择存放位置方便备份(暂未开放)； 增加上传图片的文字水印功能(暂未开放)； 更Kindeditor编辑版本为3.5.6； 上传附件分类管理 如果你要把这个KE插件应用到你的项目中，很简单，如是Servlet环境只须一个步骤即可，Struts2环境则需要两个步骤，具体如下：\nServlet环境：只需要在web.xml中配置如下的参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 \u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;web-app version=\u0026amp;#34;2.5\u0026amp;#34; xmlns=\u0026amp;#34;http://java.sun.com/xml/ns/javaee\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; …","date":"2011-05-05T09:32:12+00:00","updated":"2011-05-05T09:32:12+00:00"},{"objectID":"1301001473","permalink":"/tech/kindeditor-jsp-complete.html","title":"JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)","content":"在此之前我一直都是在用FCKEditor在线编辑器，当然也有用过其它在线编辑器如eWebEditor,tinyMCE,CuteEditor，jHtmlArea等等，但在最终项目发布的时候并没有采用它们，因为它们要不是皮肤呆板，就是配置太烦琐，或是功能太少、浏览器兼容性不好等等。去年一个偶然的机会让我认识了KindEditor这款在线编辑器，正如它的名字那样这是款友好的编辑器，它不仅体积小配置简单，而且功能与皮肤也是令人相当的振憾。还有个很重要的因素，它是我们国人的开发的免费工具，从产品发布至今更新脚步未曾停止哦。下面就会大家介绍下经过我完善后的KindEditor吧。\n目前官方网站已经将KindEditor更新到了3.5.2版，从3.4的版本开始官方就去除了一些不常用的功能改用plugin形式来丰富KindEidtor，这就为我们打造个性的插件奠定了基础。其实只要是你的JS基础够扎实，花点时间看看KindEditor的源码，你就完全可以在其原有的基础上完善出你所想要的功能。下面是我的完善记录：\n集合了日期、时间、在线预览和特殊字符插件,采用3.0皮肤；\n将图片上传与管理的JSP页面改写成SERVLET，同时去除JSON包；\n添加图片压缩功能，对超出的宽高压缩成指定的值；\n添加上传附件功能；\n添加图片、附件按日期文件夹分类管理的功能；\n添加上传图片、附件的title属性，缺省为原文件名；\n添加上传附件相关的初始属性\n修改从word粘贴样式，减少样式。\n关于如何使用我就不多说了，官方网站上有详细的API，文章最后我也会给出经我完善的KindEditor还有Demo，先来看看效果吧。\n完善后的KE目录 完整功能示 浏览服务目录 附件展示效果 与Extjs整合效果 最后要说的是这款编辑器真的很不错，相信你用过它后一定会喜欢上它的，呵呵，多多支持国内软件事业的发展吧。\nPS: 示例源码下载 ","date":"2011-03-24T21:17:53+00:00","updated":"2011-03-24T21:17:53+00:00"},{"objectID":"1288742400","permalink":"/tech/jquery-ajax-struts2.html","title":"关于Struts2与Jquery实现无刷新分页的不解问题","content":"我最近正在做一个无刷新的网站管理后台，并把它作为我的毕业设计主题，不过在代码实现上遇到了点小问题，想向大家请教一二。我的设计思路大概是这样的：将后台所生成的数据用JSON的格式输出，在前台借助JQUERY的AJAX功能将传过来的数据写出。这样的方式在实现数据的增、改、删功能上并不会很难，不过在数据的查询方面便麻烦了，如何实现数据的无刷新分页呢？我查阅网上一些网友的做法，不过普遍发现他们的代码有点繁琐也不符合我设计初衷。通过查看JQUERY的API我自己想出了一种可行的方案(目前已经实现部分功能)：在查询的页面中先创建一个无数据的表格样式，通过JQUERY的CLONE功 能在查询数据时复制这个表格的样式同时将后台传过的数据填充其中和移除那行无数据的样式表格。\n前台的JS相关代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 显示所查询的数据 function dataSource(){ $.ajax({ url:\u0026#34;${pageContext.request.contextPath}/jsonservlet\u0026#34;, type:\u0026#34;post\u0026#34;, data:{}, dataType:\u0026#34;json\u0026#34;, error:function(){alert(\u0026#34;服务器通讯失败，请稍后再刷新页面。 ^_^\u0026#34;);}, success:function(data){ insertTr(data); } }); } // 查询数据的分页跳转 function goPage(thePage){ $.ajax({ url:\u0026#34;${pageContext.request.contextPath}/jsonservlet\u0026#34;, type:\u0026#34;post\u0026#34;, data:{page:thePage}, dataType:\u0026#34;json\u0026#34;, error:function(){alert(\u0026#34;服务器通讯失败，请稍后再刷新页面。 ^_^\u0026#34;);}, success:function(data){ insertTr(data); } }); } // 填充表格中的每行数据 function insertTr(data) { //读取tr里数量 var r = $(\u0026#34;#datasource tr\u0026#34;).size(); var list = data.dataSource; $.each(list, function(i, r) { //克隆已有的表格样式及属性 var row = $(\u0026#34;#source\u0026#34;).clone(); //将数值填充至表格中 row.find(\u0026#34;#id\u0026#34;).text(r.id) row.find(\u0026#34;#name\u0026#34;).text(r.name); row.find(\u0026#34;#time\u0026#34;).text(r.time); //将此行添加到表格中 row.appendTo(\u0026#34;#datasource\u0026#34;); }); // 移除第一行，因为它只有样式没有数据 $(\u0026#34;#datasource\u0026#34;).children(\u0026#34;tr:first\u0026#34;).remove(); } 通过实践发现这个方案是可行的，不过出现了一个问题：在数据翻页时如何将当前的数据移除并将新数据填充到页面中呢？（即：在转到第2页时把当前第1页的数据移除并填充第2页的数据）我尝试了很多方法可仍是未能实现我想要的无刷新的分页效果，希望大家能帮我看看是哪里出问题了。谢谢。\nPS: (最后自行解决了，解决方案如下)\n1 2 var r = $(\u0026#34;#datasource tr\u0026#34;).size(); 只要在上面的代码后面增加如下的代码:\n1 2 3 4 if(r \u0026gt; 1){ $(\u0026#34;#datasource\u0026#34;).find(\u0026#34;tr:not(:first)\u0026#34;).remove(); } \u0026ldquo;代码下载\u0026rdquo; ","date":"2010-11-03T00:00:00+00:00","updated":"2010-11-03T00:00:00+00:00"},{"objectID":"1283681513","permalink":"/tech/jquery-ajax-struts1.html","title":"JQuery+Strusts1.x实现Ajax无刷新登录","content":"在当今技术发展日益成熟，人们除了追求技术创新与发展外，更多也关注到了与用户交互的便利性方面上。当程序员还在为前后数据交互刷新问题困惑时，AJAX 问世了，它以方便快捷的优越性博得了广大程序员的追捧。经过几年的发展，它也渐渐成为我们开发中必不可少的一件利器，下面我就来讲个Struts1 + Ajax的登录示例。\n所用的JS插件： JQuery1.3.2汉化版、JQuery.form2.43\n下面我们先来看看页面中核心的JS代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 function submitForm() { // 用jquery.form插件实现对表单数据系列化 var form = $(\u0026amp;#34;form[name=AdminLoginForm]\u0026amp;#34;); // 配置jquery.form中ajaxForm的参数 // success 操作成功时的回调函数 // resetForm 是否刷新表单 // dataType 接收服务器返回数据的类型, 有script, xml, json等 var options = { success: showResponse, resetForm: false, dataType: \u0026amp;#34;script\u0026amp;#34; }; // ajax发送表单数据到服务器 form.ajaxForm(options); return false; } //回调函数 function showResponse(responseText, statusText) { if (statusText == \u0026amp;#34;success\u0026amp;#34;) { alert(responseText); } else { alert(\u0026amp;#34;由于通讯问题，请稍后再登录！\u0026amp;#34;); } } 在上面的代码中我们可以发现通过JQuery和JQuery.form两款插件，我们只要短短的三行代码就可以实现与后台的数据交互。JQuery是一款功能很强大的JS插件，我个人也很喜欢，调用很方便，代码风格也不错。有空可以研究一下哦，呵呵……\n下面继续来看看struts的action的代码：\n1 2 3 4 5 6 7 8 9 …","date":"2010-09-05T10:11:53+00:00","updated":"2010-09-05T10:11:53+00:00"}]