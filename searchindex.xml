<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>替换SpringBoot里的文件</title><url>https://lisenhui.cn/2021/04/14/replace-files-in-springboot.html</url><categories><category>springboot</category></categories><tags><tag>spring</tag><tag>springboot</tag><tag>java</tag></tags><content type="html"> 现在使用Spring Boot架构的应用开发来说是非常的普遍，统一化的打包部署确实带来不少便利，但当遇到问题时也是会比较棘手。或许你会觉得很惊讶，但如果说这是产品部署运维过程中遇到的难题需要修改Spring Boot应用程序，你就会觉得困难也是不奇怪的。本文就来分享下如何使用jar命令应对线上部署产品时，要临时替换Spring Boot应用中的Jar包的操作。
在测试环境部署某个产品应用时，在最后启动时遇到失败，查看并分析启动日志，发现了如下的堆栈日志信息：
看到此MySQL驱动的类名，当时心中已经有了答案，估计肯定是因为高版本的MySQL驱动程序不兼容低版本的MySQL Server所引起的。接下来使用如下的 jar 命令进一步确认下便是：
$ jar -tvf semxxx.jar | grep mysql mysql-connector-java-8.0.12.jar 当前测试环境使用的 VM 集成镜像，里面很多组件版本相对比较低，但一直使用都没有问题也未曾再升级。
从上面错误的堆栈日志中有看到DruidDataSource字样，猜测此开发使用了Druid数据库连接池，那还是很有希望的，因为Druid数据库连接池有个自动适配数据库驱动程序类的能力特性，但愿开发在写代码时没有使用硬编码的形式。
网上搜索了一些关于 jar 命令如何打包有主运行程序的JAR包后，便着手开始替换MySQL程序的工作。相关步骤如下：
解压产品打包好的spring-boot应用程序 $ jar xf semantic-xxxx.jar -C tmp/ 删除lib目录下的MySQL高版本驱动 $ cd ./tmp/BOOT-INF/lib/ $ rm -rf mysql-connector-java-8.0.16.jar 添加低版本的MySQL驱动包 $ cd ./tmp $ cp ~/mysql-connector-java-5.1.34-bin.jar ./BOOT-INF/lib/ 修改classpath.idx文件中的JAR列表 $ cd ./tmp/BOOT-INF/ $ vim classpath.idx $ # 把那个高版本驱动程序JAR名称修改成低版本的名称即可 重新打包Jar $ cd ./tmp $ jar cfM0 semantic-xxxx.jar . 最后就是重新启动应用程序，“万幸”我们的程序员们没有写硬编码，启动成功，如愿进入到了产品的操作界面，功能使用也一切正常。
参考文章：
jar命令修改 springBoot打包成的jar 直接替换Springboot jar包中的文件 springboot项目jar包发布的，如何线上修改jar包</content></entry><entry><title>加入Istio官方翻译组织的历程记录</title><url>https://lisenhui.cn/2021/03/20/join-istio-translation-org.html</url><categories><category>社区</category></categories><tags><tag>istio</tag><tag>云原生</tag></tags><content type="html"> 作为曾经的程序猿，自己也一直“享受”着来自开源社区的那些无私分享。这些开源项目对自己的影响和启发还是很大的，之前就有想过如何去回馈开源社区，也开贡献过自己的一些项目，参与过一些开源项目，但都还是仅限国内的项目。不久前正好看到 Jimmy Song 在微信朋友圈发布《Istio 官网翻译工作组成立暨志愿者招募》的动态，没有任何的犹豫，下班后便联系 Jimmy 申请加入翻译工作，并在随后的时间完成自己的首次翻译，也成功被合并到了 Istio 官方仓库的主分支当中。如果你也有和我一样的想法，那么欢迎您也来一起加入，期待。
接下来给大家一起分享下，加入Istio官方翻译组织的历程，为后续想加入（或是参与其他开源项目）的小伙伴们做个引路参考，如有不明白之处，可以在文章下的评论区，发表你的建议或意见，谢谢。
翻译的全流程概览如下：
1. 准备工作 俗话说： “磨刀不误砍柴功。” 在正式参与项目合作之前，还是有不少的准备工作需要做的。 当然如果您是资深的开源玩家，那么这些对您来说都是轻车熟路，可以直接跳过本篇文章，参与到实际的项目合作中去。
1.1 科学上网 在技术方面，谷歌可以说是一直都在领导者位置，只是可惜国内情况，并不能让我们愉快的使用这份“珍贵”的资源，所以你得学会如何使用VPN进行访问谷歌站点，因为后续的任务登记在Google docs中。 不过这个能力需要您自给自足，您可以通过网络寻找到很多不错的资源。
1.2 Github账号 作为全球知名的 Git 代码仓库管理与共享平台，相信您早已注册有账号，如没有账号也没有关系，现在您就可以通过 Github 在线注册快速获取，开启您的“新世界”大门。
1.3 Git环境与工具 Git安装还是比较简单的，可直接到官方网站 Git Downloads 下载与您电脑系统对应平台版本安装。同时也可以安装个图形化的客户端，个人一直使用的是Git Extensions工具，它集成Git的命令操作与相关概念，可以帮您提高 Git 使用效率。当然如果您是一名 Geeker，那仍然可以追求命令行的速度，两种方式任君选取。
关于 Git 和 Github 的更多详细使用，初学者可以参考下 Github新手详细教程这篇文章。
1.4 Hugo运行环境 Hugo（基于Go语言）是当下主流的静态站点生成引擎之一，Istio 的官方站点便是基于此引擎构建的，因此您也需要熟悉下对它的基本使用。放心非常的简单（对此 Istio 翻译项目而言，只需了解一个运行命令即可），相信经过此次翻译工作之后，您也会深深“爱”上它的。
首先在 Hugo 官方仓库的发布中，找到并下载与您电脑系统对应平台的版本 Hugo Downloads，然后把下载文件解压到适合的位置，并为之配置系统环境变量，最后终端工具上使用 hugo version 或 hugo env 命令来检测 Hugo 安装是否成功，正常情况下是会输出如下的版本信息：
> hugo version Hugo Static Site Generator v0.80.0-792EF0F4 windows/amd64 BuildDate: 2020-12-31T13:37:57Z 至此，您的 Hugo 环境便已经准备好了，可以在本地运行 Istio 的文档预览效果。当然您也可以稍微多些了解下 hugo server 命令相关的参数，或许某些时刻您会用的上，参考如下：
hugo server # --bind="127.0.0.1" 服务监听IP地址； # -p, --port=1313 服务监听端口； # -w, --watch[=true] 监听站点目录，发现文件变更自动编译； # -D, --buildDrafts 包括被标记为draft的文章； # -E, --buildExpired 包括已过期的文章； # -F, --buildFuture 包括将在未来发布的文章； # -b, --baseURL="localhost" 服务监听域名； # --log[=false]: 开启日志； # --logFile="/var/log/hugo.log": log输出路径； # -t, --theme="" 指定主题； # -v, --verbose[=false]: 输出详细信息 若您是一名程序猿，相信它会改变您对网站开发的模式，毫不夸张的说，结合当下云生态的无服务化编程，静态站点的开发是个全新的世界。
1.5 MD文件编辑工具 Istio 的站点文档均是采用MD格式的文件，所以我们需要一款自己熟悉的MD文档编辑工具。在此推荐使用比较广泛且功能强大的 Sublime Text 文本编辑器，加上 Markdown Editing 插件的加持，让你的MD文档编辑非常的顺滑。
1.6 翻译工具 英文毕竟不是我们的母语，在翻译过程中或多或少还是需要借助下翻译工具的支持，个人使用的网易有道词典桌面版本，在大部分情况下翻译效果还是比较满意的。
2. 加入组织 接下来就是开始“寻找”组织，并加入其中成为一员。
2.1 加入沟通群 已知是有个微信的沟通群，方便大家相互交流翻译过程中的问题。之前此群是可公开加入，但由于广告党的入侵，已经调整策略，只能由管理员来拉人，感兴趣的小伙伴们可以给 rootsongjc@gmail.com 或是 kebe.liu@daocloud.io 两位管理员申请加入。
2.2 登记个人信息 为了让大家相互彼此了解及翻译过程中的合作，需要你在Google Docs（点击加入）上面填写些个人信息，如Github账户名称，邮箱地址，姓名等基础信息。
2.3 克隆Istio仓库 因为当前我们还不是 Istion 的正式 Commiter，所以我们只能通过 Pull Request (简称PR)方式提交我们的修改内容，这就需要先把 Istio 的官方文档仓库克隆到我们自己的仓库列表中。访问 Istio 仓库的地址： https://github.com/istio/istio.io（点击打开），点击右上角的 Fork 按钮，稍等一会便可以在自己的仓库中看到同名的仓库，然后将此仓库克隆到本地电脑中用于后续的翻译编辑。
3. 翻译流程 上述准备工作都已经完成好后，便可以开始我们的 Istio 翻译之旅啦。
3.1 登记任务 如同上面登记个人信息一样，正式开始翻译前，需要在文档中登记下您要认领的任务。（多人协作的协同方式，不然大家都窜到一块去就不好啦）任务文档中标记了各个任务的优先级别，可按照这个次序由高到低开始认领，记得要登记认领人和状态等信息。
3.2 翻译工作 开始翻译之前，建议先快速浏览下所认领的任务，看是否有合适归并在一起的类型。一般情况之下，是建议每翻译一篇文章都独立创建个分支开展，但如果调整内容比较少的话，可以考虑归并到一起，减轻Reviewer的工作量。
另外建议每次翻译前，先对比下 Istio 官方仓库，并进行同步更新到本地，操作流程请参考下面 《4.1 如何同步官方仓库更新》 的章节。
接下再给大家分享下，在翻译中使用小技巧：
设置好编辑器的换行显示，避免编辑时要左右拖动滚动条； 开启左右两个窗口模式，可以使用Windows自带分屏功能或是编辑器的窗口功能，推荐使用后者切换时比较方便； 使用 Crtl+P 快捷键打开 Sublime Text 的搜索功能，拷贝领取任务中的文章路径，分别打开 en 和 zh 目录下对应的文件，如下图所示： 翻译工作确实会比较枯燥一些，要逐行逐句进行理解和提炼，非常考验您的耐心，哈
在完成翻译工作后，建议启用本地的 Hugo 服务预览验证下，确保排版，图片，标点符号等显示都没有问题。
3.3 PR提交与评审 完成翻译和自我检查工作后，便可以使用 Git 命令或工具提交您的贡献，记得不仅要提交在本地，还要推送到 Github 远程仓库上呢。
推送成功后切换到您 Github 下的 Istio 仓库主页，就可以在代码上方看到一个明显的 PR 提示，点击绿色按钮就可以快速创建并提交给 Istio 官方，静静等待其他人的评审。
3.4 更新任务状态 记得提交完 PR 后及时在登记的任务栏中添加 PR 记录，并更新状态，同时也要留意自己的邮箱或是查看 Github 上的消息通知（如下图所示），关注最新的变化。可能在其他评审后需要您进行修改（按评审建议调整对应内容，重新提交即可），如没有问题一般都是直接被合并的。
至此，整个翻译的流程便已经完整走通，在等待 PR 的日子里
4. 常见问题 4.1 如何同步官方仓库更新 翻译工作一般都是比较被动的，加上大家工作的时间差异，可以在翻译前参考如下步骤同步当前官方最新文档状态：
在自己的仓库中，创建个新的PR请求，如下图所示： 参考下面的图片数字顺序，调整对应仓库名称与分支（左边是自己的仓库，右边是官方的仓库），点击右边的绿色按钮，填写相关的评审信息（主要是自己能理解的就好，没有标准） 然后会自动跳转到那个PR，在下方找到 Merge pull request 按钮点击并确认即可； 使用 git pull 命令或是 Git Extensions 工具拉取最新文件到本地； 4.2 本地运行时缺失JS和CCS文件 Istio 的静态资源采用了sass方式进行开发，所以本地运行时可能无法编译这些文件，导致您在本地预览时无法正常显示（比较错乱），可以找群里的其他小伙伴分享一下（或是点击下载 istio.io-generated-files.tgz），然后把 css, js, img 里的资源放到本地的 static 对应目录下面，重新启动 Hugo 服务后就可以正常的显示。
注意： 提交翻译文件时，不要把这些资源文件提并上去，需要把它们过滤下。 在 Windows 平台下有个操作小技巧，不要关闭 static 的文件窗口，然后提交前直接按 Ctrl+Z 组合键就可以快速撤销。
4.3 提交PR进遇到 google-cla 检查失败 在 Istio 的自动化检查过程中，有个环节是需要谷歌的 CLA 支持的，首次提交 PR 时可能会遇到如下的问题，那么只要去 comment 里的那个链接地址注册一下就好，但要注意名称与要您的 Github 账号名称保证一致，不然无法通过检验。
4.2 如何查找过时移除文档记录 翻译过程中，您可能会遇到一些文档因过时而被移除的情况，那么这时您不是只简单的同步删除过时文档，建议还是要在 commit 信息中把对应的删除 PR 找出来。 这里可以借助 git log 命令帮您定位，参考如下：
# see the changes of a file, works even # if the file was deleted git log -- [file_path] # limit the output of Git log to the # last commit, i.e. the commit which delete the file # -1 to see only the last commit # use 2 to see the last 2 commits etc git log -1 -- [file_path] # include stat parameter to see # some statics, e.g., how many files were # deleted git log -1 --stat -- [file_path] # see the change content detail git show commit_id 复制找到的 commit_id 信息，切换到 Istio 官方的 PR 记录中，通过搜索可以快速定位到是哪个 PR 提交的，然后把 PR 链接和描述信息一并附上，这样 Reviewer 就可以清楚的知道缘由，快速帮忙你评审。
5. 总结 在参与 Istio 的翻译过程中，还算是比较顺利的，不仅让自己学习到了不少 Hugo 的建站用法，而且也提升了个人的翻译能力。
最后希望本文能对您有所帮忙，也期待您能一起加入进来，大家共同努力争取早日完成这份 “大业” 。</content></entry><entry><title>使用Github Action自动同步仓库到Gitee</title><url>https://lisenhui.cn/2021/02/25/add-sync-gitee-action.html</url><categories><category>github</category></categories><tags><tag>git</tag><tag>github</tag></tags><content type="html"> 1.背景 作为程序员出生的你，肯定知道备份的重要性。再说现在大环境背景下，美国的政治关系还是比较混乱的，而对于存放在Github上面的项目，也不再是技术自由的国度啦。所以说我们的代码还是有必要进行“双”备份的，接下来就是介绍下，如何使用Github上面的Action功能，将Github上面的代码同步备份到国内的Gitee仓库站点。
2.准备工作 在一次无意间浏览到了yanglbme的贡献的一个Git Page Action代码，经过简单的尝试验证，感觉还是挺好用的，便在自己的博客项目中加入相应的Github Action。大部分的步骤在上面那个站点都有介绍，在此就大概小结一下要注意的点。
2.1 准备SSH密钥 在你的本地使用ssh-keygen命令生成用密钥时，千万不要使用密码，在执行ssh-keygen -t rsa -C "youremail@example.com"命令时，直接不断敲下回车键即可。
2.2 Gitee相关 建议Github和Gitee使用同一个密钥，他们的设置方法如下：
1.Github: Settings -> SSH and GPG keys
2.Gitee: 安全设置 -> SSH 公钥
另外还有一个重点就是，一定要关注Gitee的公众号： giteecom，不然后面Github workflow执行就会失败的。
2.3 Github加密设置 切换到Github，然后在当前项目下「​Settings -> Secrets」中进行添加[Repository secrets]，分别为:
GITEE_PASSWORD: Gitee登录的密码 GITEE_RSA_PRIVATE_KEY: 前面生成的SSH密钥的私钥
2.4 Git workflow准备 在你的Github的仓库中，添加个.github/workflows/目录结构，创建个名称为sync-2-gitee.yml文件，填充如下的文件内容：
name:Syncon:push:branches:[main, hugo]jobs:sync-2-gitee:runs-on:ubuntu-lateststeps:- name:Sync to Giteeuses:wearerequired/git-mirror-action@masterenv:# 注意在 Settings->Secrets 配置 GITEE_RSA_PRIVATE_KEYSSH_PRIVATE_KEY:${{ secrets.GITEE_RSA_PRIVATE_KEY }}with:# 注意替换为你的 GitHub 源仓库地址source-repo:git@github.com:doocs/advanced-java.git# 注意替换为你的 Gitee 目标仓库地址destination-repo:git@gitee.com:Doocs/advanced-java.gitreload-pages:needs:sync-2-giteeruns-on:ubuntu-lateststeps:- name:Build Gitee Pagesuses:yanglbme/gitee-pages-action@mainwith:# 注意替换为你的 Gitee 用户名gitee-username:yanglbme# 注意在 Settings->Secrets 配置 GITEE_PASSWORDgitee-password:${{ secrets.GITEE_PASSWORD }}# 注意替换为你的 Gitee 仓库，仓库名严格区分大小写，请准确填写，否则会出错gitee-repo:doocs/advanced-java# 要部署的分支，默认是 master，若是其他分支，则需要指定（指定的分支必须存在）branch:main 注： 这里对原版本做了个小修改，分成2个job，体现一个workflow的效果。
2.4 运行效果 那后续在给Github仓库推送代码时，便会有自动同步代码到Gitee仓库，同时也会重新reload静态页面服务，省去手动干预的流程。
3.小结 整个方案执行起来还是比较简单的，唯一个可能存在的风险，便是那个密码流程的流程。不过本只是个CI过程，日志中也有脱敏操作，这样也就安全多啦，而且像个人的账户也不会受到特别的关注。
这是首次体验到Github Action的魅力，后续可以持续关注下，这个功能对于一些开源小项目的自动化测试还是有很大的帮助。
##　４.参考
1.gitee-pages-action 2.getting-started-with-github-actions 3.使用Github Actions实现代码推送Github自动同步到Gitee镜像仓库！ 4.基于GITHUB ACTION的定时任务，真香！</content></entry><entry><title>GitExtensions推送Github失败记录</title><url>https://lisenhui.cn/2021/02/22/git-extensions-push-fail.html</url><categories><category>工具</category></categories><tags><tag>Git</tag><tag>工具</tag></tags><content type="html"> 问题现身 555~，今天体验了一把安装最新程序的“快感”！！！
在使用Git Extensisons推送最新写的文章到Github时，遇到了个SSH KEY认证无效的莫名错误。事情的发生是这样的：今天在首次打开Git Extensions软件时，它非常友好的弹出更新提示窗口，然后就手不自觉的点击了下确认按钮。结果更新好后，在推送文章到Github时就发生了如下面一样神奇的错误阻拦：
FATAL ERROR: No supported authentication methods available (server sent: publickey) fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 看到这个错误真是一脸的发楞呀，没有修改过任何SSH KEY相关的配置，咋就没有相应的权限进行操作了呢？
开始脑子里想到的是，难道是本地的SSH KEY被清理了？但检查了文件后发现一切正常，而且使用git push命令操作也是正常的。真是百思不得其解，暂时只能参考报错的提示出来尝试操作修复。
初步解决办法 根据报错窗口的提示，使用Putty工具把本地的SSH KEY生成Private模式，操作如下：
然后把这个Private KEY加载到推送的流程中，再次点击推送按钮就会看到操作成功提示信息。
问题定位 虽然解决完这个推送的问题，但还觉得事情有点奇怪和蹊跷。于是想到了Git Extensions的配置是否有变化，经过一番查找测试后，确认是由于官方当前默认在Windows使用Putty作为客户端，把它调整为OpenSSH方式，问题便不再出现。
总结 在非必要的情况下，还是不太建议升级软件版本，稳定的环境比用不到的新功能更具价值。</content></entry><entry><title>Github个人信息卡片</title><url>https://lisenhui.cn/2021/01/24/github-personal-profile-card.html</url><categories><category>github</category></categories><tags><tag>github</tag></tags><content type="html"> Github上总是会有一些新奇的东西出现，这不无意间又发现了个有趣的玩法，可以用它来作为你的个人开发者名信片展现。具体展现效果如下：
操作起来也不繁琐，类似以前的pages服务那样，只准备个特定的仓库就可以，具体操作如下：
1. 申请公开仓库 在Github上面申请个与你用户名同名的公开仓库，然后你就会发现收到来自Github的“赞美”提示信息，如下：
仓库创建好后，会默认准备好一个README.md文件，后续你在这上面写相关的信息即可。
２. 个人介绍信息 接下来就是你在README.md上面添加个人信息，写法上支持标准的markdown语法编辑，同时也是支持各种表情图标，可以按你个人的意愿添加任意内容。顺便提下，可以使用Github API展现你自己仓库相关的代码提交，质量，打分等信息，效果见开篇的介绍。
3. 示例 自己简单的编写下，仅供各位看观参考，哈。
&lt;img align="right" src="https://github-readme-stats.vercel.app/api?username=elkan1788&amp;show_icons=true&amp;icon_color=CE1D2D&amp;text_color=718096&amp;bg_color=ffffff&amp;hide_title=true" /> ### Hello, World! :tada::tada::tada: - :building_construction: Working at @Kyligence - :house_with_garden: Living at Shanghai - :orange_book: [《Apache Kylin权威指南（第2版）》](https://item.m.jd.com/product/12566389.html) - :monocle_face: Try to find it out. 喜欢的话，那就赶紧行动起来吧。</content></entry><entry><title>优化Hugo Next主题的过程</title><url>https://lisenhui.cn/2020/10/02/make-next-theme-pithy.html</url><categories><category>博客</category></categories><tags><tag>NexT</tag><tag>博客</tag></tags><content type="html"> 1. 背景 经过一番考虑还是把个人博客从Hexo引擎迁移到Hugo引擎，博客主题依旧还是沿用NexT。其实本来还担心又要折腾弄个全新的博客主题，后来Github上看到兰陵子分享的NexT主题，就直接拿过来引用。但在部署后发现还是有些地方需要改善，在此记录下改造优化的过程。如果正好你也喜欢这个主题，那么欢迎拿去使用，也欢迎交流反馈。
2. 评论功能 评论功能是博客空间一项较为重要的功能，作为博主与读者交流的重要桥梁，那自然是不可或缺。之前一直使用的是LiveRe，最近发现访问不太稳定，另外还不支持游客评论模式，于是乎考虑使用Valine来做评论支持，不过最后还是把两个都实现了。
2.1 LiveRe LiveRe(来必力)是韩国最大第三方社交评论系统，自打多说评论下线后一直都是使用它做博客的评论框。个人开发者可以到官网网站注册个City免费版本即可，它的集成也是很简单，直接在博客的JavaScript页面中加载如下的代码：
{{ if and (.IsPage) (isset .Site.Params "comment") (eq .Site.Params.Comment "LiveRe") }} &lt;script type="text/javascript"> (function(d, s) { var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === 'function') { return; } j = d.createElement(s); j.src = '//cdn-city.livere.com/js/embed.dist.js'; j.async = true; e.parentNode.insertBefore(j, e); })(document, 'script'); &lt;/script> {{ end }} 然后在想出现评论框的位置，定义个Div元素，参考如下：
{{ if and (isset .Site.Params "comment") (eq .Site.Params.Comment "LiveRe") }} &lt;div id="lv-container" data-id="city" data-uid="{{ .Site.Params.LiveReId }}"> {{ end }} 最后的效果如下：
2.2 Valine Valine,是一款基于LeanCloud的快速、简洁且高效的无后端评论系统。官方的文档非常详细，这里就不再赘述，最后实现的效果如下：
需要注意一下，由于Valine里面集成了LeanCloud的SDK引用，所以自己再使用LearnCloud功能就不需要再引用相关的SDK，不然后就会发生冲突。
3. 访问统计 作为博客站长，肯定是会比较关注自己空间的访问状况和相关的数据，比如PU和UV流量，可以借助一些现有平台帮助我们收集。
3.1 博客空间访问统计 像CNZZ，百度，谷歌(可能被墙)，GrowingIO等（你也可以集成自己熟悉的平台）都可以实现对博客空间访问的统计与相关数据收集，另外这些平台的埋点脚本也是支持一起集成使用。 此次主要是集成了CNZZ, 百度和谷歌，但是这些平台的数据只有站长才有权限查看，所以另外引入不蒜子计数器，把网站PU和UV数据公开展示，效果如下：
3.2 文章访问统计 除了空间访问数据以外，文章的热度也可以进行统计，之前NexT上也是使用LearnCloud作为后台计数的，此次可借助上面Valine评论插件自带的文章计数器功能。 但同时考虑到要是引用LiveRe评论插件的可能，于是移植原有Hexo上面的相关代码，并更新最新LearnCloud SDK代码，最终实现不管是在引用哪个评论插件，均可以实现文章热度的统计。
增加此项统计功能时，把原有文章相关的ICON图标进行修复。
4. SEO优化 为了博客空间能够引流更好，不仅需要写出更多的原创作品，而且也需要一定的站点SEO优化支持。
4.1 sitemap.xml生成 sitemap文件生成有利于站点收录平台，Hugo生成sitemap文件时要注意一下文件头部的生成，整体代码如下：
{{ printf "&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"yes\" ?>" | safeHTML }} &lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"> {{ range .Data.Pages }} &lt;url> &lt;loc>{{ .Permalink }}&lt;/loc> &lt;lastmod>{{ safeHTML ( .Date.Format "2006-01-02T15:04:05-07:00" ) }}&lt;/lastmod> {{ with .Sitemap.ChangeFreq }} &lt;changefreq>{{ . }}&lt;/changefreq> {{ end }} {{ if ge .Sitemap.Priority 0.0 }} &lt;priority>{{ .Sitemap.Priority }}&lt;/priority> {{ end }} &lt;/url> {{ end }} &lt;/urlset> 最后把这个文件路径提交到对应的收录平台即可，比如下面的：
百度: 收录入口 谷歌: 收录入口 4.2 bshare分享 另外通过站点自带的分享功能，可以快速将文章分享给不同的读者或者是其他平台。此次采用的是BShare插件，可以快速生成不同平台的分享链接，读者只需要一键点击便可快速分享，效果如下：
目前关于BShare的HTTPS引用问题已通过Meta标签解决，但其内部有好几个引用是无效的，会在控制台输出一些报错信息，但不会影响整个页面的渲染。此问题已经提交BShare反馈，期待后续有升级修复。
5. 自我介绍 原有的NexT主题里并没有带自我介绍的页面，参考原来Hexo主题里面的个人介绍页面，增加一些shortcode的代码，实现一个有别于文章的个人信息介绍页面，效果如下：
6. 本地搜索 本地搜索可通过文章标题或内容关键字快速检索出相关的内容，原理也比较简单，就是把文章标题和内容先抽取到一个XML文本中记录，然后通过JavaScript脚本读取解析。原来主题中的实现是通过sitemap.xml来解析，但这样会与真正的sitemap.xml文件产品冲突，后来改用robots.txt文件进行存储，同时修正相正相关的弹出框等相关样式和图标，最终效果呈现如下：
7. 公益404 引入腾讯的404公益页面，虽然本站点没有什么流量，但也希望通过这种方式让更多的失散儿童能够早日回家。
8. 在线聊天 评论功能可以实现与读者的交流，只不过实时不是很强，那么在线交流正好是不错的方式。 DaoVoice是款不错的在线聊天产品，同时也供了免费使用版本机会，集成也是相当的简单, 只要在Script引用地方加入如下的代码即可：
daovoice('init', { app_id: "xxxxx" }); daovoice('update'); &lt;script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:':'http:') + "//widget.daovoice.io/widget/xxxxx.js","daovoice")&lt;/script> 最后实现的效果如下：
9. 图片浏览功能 通过在文章里面直接引用的图片都会是被压缩，或是缩小，无法查看原图的清晰明了。之前NextT自带的图片浏览插件并不好用，所以替换成了ImageViewer来实现对文章内的图片浏览，会有类似幻灯片的效果，如下：
10. 其它优化 考虑到HTTPS流量计费原因，所以把所有页面中无关的因素全都进行剔除，把各种JavaScript类库和CSS样式用CDN链接进行替换，同时开启压缩模式让网页体积更小。
另外还增加了标签云、3D访问显示，打赏功能，修复显示问题等小细节的处理，让整个博客站点功能看起来更加完整。
最后整站的效果就如你现在看的那样，依然保持了NexT主题清爽的界面风格。</content></entry><entry><title>安装CDH6过程中几个入坑记录</title><url>https://lisenhui.cn/2020/09/28/install-cdh-issues-notes.html</url><categories><category>大数据</category></categories><tags><tag>大数据</tag><tag>CDH</tag></tags><content type="html"> 其实CDH环境部署安装并非是什么难事，正所谓是熟能生巧嘛。但正好不巧的就是太久没有操作过，便是会遇到一些“奇奇怪怪”的问题，而后花费些功夫才能解决好，事后也就顺道把它们记录下来，避免以后再犯。
1. CDH的元数据库初始化脚本 想必安装过CDH环境的人员都知道，在CM安装完成后，有个脚本名称为：scm_prepare_database.sh，按官方说法是用于初始化CDH元数据库的，所以大家肯定是都会按步就搬的执行。但不知道大家有没试过想它背后是否真的有产生过什么工作？换句话说就是不执行此脚本会有什么问题？
在过往安装CDH环境的经验中，一般都是会把CM和MySQL数据库安装在同一台机器上（非生产环境）。但这次恰好是在云上环境搭建，所以MySQL直接使用的是云上服务，结果在安装好CM，执行好scm_prepare_database.sh脚本后，启动CM并没有出现预期的成功消息。查看启动日志发现如下错误：
提示scm.cm_version表不存在，难道是之前执行scm_prepare_database.sh脚本有问题？于是乎又重新执行一次该脚本，确定输出结果是成功的，但CM启动仍然是失败的。当时就真是纳闷了，这个CM的元数据库是在哪一步初始化的呢？
经过一番尝试和验证后，确认scm_prepare_database.sh脚本并不会初始化CM的元数据库，只是生成db.properties文件，同时会创建一个指定名称的数据库，而真正初始化的操作是在CM首次启动时执行的。
结论： 安装完成CM并不一定需要执行scm_prepare_database.sh脚本，可以手动创建数据库及配置db.properties文件。
2. MySQL5.7+版本问题 前面第1步中遇到的问题，其实在后来分析日志时发现，根本原因是CM在执行数据库初始化时，有些DDL语法不支持导致初始化工作并未完成。部分错误日志如下：
但是CM的提示信息并不友好，并未告知CM元数据库初始化是否完成，导致定位问题有点难度挑战，后来是手动调整DDL语法才得以完成初始化工作。
这里总结出一个经验，就是正常情况下CM元数据库会生成54张表，可以以此为判断CM初始化工作是否完成。
另外就是MySQL GTID的问题，导致建表一直失败：
错误代码： 1786 Statement violates GTID consistency: CREATE TABLE ... SELECT. 参考：MYSQL Statement violates GTID consistency: CREATE TABLE &hellip; SELECT. 错误代码： 1786 问题
说是要关闭2个参数配置，但是由于使用的云上数据库组件，并未支持系统配置参数修改。最后只好是在本地搭建个MySQL服务，待CM初始化工作完成好，再把表结构和数据同步到云上数据库，问题得以解决。
3. Hosts配置文件失误 安装Yarn服务组件时一直报出上传Mapreduce的JAR包失败，查看日志信息提示说是无法创建HDFS目录，告知是没有权限执行。于是乎就去临时调整目录权限，但失望的是安装仍然是失败的，还是报出相同的错误。
再重新分析日志时发觉，貌似是HostName书写有问题，于是对比了下Hosts文件和机器的HostName，结果还真是不一样的。由于当时准备Hadoop节点机器时，使用的是云上同步创建功能，会自动在HostName后面添加对应的序号，只是没想到这个序号会是4位数字，但在Hosts文件里填写时只写了3位。 真可谓是：“差之毫厘，谬以千里”。重新调整Hosts文件配置后，所有安装与启动便成功。
未完待更新&hellip;</content></entry><entry><title>停止使用原中文域名公告</title><url>https://lisenhui.cn/2020/09/17/stop-use-chinese-domain-notice.html</url><categories><category>博客</category></categories><tags><tag>博客</tag></tags><content type="html"> 从今天起正式启用lisenhui.cn作为本博客空间唯一域名。
早上的时候收到了域名服务商的通知短信，提示域名需要续费。才发现不知不觉中，原来工作后注册的第一个域名，已经陪伴自己走过了7个年头啦。当时也就是觉得中文域名比较特别，然后就自己的名字注册了李森辉.cn的域名。
不过现在还是决定弃用这个中文域名，因为考虑到中文域名其实也还不成熟，在这些年使用的过程就总是遇到各种问题，虽然后来都找到办法绕过去解决，但是终究不太方便。
因此带来的影响，只能说是后续再慢慢修正吧。（不过本站的流量也是一般啦）</content></entry><entry><title>博客引擎迁移至Hugo计划</title><url>https://lisenhui.cn/2020/08/15/blog-move-2-hugo-plan.html</url><categories><category>博客</category></categories><tags><tag>博客</tag><tag>Hugo</tag></tags><content type="html"> 近期发现自己的个人博客空间突然之间不能访问，一番查证后发现原来是之前使用的page服务商已经停止提供服务。无奈只好重新迁移回到Github Pages。但这就是又得到重新准备Hexo的相关开发环境，还得辛苦的调试才能成功。而恰好这时在网上有看到过Hugo静态站点引擎的文章，一款基于Go语言开发的极速框架，开发环境部署也简便快速。另外近期原有的域名也快到期了，正好就一起把博客空间整理整理吧。
访问Hugo官方网站，翻看了下官方的文档，确实是使用比较容易简单。但发浏览已有主题时，并没有找到自己博客空间现正在用的NexT主题，那是不是意味着又得重新来倒腾一回！
不过还好最后在Github找到有人已经移植了Hexo NexT主题： hugo-theme-next，所以后续的迁移计划便是基于此展开，整体的思路和计划如下：
考虑到都是使用业余时间来完成，所以时间线拉的比较长一些，也不知道当中遇到的问题能否顺利解决。先不管这么多啦，凡事都是得先有个Flag嘛，后续努力的把Flag实现就好啦。</content></entry><entry><title>在Linux上安装中文字体</title><url>https://lisenhui.cn/2019/10/21/install-linux-chinese-fonts.html</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 背景 平时一般都很少在Linux服务机器上使用UI桌面，但也还是有机会遇到，这不今天便遇到Linux版本的火狐浏览器显示中文乱码。无论怎么调试浏览器的相关设置，都没有办法凑效，甚是有点郁闷。
安装字体 在前面调试浏览器设置，在字体设置那栏就发现没有适合中文显示的字体库，那就是意味着安装个字体就可以解决问题啦。从Windows系统中找了个微软雅黑字体库（msyh.ttc,msyhl.ttc,msyhbd.ttc），并上传到Linux服务器的指定目录下： /usr/share/fonts
注：可以在此目录下创建个文件夹存放微软雅黑的3个字体库文件，方便管理
然后再通过yum命令安装字体管理工具，如下：
yum install -y fontconfig mkfontscale 最后验证一下字体安装是否成功，命令如下：
[root@quickstart fonts]# fc-list :lang=zh Microsoft YaHei,微软雅黑:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei UI,Microsoft YaHei UI Light:style=Light,Regular Microsoft YaHei UI:style=Regular,Normal,oby?ejné,Standard,Κανονικ?,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta Microsoft YaHei,微软雅黑,Microsoft YaHei Light,微软雅黑 Light:style=Light,Regular Microsoft YaHei UI:style=Bold,Negreta,tu?né,fed,Fett,?ντονα,Negrita,Lihavoitu,Gras,Félk?vér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kal?n,Krepko,Lodia Microsoft YaHei,微软雅黑:style=Bold,Negreta,tu?né,fed,Fett,?ντονα,Negrita,Lihavoitu,Gras,Félk?vér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kal?n,Krepko,Lodia 如能显示出来微软雅黑字样，那就表示显示成功，再到火狐浏览器的高级设置中把字体选项调整为微软雅黑即可，效果如下：
总结 遇到乱码问题，除了查找lang设置之外，还需要关心一下字体库。
换个位置思考！！！</content></entry><entry><title>不能在HDFS Data节点上创建临时文件</title><url>https://lisenhui.cn/2019/03/21/unable-create-tmp-file-in-hdfs-nodes.html</url><categories><category>大数据</category></categories><tags><tag>Hive</tag><tag>大数据</tag></tags><content type="html"> 在新创建的Hadoop边缘节点上，尝试通过Hive CLI模式进行数据插入操作，结果没有出现意想中的成功信息，反倒是捕获到如下的异常：
FAILED: SemanticException [Error 10293]: Unable to create temp file for insert values File /tmp/hive/kylin/9c84de0a-fca2-4d3c-8f72-47436a4adb83/_tmp_space.db/Values__Tmp__Table__1/data_file could only be replicated to 0 nodes instead of minReplication (=1). There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1720) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3440) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:686) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:217) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:506) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2226) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2222) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2220) ERROR: Current user has no permission to create Hive table in working directory: /user/kylin 从异常提示信息上来面，初步判定为对/user/kylin目录没有权限（有点奇怪明明就是kylin用户为何会没有权限操作），简单直接的把其权限降低到777后，错误仍然是存在。接着尝试切换到Hive的Beeline连接方式，重复上原来的插入语句，操作成功了！那上面的错误是何原因引起的呢？
借助强大的Google搜索查找了一番，结果各说纷纭：有说是HDFS存储空间不足，有的说是集群节点的防火墙未关闭，有的说是DataNode服务异常 等等。网上的方案都尝试过了，问题仍然是没有解决。由前的防火墙联想到会不会是IP引起的问题 。
因为集群是本地虚拟机搭建的，而恰巧又配置了双网卡，而边缘节点连接的是集静态IP地址。如下：
eth0 Link encap:Ethernet HWaddr 08:00:27:B2:38:58 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:797 errors:0 dropped:0 overruns:0 frame:0 TX packets:944 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:98791 (96.4 KiB) TX bytes:84770 (82.7 KiB) eth1 Link encap:Ethernet HWaddr 08:00:27:B5:9D:6A inet addr:192.168.56.104 Bcast:192.168.56.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:3523935 errors:0 dropped:0 overruns:0 frame:0 TX packets:443589 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:5073146719 (4.7 GiB) TX bytes:163351146 (155.7 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:342031 errors:0 dropped:0 overruns:0 frame:0 TX packets:342031 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:405110832 (386.3 MiB) TX bytes:405110832 (386.3 MiB) 接着检查了下/etc/hosts的文件配置，结果真是默认设置10.0.2.15地址为集群IP，将其修改为静态IP地址并重启Hadoop集群的所有服务，再次通过Hive CLI模式连接Hive，执行之前的插入语句一切正常。
总结 配置Hadoop集群要特别注意IP地址的分配，建议还是通过HostName形式来避免IP地址问题。另外当已有案例不能协助解决问题时，可仔细检查环境的配置情况。</content></entry><entry><title>关于我</title><url>https://lisenhui.cn/about.html</url><categories/><tags/><content type="html"> 希望是无所谓有，无所谓无的，这正如地上的路。
其实地上本没有路，走的人多了，也便成了路。
鲁迅
绰号
凡梦星尘(elkan1788)
留言箱： elkan1788@gmail.com
历史正文
CSDN Blog ITEye Blog1 ITEye Blog2 GitHub Page 啰嗦几句
奔波于大都市中求生的一枚攻城狮/码农，完美是对代码的基本要求。 (曾经)
文静的外表下藏有颗"叛逆&ldquo;的心，不怕世俗之见敢于突破束缚，喜欢去追求真正的自由路。
心中怀揣着的梦想，希望有一天能够把它实现。
感谢支持！</content></entry><entry><title>Win10常用的快捷操作方式</title><url>https://lisenhui.cn/2018/08/08/win10-quick-operations.html</url><categories><category>Windows</category></categories><tags><tag>Windows</tag><tag>技巧</tag></tags><content type="html"> 常言道“工欲善其事，必先利其器。”
不过从Mac再过渡回来到Windows确实是有诸多的不习惯，但仍是要学会克服，无它，工作是生存的根本技能。于是从网络上扒了下关于Win10快捷键的分布，还是挺有趣的。记录也下部分常用快捷键，如下：
操作手势 1.双指单击触摸板，模拟鼠标右键，即弹出菜单
2.三指单击触摸板，弹出搜索框
3.四指单击触摸板，弹出操作中心，即模拟Win+A
4.三指同时上划，弹出多任务界面，即模拟Win+Tab
5.三指同时下划，将所有窗口最小化，即模拟显示桌面
6.三指同时向左/右划，快速切换任务，即模拟Alt+Tab
7.双指同时向左/右划，切换上一个/下一个项目，用于浏览图片或“开始”等横向排版程序的滚动
快捷键 1.创建新的虚拟桌面：Win + Ctrl + D
2.关闭当前虚拟桌面：Win + Ctrl + F4
4.多桌面切换：Win + Ctrl + 左/右
5.快速打开搜索：Win + Q
6.快速打开Win10设置栏: Win + I
7.临时查看桌面： Win+，
8.最小化所有窗口：Win+M
9.打开位于任务栏指定位置程序的新实例：Win+Shift+数字键
10.最大化窗口(传统桌面)：Win + 向上键
11.最小化窗口(传统桌面)：Win + 向下键
12.将窗口最大化到屏幕的左侧(传统桌面)：·Win + 向左键
13.将窗口最大化到屏幕的右侧(传统桌面)：Win + 向右键
14.前进：Alt + 向右键
15.后退：Alt + 向左键
16.截图（保存到内存）：Win + Shift + S
以上快捷操作都是亲自验证后可用，仅供参考，后续的有新发现会持续更新，欢迎关注，谢谢。</content></entry><entry><title>Axure教程：动态面板内容超出界线显示</title><url>https://lisenhui.cn/2018/03/12/axure-lightbox-shade.html</url><categories><category>产品</category></categories><tags><tag>Axure</tag><tag>产品</tag></tags><content type="html"> 问题 随着用户需求的不断更新，产品原型的设计也在不断迭代升级，那么是必会让整体的设计复杂增加，各中组件相互影响的因素就更多。这不现在就遇到在动态面板上显示一个隐藏的元件时，结果下拉的组件显示不完全了，真的好是郁闷，如下图所示：
从问题的表象可以分析出主要的关键点如下：
隐藏的元件图层位置，并不是最顶层，导致显示位置不对 动态面板的大小，限制了隐藏元件显示的区域 解决方案 尝试过多次解决方案后，找到了个最优的办法，只要2个步骤即可，具体操作如下：
顶层设置 定位到显示隐藏元件的点击事件，在显示的时候同时将其至为顶层，如下图所示：
面板自适应 定位到隐藏元件所在的面板，在面板的属性上，将自动调整为内容尺寸打勾，如下图所示：
效果预览 操作完以上2步后，即可查看到如下的效果：
OK，至此已经实现我们想要解决的问题，遇过问题可以多点点Axure的各种设置，会有预想不到的效果，哈~。</content></entry><entry><title>Axure教程：实现表格数据展示</title><url>https://lisenhui.cn/2017/12/29/axure-datalist-table.html</url><categories><category>Axure</category></categories><tags><tag>产品</tag><tag>Axure</tag></tags><content type="html"> 通常在系统管理后台中，使用列表（表格）形式展示数据是最为常见的方式。而在使用Axure设计产品原型时想实现这个数据列表却不太容易，或许常见的做法就是使用矩形拼凑起来，还有就是直接使用表格控件来布局。但是这都不太方便，首先就是布局麻烦，其次就是数据修改比较麻烦。接下来给大家介绍下如何使用表格+中继器控件实现数据列表。
其实在实际的原型设计过程中，都会在表格+中继器的基础上增加个矩形框一起使用。这也是迫于无奈，在Axure上面表格无法实现单元格的合并。因此通常表格只能把表格做为数据列表中的表头，然后再利用中继器的数据填充功能来展示数据部分。当遇到一些需要合并的单元格时，矩形框便发挥了它的强大作用。下面就着重来讲下中继器如何来显示数据：
创建中继器，双击进入中继器删除里面的初始内容
创建与表格相同列数的矩形框，高度可自定义，宽度保持与表格对应列相同，给每个元件起个名字（配备自己喜欢的风格，后续数据就会复制当前的样式）
选择中继器，在属性(Properties)中找到Repeater，创建与表格列数相同的列并起名（建议保持与上一步的名称相同），最后填充示例数据 注：可以直接在Excel中编辑数据，然后直接拷贝到中继器里面
选择中继器，添加个Case用于绑定数据与矩形框的关系 设置隔行换色效果，选择中继器，在Style中找到Item Background勾选Alternating然后配对奇偶行的前景色 注：如果在中继器里面使用矩形框，一定要把其背景色设置为无，不然隔行换色就不起效果，这个教训惨痛的。
这些便是关于在Axure中实现表格数据实现，如遇到一些复杂的要求，可以以此为参考，自由的发挥想象。
整体的效果如下：
PS:
示例源文件下载：数据表格.rp</content></entry><entry><title>Axure教程：实现动态的遮罩层</title><url>https://lisenhui.cn/2017/12/15/axure-lightbox-shade.html</url><categories><category>Axure</category></categories><tags><tag>产品</tag><tag>Axure</tag></tags><content type="html"> 今天在做产品原型设计时，遇到了个关于动态显现遮罩层的难点。&ldquo;无奈"为追求高保真的效果，还是花了点心思做个原型实现。待做好回过头来看看的话，其实这个效果的难度也不大，只是看个人意愿是否想做而已。Axure本身就提供了模板的功能，也就是说只要实现一次但可以一劳永逸。下面就一起来看看这个遮罩层实现过程和效果吧。
做前端开发的同学都知道，在HTML实现一个遮罩层，只需要添加个浮动的DIV即可轻松实现。那么在Axure中如何去实现它呢？
如上图所示，可以将这个遮罩层的实现分为如下2部分：
主体内容，即遮罩层要盖住的部分 遮罩层组件，即遮罩层+其它装饰部分（在Demo中只是增加了个Loading的动画图片来区分） 所以遮罩层的实现思路就清晰啦步骤如下：
准备一个与你所想要遮盖内容大小相同的矩形框，注意要减去边框的大小，示例：主体内容大小为600x400，边框宽度为1px，那么遮罩层的大小为598*398且是无边框的
设置遮罩层的填充色，还有相对的透明度
加强遮罩层显示的动画效果（Axure上所支持的效果并不多，如不能够满足，可以采用文字描述阐明效果要求）
接着用3个按钮来做不同效果的展示：
打开遮罩层 关闭遮罩层 自动演示 那么现在来看看最终的实现效果如下，请看下面的大屏幕在线查看：
如果想要做全屏的遮罩层就更加的简单啦，只在要显示组件上增加个灯箱的效果即可。
PS:
示例源文件下载：遮罩层效果.rp</content></entry><entry><title>Apache Nifi在Windows环境下搭建伪群集及证书登录</title><url>https://lisenhui.cn/2017/10/26/nifi-windows-local-cluster.html</url><categories><category>大数据</category></categories><tags><tag>大数据</tag><tag>Nifi</tag></tags><content type="html"> 前些时间做了关于Apache Nifi分布式集群的搭建分享，但很多时候要搭建分布式集群机器资源是个问题，而现在的单机的配置还是相当不错的，故现在就做个关于Windows上搭建个伪分布式集群的分享，同时通过另外一种方式实现Apache Nifi的授权认证。
系统环境及软件版本 Windows8.1
JDK1.8.0_131
Nifi-1.4.0
Nifi安装目录 WEB端口 xxx\nifi-ncm 9443 xxx\nifi-cluster01 9444 xxx\nifi-cluster02 9445 (其它版本可参考此篇文章) 另在测试中发个问题，使用Apache Nifi内嵌的Zookeeper搭建伪集群里启动总是提示端口占用的问题，故放弃只采用了单结点启动。
Nifi的服务证书 生成本地Nifi服务证书 解压nifi-toolkit-1.4.0-bin.tar.gz文件后，通过CMD进入bin目录，执行以下的命令：
D:\DevelopTools\nifi-toolkit-1.4.0\bin>tls-toolkit.bat standalone -n "localhost( 3)" -C "CN=Admin, OU=ApacheNIFI" -o "..\target" 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandaloneCommandLine: No nifiPropertiesFile specified, using embedded one. 2017/10/26 18:21:32 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: Running standalone certificate generation with output directory ..\ target ****************************************************************************** 2017/10/26 18:21:34 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: Successfully generated client certificate ..\target\CN=Admin_OU=Apa cheNIFI.p12 2017/10/26 18:21:34 INFO [main] org.apache.nifi.toolkit.tls.standalone.TlsToolki tStandalone: tls-toolkit standalone completed successfully 生成后的目录结构如下：
Folder PATH listing for volume senhui.li Volume serial number is 000000F0 FA46:A0EB D:. │ CN=Admin_OU=ApacheNIFI.p12 │ CN=Admin_OU=ApacheNIFI.password │ nifi-cert.pem │ nifi-key.key │ ├─localhost │ keystore.jks │ nifi.properties │ truststore.jks │ ├─localhost_2 │ keystore.jks │ nifi.properties │ truststore.jks │ └─localhost_3 keystore.jks nifi.properties truststore.jks 特意注意： -C &ldquo;CN=Admin, OU=ApacheNIFI&rdquo; 中间的空格必须保留
拷贝Nifi服务证书 将localhost目录下的文件拷贝到nifi-ncm目录下替换所有的文件 将localhost_2目录下的文件拷贝到nifi-cluster01目录下替换所有的文件 将localhost_3目录下的文件拷贝到nifi-cluster02目录下替换所有的文件 将CN=Admin_OU=ApacheNIFI.p12和CN=Admin_OU=ApacheNIFI.password拷贝到桌面备用，后续登录需要使用 配置单点Zookeeper相关 创建目录及id 进入nifi-ncm的目录，创建woker目录，并把server id写到文件中，命令如下：
D:\DevelopTools\nifi-ncm>mkdir -p state\zookeeper D:\DevelopTools\nifi-ncm>echo -n '1' > state/zookeeper/myid 更新ZK配置 进入nifi-ncm的conf目录，打开zookeeper.properties文件，内容更新参考如下：
clientPort=2181 initLimit=10 autopurge.purgeInterval=24 syncLimit=5 tickTime=2000 dataDir=./state/zookeeper autopurge.snapRetainCount=30 # 只需要配置端口服务 server.1=localhost:2181 更新Nifi配置 进入nifi-ncm的conf目录，打开nifi.properties文件，更新如下的配置属性：
nifi.state.management.embedded.zookeeper.start=true # zookeeper properties, used for cluster management # # 另外两个节点，只要编辑此字段即可 nifi.zookeeper.connect.string=localhost:2181 更新State配置 进入nifi-ncm的conf目录，打开state-management.xml文件，更新zookeeper配置，如下：
&lt;cluster-provider> &lt;id>zk-provider&lt;/id> &lt;class>org.apache.nifi.controller.state.providers.zookeeper.ZooKeeperStateProvider&lt;/class> &lt;property name="Connect String">localhost:2181&lt;/property> &lt;property name="Root Node">/nifi&lt;/property> &lt;property name="Session Timeout">10 seconds&lt;/property> &lt;property name="Access Control">Open&lt;/property> &lt;/cluster-provider> 然后把此文件拷贝到nifi-cluster01和nifi-cluster02相同的目录下
配置Nifi Admin 添加Admin用户 进入nifi-ncm的conf目录，打开authorizers.xml文件，找到file-provider添加如下配置：
&lt;authorizer> &lt;identifier>file-provider&lt;/identifier> &lt;class>org.apache.nifi.authorization.FileAuthorizer&lt;/class> &lt;property name="Authorizations File">./conf/authorizations.xml&lt;/property> &lt;property name="Users File">./conf/users.xml&lt;/property> &lt;property name="Initial Admin Identity">CN=Admin, OU=ApacheNifi&lt;/property> &lt;property name="Legacy Authorized Users File">&lt;/property> &lt;property name="Node Identity 1">CN=localhost, OU=NIFI&lt;/property> &lt;property name="Node Identity 2">CN=localhost_2, OU=NIFI&lt;/property> &lt;property name="Node Identity 3">CN=localhost_3, OU=NIFI&lt;/property> &lt;/authorizer> 然后把此文件同时拷贝到别外两个节点目录。
注： 在Node Identity x中的OU要写成NIFI，尝试过用别的名称好像不成功，具体的原因未知，感兴趣的可以自行探究一二。
安装证书 打开谷歌浏览器，在设置中找到安全选项中找到管理证书，点击Import开始导入上面生成的证书：CN=Admin_OU=ApacheNIFI.p12，密码在后缀名为.password的文件中，如下图所示： 启动Nifi服务 进入到Nifi安装目录，然后在bin目录中找到run-nifi.bat文件并双击运行，注意启动的顺序： nifi-ncm&ndash;>nifi-cluster01/2，等待片刻后（可能会有点久，需要一个选举的过程）打开浏览器输入"https://localhost:9443/nifi"，选择刚刚导入的证书，如看到下面的画面表示启动成功： 用户策略 刚登录NIFI页面时，你会发现图标都是灰色的，需要赋予相应的权限才可以开始编辑权限才可以开始编辑。点击页面左侧面板上的钥匙图标，会弹出访问策略的窗口，如下图所示：
在此会看到用户列表为空，那么就要给相应的行为添加用户，点击Create链接即可开始添加，如下图所示： 待所有的权限添加完成后，便可看到NIFI页面的按钮已经点亮，可以开始创建流程。
示例演示 模板上传 下载DEMO压缩包，解压出来有个WordCountDemo.xml文件。然后打开浏览器输入NIFI访问地址： https://localhost:9443/nifi/，点击左侧面板中的上传按钮上传模板，如下图所示： 创建流程 拖动NIFI页面顶部的模板按钮到画板空白处，点击ADD按钮即可，然后双击打开WordCountDemo组找到PutFile组件，修改目录地址为你机器的实际可访问路径，如下图所示：
启动流程 点击NIFI页面左下角的NiFi Flow链接返回到主面板，点击WordCountDemo组，然后点击左侧面板中的开始按钮启动流程，如下图所示：
如无异常那么此时你可在目录下找到名为telltale_heart_wordcount的文件，打开便可看到如下图的统计内容：
至此在本地搭建NIFI伪集群就完成了，有问题欢迎留言。</content></entry><entry><title>Apache Nifi集群搭建及用kerberos实现用户认证</title><url>https://lisenhui.cn/2017/10/22/ninfi-cluster-deploy-with-kerberos.html</url><categories><category>大数据</category></categories><tags><tag>大数据</tag><tag>Nifi</tag></tags><content type="html"> 最近这段时间在接触数据流式处理方面的事宜，用到了Apache NIFI现把安装配置中学习的一些经验分享下。此篇文章主要是针对集群及用户权限方面，关于Apache NIFI的介绍就不做过多的说明，直接引用官方的首页的说明如下图所示：
Apahce NIFI的单机运行是相当的简单，易用，完全就是傻瓜式的。下载解压，进行bin目录执行nifi.sh start 打开浏览器输入http://127.0.0.1:8080/nifi即可看到一个简洁漂亮的WEB UI。那么接下来我们要配置的是它的集群模式，官方说明NIFI采用的是0主节点模式，集群中的每个节点在数据集上执行相同的任务，但是每个节点都在不同的数据集上运行（详细的说明请查看官方文档），并且内置了Zookeeper服务，如下图所示：
系统环境及软件版本 CentOS7
JDK1.8.0_91
Nifi-1.4.0
Kerberos5
(其它版本可参考此篇文章)
HostName IP Services centos7-master 192.168.56.100 Kerberos5 Server, Nifi Cluster Manager centos7-cluster01 192.168.56.101 Kerberos5 Client, Nifi Cluster 搭建Kerberos5服务 安装KDC服务及配置 进入到Master机器，执行以下命令安装KDC服务：
yum -y install krb5-server krb5-libs krb5-workstation 注：测试中发现krb5-auth-dialo组件是不可用的，也无需安装
修改KDC默认配置 进入/etc目录找到/etc/krb5.conf文件打开并修改，参考如下：
# Configuration snippets may be placed in this directory as well includedir /etc/krb5.conf.d/ [logging] default = FILE:/var/log/krb5libs.log kdc = FILE:/var/log/krb5kdc.log admin_server = FILE:/var/log/kadmind.log [libdefaults] dns_lookup_realm = false ticket_lifetime = 24h renew_lifetime = 7d forwardable = true rdns = false # 这个注释需要开启，并填写默认的域 default_realm = CENTOS7-MASTER.COM default_ccache_name = KEYRING:persistent:%{uid} [realms] # 把此处的EXAMPLE.COM修改成自己的域 CENTOS7-MASTER.COM = { kdc = centos7-master admin_server = centos7-master # 添加默认的域 default_domain = CENTOS7-MASTER.COM } [domain_realm] # 把此处的EXAMPLE.COM修改成自己的域名 .centos7-master.com = CENTOS7-MASTER.COM centos7-master.com = CENTOS7-MASTER.COM 修改KRB5KDC配置文件 进入/etc目录找到/var/kerberos/krb5kdc/kdc.conf文件打开，参考如下修改：
[kdcdefaults] kdc_ports = 88 kdc_tcp_ports = 88 [realms] # 修改此处的EXAMPLE.COM域名 CENTOS7-MASTER.COM = { #master_key_type = aes256-cts acl_file = /var/kerberos/krb5kdc/kadm5.acl dict_file = /usr/share/dict/words admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal kdc_ports = 88 kadmind_port = 749 } 初始化数据库 [root@centos7-master ~]# kdb5_util create -s Loading random data Initializing database '/var/kerberos/principal' for realm 'CENTOS7-MASTER.COM', master key name 'K/M@CENTOS7-MASTER.COM' You will be prompted for the database Master Password. It is important that you NOT FORGET this password. Enter KDC database master key: Re-enter KDC database master key to verify: 修改数据库权限 找到/var/kerberos/krb5kdc/kadm5.acl配置文件，给数据库管理员添加ACL权限，*代表全部权限，操作如下：
[root@centos7-master ~]# vi /var/kerberos/krb5kdc/kadm5.acl */admin@CENTOS7-MASTER.COM * 启动KDC服务 service krb5kdc start service kadmin start 创建数据库管理员 参考如下命令创建管理员用户，保存好创建时设置的密码(如果忘记后期可以使用cpw命令更新)，并导出keytab
[root@centos7-master ~]# kadmin.local -q "addprinc root/admin" Authenticating as principal root/admin@CENTOS7-MASTER.COM with password. WARNING: no policy specified for root/admin@CENTOS7-MASTER.COM; defaulting to no policy Enter password for principal "root/admin@CENTOS7-MASTER.COM": Re-enter password for principal "root/admin@CENTOS7-MASTER.COM": Principal "root/admin@CENTOS7-MASTER.COM" created. [root@centos7-master ~]# kadmin.local kadmin: ktadd -k /data/root.keytab root/admin kadmin: q [root@centos7-master ~]# kinit root/admin 安装KDC Client服务 进入从Cluster机器，执行如下命令安装KDC Cliente服务：
yum -y install krb5-libs krb5-workstation 更新配置并测试 拷贝主节点的krb5.conf和root.keytab到从节点服务，参考如下：
[root@centos7-cluster01 ~]# scp root@centos7-master:/etc/krb5.conf /etc/krb5.conf [root@centos7-cluster01 ~]# scp root@centos7-master:/data/root.keytab /data/root.keytab [root@centos7-cluster01 ~]# kadmin -p root/admin Authenticating as principal root/admin with password. Password for root/admin@CENTOS7-MASTER.COM: kadmin: 拷贝keytab文件 拷贝root.keytab到/data/root.keytab目录，注意此处指的是所有机器
创建Nifi服务证书 创建证书 解压nifi-toolkit-1.4.0-bin.tar.gz文件后进入bin目录，执行以下的命令：
[root@centos7-master ~]# ./tls-toolkit.sh standalone -n 'centos7-master, centos7-cluster01' -C 'CN=admin, OU=ApacheNIFI' -o './target' -f '/usr/local/bin/nifi-ncm/conf/nifi.properties' [root@centos7-master target]# tree . ├── centos7-cluster01 │ ├── keystore.jks │ ├── nifi.properties │ └── truststore.jks ├── centos7-master │ ├── keystore.jks │ ├── nifi.properties │ └── truststore.jks ├── CN=admin_OU=ApacheNIFI.p12 ├── CN=admin_OU=ApacheNIFI.password ├── nifi-cert.pem └── nifi-key.key -n 表示机器的hostname -C 生成浏览器证书（注意： CN=admin, 后面的空格一定要保留） -o 输出的目录 -f Nifi的配置文件位置 拷贝证书 拷贝生成好证书到主从节点服务器下NIFI安装目录中的conf文件夹，如下：
[root@centos7-master target]# scp centos7-cluster01/* centos7-cluster01:/usr/local/bin/nifi-cluster01/conf [root@centos7-master target]# cp target/centos7-master/* /usr/local/bin/nifi-ncm/conf/ 配置Zookeeper服务 注意：所有的主从节点都需要操作
创建id文件 进入到NIFI安装目录下，并创建state/zookeeper目录和myid文件，然后把对应的ID写入到文件中，操作如下：
[root@centos7-master nifi-ncm]# mkdir -p state/zookeeper [root@centos7-master nifi-ncm]# echo -n '1' > state/zookeeper/myid 注意： 从节点上创建的myid为2，如：echo -n '2' > state/zookeeper/myid
修改配置文件 clientPort=2181 initLimit=10 autopurge.purgeInterval=24 syncLimit=5 tickTime=2000 dataDir=./state/zookeeper autopurge.snapRetainCount=30 # # Specifies the servers that are part of this zookeeper ensemble. For # every NiFi instance running an embedded zookeeper, there needs to be # a server entry below. For instance: # # server.1=nifi-node1-hostname:2888:3888 # server.2=nifi-node2-hostname:2888:3888 # server.3=nifi-node3-hostname:2888:3888 # # The index of the server corresponds to the myid file that gets created # in the dataDir of each node running an embedded zookeeper. See the # administration guide for more details. # # 注意修改成你对应的服务器地址 server.1=centos7-master:2888:3888 server.2=centos7-cluster01:2888:3888 更新状态配置 进入到Nifif安装目录下修改conf/state-management.xml配置，在zk-provider节点下添加连接字符串
&lt;cluster-provider> &lt;id>zk-provider&lt;/id> &lt;class>org.apache.nifi.controller.state.providers.zookeeper.ZooKeeperStateProvider&lt;/class> &lt;property name="Connect String">centos7-master:2181,centos7-cluster01:2181&lt;/property> &lt;property name="Root Node">/nifi&lt;/property> &lt;property name="Session Timeout">10 seconds&lt;/property> &lt;property name="Access Control">Open&lt;/property> &lt;/cluster-provider> 更新NIFI配置 进入到Nifif安装目录下修改conf/nifi.properties文件，把内置的zookeeper启动和cluster设置成true，如下：
nifi.state.management.embedded.zookeeper.start=true nifi.cluster.is.node=true # zookeeper properties, used for cluster management # nifi.zookeeper.connect.string=centos7-master:2181,centos7-cluster01:2181 nifi.zookeeper.connect.timeout=3 secs nifi.zookeeper.session.timeout=3 secs nifi.zookeeper.root.node=/nifi 配置Nifi Admin初始化 更新NIFI配置 进入到Nifif安装目录修改conf/nifi.properties文件，把kerberos5的登录适配加上，如下：
nifi.kerberos.krb5.file=/etc/krb5.conf # kerberos service principal # nifi.kerberos.service.principal=root/admin@CENTOS7-MASTER.COM nifi.kerberos.service.keytab.location=/data/root.keytab 更新用户配置 进入到Nifif安装目录中的conf目录，添加authorizer到authorizers.xml，打开file-provider节点注释并添加如下内容：
&lt;authorizer> &lt;identifier>file-provider&lt;/identifier> &lt;class>org.apache.nifi.authorization.FileAuthorizer&lt;/class> &lt;property name="Authorizations File">./conf/authorizations.xml&lt;/property> &lt;property name="Users File">./conf/users.xml&lt;/property> &lt;property name="Initial Admin Identity">root/admin@CENTOS7-MASTER.COM&lt;/property> &lt;property name="Legacy Authorized Users File">&lt;/property> &lt;property name="Node Identity 1">CN=centos7-master, OU=NIFI&lt;/property> &lt;property name="Node Identity 2">CN=centos7-cluster01, OU=NIFI&lt;/property> &lt;/authorizer> 更新登录配置 进入到Nifif安装目录中的conf目录，修改login-identity-providers.xml 文件，打开kerberos-provider节点注释：
&lt;provider> &lt;identifier>kerberos-provider&lt;/identifier> &lt;class>org.apache.nifi.kerberos.KerberosProvider&lt;/class> &lt;property name="Default Realm">CENTOS7-MASTER.COM&lt;/property> &lt;property name="Kerberos Config File">/etc/krb5.conf&lt;/property> &lt;property name="Authentication Expiration">12 hours&lt;/property> &lt;/provider> 启动NIFI服务 先启动主节点的NIFI，而后启动从节点的NIFI，执行命令./bin/nifi.sh start， 然后打开浏览器输入https://centos7-master:9443/nifi/便会跳转到登录页面，输入在第1步骤创建的用户与密码，即可登录成功。界面显示如下：
如上面两图显示，在界面的左上角可以清楚的看到当前节点数为2，用户为**root/admin@CENTOS7-MASTER.COM**，其中centos7-master是协调器，centos7-cluster01是主要节点，主菜单中也增加有了Cluster，User和Policies选项。
至此Apache NIFI的集群服务与用户认证便完成好啦，后面便可开展下一步的工作。
遇到的坑：
首次登录时提示用户名或密码无效，可通过kadmin更新用户的密码 登录成功后提示用户没有对应的策略，重启NIFI服务即可 引用参考
nifi-security-user-authentication-with-kerberos.html Nifi-搭建 kerberos认证原理&mdash;讲的非常细致，易懂 Kerberos 基本安装与配置 收到的赏金 感谢各位的慷慨解囊!
序号 昵称 来源 金额(元) 留言 1 林俗人 微信 2 感谢博主，感谢分享!</content></entry><entry><title>关于Ambari中服务运行正常UI却显示服务停止的问题</title><url>https://lisenhui.cn/2017/10/18/ambari-monitor-status-issues.html</url><categories><category>大数据</category></categories><tags><tag>Ambari</tag><tag>HDP</tag><tag>大数据</tag></tags><content type="html"> 很多时候环境的维护的确是件头痛的事件，这不本来在Ambari的Dashboard页面显示正常服务的监控，实然间出现了个奇怪的现象： 在机器查询服务的运行进程是正常的，可偏偏Ambari的UI界面却显示状为停止，但端口检查又显示正常的。如下图：
本也可以放任不管的(反正服务运行正常就好)，但无奈强迫症的"毛病"又犯了，非得把它消灭掉心里才舒服。尝试了几次都没能成功，后来回想下好像同事有手动启动的某些组件，难道是这个原因。使用ps检查了这些组件的进程用户，发现确实如此，强制杀死这些组件，然后使用Ambari UI重启它们，可最终的结果还是没变。
真是挺郁闷的，此时也只好借助google啦，然后找到一篇类似问题的文章，里面提及到了运行时的xx.pid权限问题，真是一语点醒梦中人，赶紧的查看下这些组件的pid文件权限，果然如此，因为之前的启动是用超管用户，而实际上这些组件有对应的用户维护。删除这些xxx.pid文件，再在Ambari UI上重启这些服务，一切恢复正常，漂亮的绿色界面又回来啦。
参考引用：
service-is-running-but-ambari-shows-serice-is-stop</content></entry><entry><title>HiveServer2因JDBC版本引起的问题</title><url>https://lisenhui.cn/2017/10/17/hive2-jdbc-connector-issues.html</url><categories><category>大数据</category></categories><tags><tag>大数据</tag><tag>Hive</tag><tag>Ambari</tag></tags><content type="html"> 之前一直都是用HDP来搭建和管理Hadoop环境，在安装完成调试时也未曾出现过棘手的问题，但这次在Centos6x系统上布署好后却是遇到奇怪的问题：
表面上看来Hive服务是正常运行的，进程运行正常，页面UI也正常，日志也没错误输出。简单的建表的语句都能执行，可偏偏在导入本地/HDFS数据时，便就抛出异常啦。错误的堆栈信息如下：
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'OPTION SQL_SELECT_LIMIT=DEFAULT' at line 1 另外一个问题在使用Ambari提供的HiveView UI进行HDFS数据导入提示文件不存在，错误信息如下：
org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException Line 1:17 Invalid path ''/tmp/xxx/xxxxx.csv'': No files matching path hdfs:/... 简单描述下所使用的环境：
Hive - 1.2.1000
MySQL - 5.6.17
MySQL JDBC - 5.1.17
问题一
从报错的信息可以明显知道是语法错误的问题，不过麻烦的是它没有打印出有问题的SQL语句，通过google找到了遇到相同问题文章，其中指出这是MySQL JDBC驱动5.1.17版本以下的BUG，只需要更新JDBC驱动的版本即可。那么似乎问题变得简单啦，找到新的JDBC驱动文件，执行如下操作:
拷贝驱动文件 # 拷贝到Amabri Server的资源目录 mv mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar ln -s -f /var/lib/ambari-server/resources/mysql-connector-java-5.1.44.jar /var/lib/ambari-server/resources/mysql-connector-java.jar # 拷贝到share目录 mv mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java-5.1.44.jar ln -s -f /usr/share/java/mysql-connector-java-5.1.44.jar /usr/share/java/mysql-connector-java.jar 重新设置Ambari驱动引用 ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 删除Ambari Agent上面的旧的驱动，并重启 # 注意做好备份和删除的路径 rm -rf /var/lib/ambari-agent/tmp/mysql-* # 重启服务 ambari-agent restart 在Ambari UI上重启Hive组件服务 理论上有这些操作便可解决问题了，可在运行数据导入后仍是出现同样的问题，说明上面的文件更新操作没有成功，切换到Hive Master机器上找到lib目录下的驱动文件，解压后发现版本确实没有变化，那么只能手动强制替换了，把Hive Master，Slave机器上的驱动全替换成最新版本，然后再次重启Hive组件服务，接着就出现个新问题。
问题二
单纯的从上述的日志无法确定问题的本身，因为可以确切的确定文件是存在于HDFS之上的。所以还是切换到Hive服务日志上面，找到下面的一段日志：
ERROR [HiveServer2-Background-Pool: Thread-4456]: hdfs.KeyProviderCache (KeyProviderCache.java:createKeyProviderURI(87)) - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider !! ERROR [HiveServer2-Background-Pool: Thread-4456]: metadata.Hive (Hive.java:copyFiles(2853)) - Failed to move: org.apache.hadoop.security.AccessControlException: Permission denied. user=admin is not the owner of inode=xxxxx.csv at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkOwner(FSPermissionChecker.java:250) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:227) 从这段日志明显的看出是用户权限的问题，不过这边有点不解，为何Ambari Hive View不直接使用超级用户进行操作，现在只能是强行的更改文件的所属者，命令如下：
hdfs dfs -chown hdfs:hadoop /tmp/XXX/XXX.CSV 至此所有问题都修复完成，重新执行导入操作，一切运行正常，数据成功导入。
参考引用：
hive-metastore-not-working-syntax-error-option-sql</content></entry><entry><title>Azkaban所支持的Job类型及示例</title><url>https://lisenhui.cn/2017/09/09/azkaban-execute-jobs.html</url><categories><category>大数据</category></categories><tags><tag>定时调度</tag><tag>大数据</tag><tag>Azkaban</tag></tags><content type="html"> 在官方文档的介绍中，了解到Azkaban所支持的工作类型还是很丰富的，如：Command，HadoopShell，Python，Java，Hive，Pig等等。不过在此我们主要具体只来讲解下Python与Java的工作类型任务，其它工作类型的话，比如Commnad，Hive，HadoopShell相对比较简单就不做详解，有需要的话可以自行实践一下。
不管提交哪一种任务，Azkaban默认都是通过上传压缩包来管理，那么在此建议大家养成一个习惯，不要所执行的文件(代码)打包到Azkaban的工程包里面。这样带来的好处是显而易见的，比如：
工程创建的速度快，不需要上传执行部分文件
避免了修改MySQL中的max_allow_packet参数以解决工程文件上传失败的问题
在分布式布署环境中，当执行Task免去了在不同节点中拷贝工程包的麻烦
Java工作任务 由于工作业务场景中，大部分的代码都是Java来编写的，这也正是选择Azkaban的重要原因。与常见的Java程序并无太大的差异，唯一的不同便是程序入口的方法不一样。需要在入口的类中增加个**run**方法，即这方法是启动整体个Task的关键。示例代码如下：
package io.github.elkan1788.azkabantasks; import azkaban.utils.Props; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Azkaban java job example * @author elkan1788@gmail.com */ public class JobMain { private static final Logger logger = LoggerFactory.getLogger(JobMain.class); private int fileRows; private int fileLine; /** * Dynamic parameters set */ public JobMain(String name, Props props) { this.fileRows = props.getInt("file.rows"); this.fileLine = props.getInt("file.line"); } public void run() throws Exception { logger.info(" ### this is JavaMain method ###"); logger.info("fileRows value is ==> " + fileRows); logger.info("fileLine value is ==> " + fileLine); } } 在上面的示例代码中，增加了动态参数设置，最后在打包的时候并不需要指定MainClass的所在，只要项目中的所有相关的代码及依赖打包到一个独立的文件即可。
另外我们还需要构建一个Azkaban工程脚本来告诉它如何执行我们的任务，脚本示例如下：
type=java job.class=io.github.elkan1788.azkabantasks.JobMain #指定执行jar包的路径 classpath=/home/azkaban/javademo/* #用户参数1 file.rows=10 #用户参数2 file.line=50 为了不让任务太单调，顺便个简单的命令输出，组成个FLOW形式输出，参考脚本如下：
type=command dependencies=java command=whoami 效果如下：
Pthon工作任务 Python的工作任务相对就简单了，不过目前没找到动态入参的方法。执行Python工作任务的方法有两种, 参考代码如下：
command类型 type=command command=python -u /home/azkaban/pythondemo/helloworld.py python类型 type=python python=python script=/home/azkaban/pythondemo/helloworld.py 效果如下：
总结 总的来说，Azkaban编写任务的脚本还是简单且灵活的，不过也有比较坑人的地方。比如前面举粟的Java工作任务，在实际的运行过程中是需要添加hadoop的依赖包及相关配置，能过查阅官方文档得知是因为Java任务类型是在HadoopJava衍生出来的，所以也就难怪了。还好这也是只是配置环境时的问题，后续的应用开发还是挺方便的。</content></entry><entry><title>定时调度任务器Azkaban安装</title><url>https://lisenhui.cn/2017/09/08/azkaban-install-use-share.html</url><categories><category>大数据</category></categories><tags><tag>定时调度</tag><tag>大数据</tag><tag>Azkaban</tag></tags><content type="html"> 背景与介绍 在大数据繁杂的ETL或其它数据处理过程当中，有些任务是需要定时执行的，虽然Linux自带了cron命令功能，但是仍不能满足最大的一点就是它不能提供集中式的管理和可视化的编辑。其实在大数据的生态当中已集成有个定时调度框架Oozie，只是实践下来发现其学习成本不低，布署的过程也较复杂。在尝试过其它分布工调度框架后（如阿里的宙斯Zeus），还是选择了社区较多人使用的Azkaban。
Azkaban3相对于上个版本所做的更改还是比较大的，感兴趣的话可以到其官方网站Azkaban了解下。接下来主要还是分享下Azkaban3的安装布署，下面是Azkaban3的系统架构设计图：
图中的3个组件便是Azkaban3的重要组成部分：
MySQL关系数据存储数据 Web Server GUI管理服务提供者 Executor Server 分布式节点服务布署 数据库初始化 建议使用MySQL5.6及以上版本的数据库，首先创建一个名为azkaban的数据库：
mysql> CREATE DATABASE azkaban DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 指定某个数据库用户，为其赋予对azkaban数据库具有SELECT,INSERT,UPDATE,DELETE的操作权限：
mysql> GRANT SELECT,INSERT,UPDATE,DELETE ON azkaban.* to 'azkaban-dba'@'%' WITH GRANT OPTION; 最后就是导入创建表的SQL语句，官方提供的建表语句比较分散，为此特地整理了份完整的建表语句Azkaban Create Tables 密码: 8ne8:
mysql> source /opt/download/azkaban-create-tables.sql 注意：由于Azkaban3的项目发布是通过上传文件实现的，因此需要把MySQL中允许上传包大小的能数调整下，此参数位于[mysqld]下：max_allowed_packet=64M，根据实际情况修改适合大小。
其实有个办法可做到不修改此参数 ，就是打包Azkaban项目时尽量不要包依赖文件放进来，通过相对路径的引用即可。
Web Server布署 Web Server目录下有7个文件夹，描述如下：
文件夹 描述 bin 脚本相关文件，如启动，停止Jetty服务 conf Solo服务的配件文件 lib Web Server必须的依赖包库 extlib 第三方扩展依赖包 plugins Azkaban插件安装位置 web Web Server的文件，如css，js, html等 Web Server的布署需要修改至少4处地方，具体如下：
azkaban.properties配置 官方默认的配置文件中缺少了多执行器的参数设置，参考如下：
# Azkaban Personalization Settings # 站点名称，中文可用UTF-8编码，不过邮件通知不支持 azkaban.name=Azkaban azkaban.label=Production Environment azkaban.version=3.25 azkaban.color=#FF3601 azkaban.default.servlet.path=/index web.resource.dir=web/ default.timezone.id=Asia/Shanghai # Azkaban UserManager class user.manager.class=azka ban.user.XmlUserManager user.manager.xml.file=conf/azkaban-users.xml # Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects # DB settings database.type=mysql mysql.port=3306 mysql.host=127.0.0.1 mysql.database=azkaban mysql.user=azkaban-dba mysql.password=12345678 mysql.numconnections=100 # Velocity dev mode velocity.dev.mode=false # Azkaban Jetty server properties. jetty.hostname=localhost jetty.use.ssl=false jetty.maxThreads=25 jetty.port=8081 # Azkaban Executor settings executor.port=12321 # Notification Email Settings mail.sender=elkan1788@gmail.com mail.host=stmp.gmail.com mail.user=elkan1788@gmail.com mail.password=12345678 lockdown.create.projects=false cache.directory=cache # JMX stats jetty.connector.stats=true executor.connector.stats=true # Azkaban plugin settings azkaban.jobtype.plugin.dir=plugins/jobtypes # Multiple executors settings azkaban.use.multiple.executors=true azkaban.executorselector.filters=StaticRemainingFlowSize,CpuStatus azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1 azkaban.executorselector.comparator.Memory=1 azkaban.executorselector.comparator.LastDispatched=1 azkaban.executorselector.comparator.CpuUsage=1 azkaban-users.xml配置 Azkaban采用的是类似Spring Securit的账户信息配置，参考如下：
&lt;azkaban-users> &lt;!-- UserAccount Info --> &lt;user groups="azkaban" password="azkaban" roles="admin" username="azkaban"/> &lt;user password="metrics" roles="metrics" username="metrics"/> &lt;!-- Role Info --> &lt;role name="admin" permissions="ADMIN"/> &lt;role name="metrics" permissions="METRICS"/> &lt;/azkaban-users> log4j.properties配置 官方默认的配置文件中只配置了终端的输出，通过Shell脚本重定向形成日志输出，而log4j本身是支持按日期增量管理的，参考如下：
log4j.rootLogger=INFO,C,file log4j.appender.C=org.apache.log4j.ConsoleAppender log4j.appender.C.Target=System.err log4j.appender.C.layout=org.apache.log4j.PatternLayout log4j.appender.C.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n log4j.appender.file=org.apache.log4j.DailyRollingFileAppender log4j.appender.file.File=/opt/azkaban3/web-server/logs/web-server.log log4j.appender.file.DatePattern='.'yyyy-MM-dd log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %5p [%t](%F:%L) - %m%n 启停脚本 官方默认提供启停脚本并不太友好，稍稍做了些许修改，参考如下：
启动脚本 (bin/start-web.sh) !/bin/bash # 官方默认 # bin/azkaban-web-start.sh "$@" >> logs/webServerLog_`date +%Y%m%d`.out 2>&amp;1 &amp; bin/azkaban-web-start.sh > /dev/null 2>&amp;1 &amp; 停止脚本(bin/shutdown-web.sh) !/bin/bash # 官方默认 # bin/azkaban-web-shutdown.sh "$@" >> logs/webServerLog_`date +%Y%m%d`.out 2>&amp;1 &amp; bin/azkaban-web-shutdown.sh > /dev/null 2>&amp;1 &amp; 其他配置 可以把一些公共的配置统一放到conf/global.properties配置中统一管理，如项目执行成功，失败的通知人电子邮件，默认的执行类型等等。
Executor Server布署 Executor Server与Web Server相比就只是少了个plugins目录，描述如下：
文件夹 描述 bin 脚本相关文件，如启动，停止Jetty服务 conf Solo服务的配件文件 lib Executor Server必须的依赖包库 extlib 第三方扩展依赖包 plugins Azkaban插件安装位置 原则上建议一台机器上只布署一个Executor Server节点，因为在节点启动的时候它会自动加入到数据库executors列表中，当然也是可以通过端口干预的方法来配置本地伪分布模式布署。
Executor Server布署相对简单多了，只要更新3处即可，具体如下：
azkaban.properties配置 只需要修改下官方默认配置文件的值即可，参考如下：
# Azkaban Personalization Settings default.timezone.id=Asia/Shanghai # Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects # DB settings database.type=mysql mysql.port=3306 mysql.host=127.0.0.1 mysql.database=azkaban mysql.user=azkaban-dba mysql.password=12345678 mysql.numconnections=100 # Velocity dev mode velocity.dev.mode=false # Azkaban Executor settings executor.host=127.0.0.1 executor.port=12321 executor.maxThreads=50 executor.flow.threads=30 # JMX stats jetty.connector.stats=true jetty.host=127.0.0.1 executor.connector.stats=true # Azkaban plugin settings azkaban.jobtype.plugin.dir=plugins/jobtypes log4j.properties配置 参考上面的Web Server中的配置即可，注意修改日志文件的输出路径。
启停脚本 同样的对启停脚本做了些更改，方便后期日志的回放，参考如下：
启动脚本(bin/start-exec.sh) #!/bin/bash export HADOOP_HOME=/opt/hdp/2.3.2.0-2950/hadoop # pass along command line arguments to azkaban-executor-start.sh script # bin/azkaban-executor-start.sh "$@" >> logs/executorServerLog_`date +%Y%m%d`.out 2>&amp;1 &amp; bin/azkaban-executor-start.sh > /dev/null 2>&amp;1 &amp; 停止脚本(bin/shutdown-exec.sh) #!/bin/bash export HADOOP_HOME=/opt/hdp/2.3.2.0-2950/hadoop # pass along command line arguments to azkaban-executor-start.sh script # bin/azkaban-executor-shutdown.sh "$@" >> logs/executorServerLog_`date +%Y%m%d`.out 2>&amp;1 &amp; bin/azkaban-executor-shutdown.sh > /dev/null 2>&amp;1 &amp; 启动预览 至此Azkaban3运行所需要的关键配置已经配置好，接下就是启动相应的服务预览下劳动成果。
启动 启动顺序如下：
启动 Executor Server服务： sh bin/start-exec.sh
更新数据表：在excecutors表中找到executor server hostname对应的记录，把最后一列active 的值更新为 1
启动Web Server服务：sh bin/start-web.sh
注意：启动前请确定端口正常未占用，另外留意内存的使用情况。
启动成功后，在浏览器中输入http://localhost:8081便可看到Web Server的界面，如下图所示：
Demo 在上述启动成功的Web Server中创建中新的项目，命名为：ShellJob-Demo，然后把下面示例Job下载并上传至刚才创建好的项目中，注意不需要解压哦。然后在项目中找到Exectue Flow按钮，然后不断的下一步即可，如下图组所示：
Base Flow Demo 密码: 4f4f
Azkaban3是通过Web Server把任务(Job)提交到Executor Server执行的，因此在界面上是不能直观的看到程序执行过程，但可以通过执行列表中找到正在运行的任务，查看其日志的方式来了解运行过程，如下图组所示：
好啦，至此Azkaban3的服务布署及简单示例便完成收工，是不是相对而言比较简单呢。初步阶段来看Azkaban3的使用还是可以贴合业务的场景使用，只是后面提升过程发现它自身也并不完善，比如在上面启动过程中需要手动去更新数据库才能激活Executor Server（只是首次启动时），另外官方并未提供Executor Server运行的管理，分布式运行时需要手动指定Executor Server的ID 等等。但是基本上还是可以满足日常的使用，特别是它的Job Flow设计。最后要是关于Azkaban3有问题可评论中一起讨论，后续也会更新相关的使用教程，敬请关注。</content></entry><entry><title>使用Github，Travis CI自动布署Hexo博客到Coding，OSChina服务器</title><url>https://lisenhui.cn/2017/08/19/use-travis-ci-push-hexo-blog.html</url><categories><category>Hexo</category></categories><tags><tag>Hexo</tag><tag>Github</tag><tag>Travis</tag><tag>CI</tag><tag>Coding</tag><tag>OSChina</tag></tags><content type="html"> 通常我们都是在本地用hexo deploy发布博客文章到远程的Pages服务器，可别忘记了我们是还需要提交代码的，所以是不是觉得有点麻烦还得分开两步进行操作。这时突然想起是否可用Travis CI工具来完成这个布署的操作呢？答案是肯定的，整体的流程大致如下：
在本地(又或者Github网站)上编辑文章 提交文章到Github服务器 Travis CI收到通知，同步最新的Github代码，并执行用户自定义好的Travis脚本生成静态博客 最终再把生成好的博客推送到指定的Pages服务器 只是这其中有点比较麻烦的问题就是如何保护我们的私钥，还好Travis CI已经为我们准备好啦，那么就开始我们的捣腾之旅吧。
准备Travis Client工具 准备Ruby环境 Ruby的安装请移步搜索引擎，在此只是提示下建议使用2.0以上的版本，另外就是注意更新gem的镜像地址： Ruby China。
Travis CI账户 如有需要可以单独注册账号，建议直接使用Github Token登录即可。 接下来就是需要生成个Github Token，在Github的个设置面板中找到，或者是直接点击Github Tokens进行创建，如下图所示：
保存好刚刚创建的Token，然后使用Github授权登录Travis CI并跳转至控制面板Travis Profile，选择需要创建的项目(即你的博客项目)如下图所示
Travis Client安装 Travis Client安装非常的简单，命令如下：
sudo gem install travis -v 1.8.8 --no-rdoc --no-ri 安装成功后，使用如下命令检查，安装成功会有版本号的输出。
travis version 使用如下命令检验上一步所生成的Github Token，并登录Travis CI成功后会返回欢迎信息。
travis login -g fb25xxxxxxxxxxx Successfully logged in as xxxx! SSH私钥加密 切换到博客的根据目录，创建一个名为.travis的目录，并把用于Coding和OSChina的私钥拷贝至此，使用如下的命令生成Travis能识别的加密文件：
travis encrypt-file id_rsa Detected repository as elkan1788/my-hexo-blog, is this correct? |yes| yes encrypting id_rsa for elkan1788/my-hexo-blog storing result as id_rsa.enc storing secure env variables for decryption Please add the following to your build script (before_install stage in your .travis.yml, for instance): openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in id_rsa.enc -out id_rsa -d Pro Tip: You can add it automatically by running with --add. Make sure to add id_rsa.enc to the git repository. Make sure not to add id_rsa to the git repository. Commit all changes to your .travis.yml. 加密成功后千万要记得要把id_rsa文件删除，并把如下的语句保存好，后续在布署脚本中用得上：
openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in id_rsa.enc -out id_rsa -d 准备Travis脚本 编写Travis脚本 Travis脚本使用的是yml语法，写起来并不难，注意空格的缩进就好。在博客根目录下创建名为.travis.yml的文件，内容参考如下：
# Define language environment language: node_js # use root accout or not sudo: false # node js version node_js: stable # setting timezone before_install: - export TZ='Asia/Shanghai' # cache installed modules cache: apt: true directories: - node_modules # add pages server domain addons: ssh_known_hosts: - git.coding.net - git.oschina.net # auto deploy blog to pages server deploy: provider: script script: sh .travis/deploy.sh skip_cleanup: true on: branch: master # offical request dist: precise # which branch trigger branches: only: - master 如果不确定所编写的脚本是否正确，可借助Travis CI进行校验，命令如下：
travis lint .travis.yml Hooray, .travis.yml looks valid :) 编辑deploy.sh脚本 接下来就是编写个发布博客文章到Pages服务器的脚本，主要的流程如下：
解密SSH私钥，并输出到指定的目录 修改私钥的文件权限，启动SSH Agent， 添加私钥 设置Git配置，主要是用户名，邮箱地址 使用Hexo命令->清理，生成，发布 脚本内容参考如下：
#!/bin/bash # Decrypt the private SSH key openssl aes-256-cbc -K $encrypted_c9744fe6174f_key -iv $encrypted_c9744fe6174f_iv -in .travis/id_rsa.enc -out ~/.ssh/id_rsa -d # Set the permission of the private SSH key chmod 600 ~/.ssh/id_rsa # Start SSH agent eval $(ssh-agent) # Add the SSH private key to the system ssh-add ~/.ssh/id_rsa # Set Git config git config --global user.name "凡梦星尘" git config --global user.email elkan1788@gmail.com # Clean, generate and deploy to Pages server hexo clean &amp;&amp; hexo g &amp;&amp; hexo deploy 发表文章 使用hexo new "article tittle"命令创建一篇文章，然后加入你想吐槽的观点，内容等保存，然后用git push命令推送代码到Github服务器，此时登录Travis CI便可以在对应的项目中看到"华丽"的日志输出如下图所示：
如果最后的结果是绿色，那么恭喜你，你的博客已经布署成功，赶紧去刷新页面瞅瞅。
至此所有的配置结束，怎么样，感觉是不是很炫，只要一个简单的git push命令即保存代码又搞定博客站点布署，如有问题欢迎吐槽。
参考：
使用Github、Travis-CI和Coding.net自动部署博客［一］ 使用Github、Travis-CI和Coding.net自动部署博客［二］ 使用Github、Travis-CI和Coding.net自动部署博客［三］</content></entry><entry><title>pymssql连接azure云的MSSQL数据库</title><url>https://lisenhui.cn/2017/08/17/pymssql-azure-mssql-datasource-connect.html</url><categories><category>Azure</category></categories><tags><tag>Python</tag></tags><content type="html"> 码好代码在测试环境做好测试后，满怀信心的去布署上线到生产环境，结果就是一堆的异常，具体查看了后发现是连接数据库的问题，异常信息如下：
(40532, 'Cannot open server "1433D" requested by the login. The login failed.DB-Lib error message 20018, severity 20:\n General SQL Server error: Check messages from the SQL Server\n DB-Lib error message 20002, severity 9:\nAdaptive Server connection failed\n') 难道是环境安装的有问题，切换了下测试环境又没有问题，好吧，只好再次求助Google，最后找到了原因，应该是微软云自己做的规则，在用户名中加入主机名称就好了，参考如下：
import pymssql conn = pymssql.connect(server='yourserver.database.chinacloudapi.cn', user='yourusername@yourserver', password='yourpassword', database='AdventureWorks') @yourserver 就是这个关键字
参考：
使用 Python 查询 Azure SQL 数据库
Cannot open server &ldquo;1433D&rdquo; requested by the login</content></entry><entry><title>在Mac/Linux系统下安装pymssql模块</title><url>https://lisenhui.cn/2017/08/16/mac-install-pymssql-module.html</url><categories><category>Python</category></categories><tags><tag>Mac</tag><tag>Linux</tag><tag>Python</tag></tags><content type="html"> 在非Windows环境下去访问，连接MSSQL数据，本身就是件苦差事来的。自写Python程序以来在ORM方面都是使用**pyxxx**的模块，果不其然连接MSSQL也有个模块叫pymssql，只是实际使用中并不是特别的顺利。如笔者所处的环境就是如此，开发环境为OSX 10.11，发布环境为CentOS 6.4，按官方的安装步骤实行下来，Linux环境是OK的，只是Mac环境下安装失败，错误的堆栈信息如下：
Running setup.py install for pymssql ... error Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c "import setuptools, tokenize;__file__='/private/tmp/pip-build-KA5ksi/pymssql/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))" install --record /tmp/pip-A3wRBy-record/install-record.txt --single-version-externally-managed --compile: setup.py: platform.system() => 'Darwin' setup.py: platform.architecture() => ('64bit', '') setup.py: platform.libc_ver() => ('', '') setup.py: Detected Darwin/Mac OS X. You can install FreeTDS with Homebrew or MacPorts, or by downloading and compiling it yourself. Homebrew (http://brew.sh/) -------------------------- brew install freetds MacPorts (http://www.macports.org/) ----------------------------------- sudo port install freetds ...... /usr/bin/clang -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/opt/local/include -I/opt/local/include/freetds -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c _mssql.c -o build/temp.macosx-10.6-intel-2.7/_mssql.o -DMSDBLIB _mssql.c:18924:15: error: use of undeclared identifier 'DBVERSION_80' __pyx_r = DBVERSION_80; 在安装pymssql之前有个关于的组件为**FreeTDS **，所遇到的问题也就是出现在此组件上面。 在Linux和OSX环境下的安装命令分别如下：
# Linux yum install freetds-devel.x86_64 # Mac brew install freetds 在Mac环境中需要注意**freetds**的版本引起的问题，可以正常使用的版本为**0.91**，修正后的安装命令如下：
brew uninstall --force freetds brew install freetds@0.91 brew link --force freetds@0.91 另外还得需要安装一个Python模块，安装命令如下：
pip install cython 上述环境准备就绪后，便可以顺利的安装pymssql模块，执行如下安装命令：
pip install pymssql 写个简单的测试代码如下：
#!/usr/bin/env python # -*- coding: utf_8 -*- # coding=utf8 import pymssql server = "192.168.1.2" user = "sa" password = "123456" conn = pymssql.connect(server, user, password, database="platform") cursor = conn.cursor() cursor.execute("SELECT * FROM Table") row = cursor.fetchone() while row: row = cursor.fetchone() print row conn.close() OK，全部搞定，继续码代码去。
参考如下：
pymssql-isseues432
mac-pip-install-pymssql-error</content></entry><entry><title>Hue中集成MySQL数据显示乱码</title><url>https://lisenhui.cn/2017/08/15/hue-rdbms-mysql-chinese.html</url><categories><category>大数据</category></categories><tags><tag>hue</tag><tag>大数据</tag></tags><content type="html"> Hue is a Web applications that enables you to easily interact with an Hadoop cluster. Hue applications let you browse HDFS, Jobs, run Hive, Pig and Cloudera Impala queries, manage the Hive Metastore, HBase, Sqoop, ZooKeeper, MapReduce jobs, and create and schedule worklows with Oozie.
更加关于HUE的介绍及演示可访问其官方网站：http://gethue.com
在此主要解决的是在HUE过程中集成MYSQL管理时，遇到了数据库开发中常见的中文乱码问题。先来看看集成MySQL的配置描述：
########################################################################### # Settings for the RDBMS application ########################################################################### [librdbms] # The RDBMS app can have any number of databases configured in the databases # section. A database is known by its section name # (IE sqlite, mysql, psql, and oracle in the list below). [[databases]] # sqlite configuration. ## [[[sqlite]]] # Name to show in the UI. ## nice_name=SQLite # For SQLite, name defines the path to the database. ## name=/tmp/sqlite.db # Database backend to use. ## engine=sqlite # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ ## options={} # mysql, oracle, or postgresql configuration. [[[mysql]]] # Name to show in the UI. nice_name="MY SQL DB" # For MySQL and PostgreSQL, name is the name of the database. # For Oracle, Name is instance of the Oracle server. For express edition # this is 'xe' by default. name=mysql # Database backend to use. This can be: # 1. mysql # 2. postgresql # 3. oracle engine=mysql # IP or hostname of the database to connect to. host=localhost # Port the database server is listening to. Defaults are: # 1. MySQL: 3306 # 2. PostgreSQL: 5432 # 3. Oracle Express Edition: 1521 port=3306 # Username to authenticate with when connecting to the database. user=USER # Password matching the username to authenticate with when # connecting to the database. password=PASSWORD # Database options to send to the server when connecting. # https://docs.djangoproject.com/en/1.4/ref/databases/ # options={} 这段配置很简单理解起来也难，可实际运行过程中就遇到了两个难题，先是显示出现乱码问题，另外就是配置中给的文档链接地址是**404**，真是尴尬啦。追溯下来最后到找到关于sql-mode设置，想下应该是支持MySQL的命令吧，然后就在配置最后一段加入如下的命令：
options={"init_command":"SET NAMES `utf8`"}实验了一下，乱码问题OK，中文显示正常。
其实要不生产环境的话就不用如此的折腾，最简单的办法就是更新my.ini配置，你懂的。</content></entry><entry><title>Python在命令行即时输出</title><url>https://lisenhui.cn/2017/08/13/python-output-conosle-intime.html</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"> 在程序遇到问题需要DEBUG时，通过会增加一些**print**语句输出。于是乎按惯例也在Python的代码中加入print调试，然后输入python xxxx.py，满怀信心的期待着调试信息的满屏滚动，结果是过了好阵子才显示出来。为何会这样呢？
根据网友建议增加个-u参数就OK，后来查了下原因：Python在默认情况会先把print输出到缓冲中，待缓冲满或程序后才会输出。所以可以在运行Python程序时加入此参数是非常的有用。
python -u xxxx.py 除此之外还支持别的参数，参考如下
-B 参数，在import时候，不产生pyc或者pyo文件 -c 参数，直接运行python语句 -i 参数，运行完python脚本文件以后打开一个python环境，方便查看运行结果 -m 参数，将模块按照脚本执行 -V 参数，输出Python的版本 -O 参数，产生一个优化的pyo文件（和-B 参数一起使用无效） -v 参数，会输出每一个模块引用信息，包括从何处引用的，以及何时被清除的 -u 参数，在print记录时候很有用，使用这个参数 会强制 stdin, stdout 和 stderr变为无缓冲的，会立刻输出出来，而不是等缓冲区满了才会打印数据。 参考:
Python命令行参数学习</content></entry><entry><title>Python pip中国镜像服务器地址</title><url>https://lisenhui.cn/2017/08/11/python-pip-install-chinese-mirror.html</url><categories><category>Python</category></categories><tags><tag>Mirror</tag><tag>Python</tag></tags><content type="html"> 今天在安装一个Python模块&ndash;>pymysql结果等待时间特别的长，最后超时失败啦，起初是以为是网络带宽问题，让IT调整后仍是失败，随后尝试查找国内的镜像，还有真人也遇到过相同的问题。镜像列表如下：
https://pypi.douban.com/simple/ 豆瓣 http://mirrors.aliyun.com/pypi/simple/ 阿里 http://pypi.hustunique.com/simple/ 华中理工大学 http://pypi.sdutlinux.org/simple/ 山东理工大学 http://pypi.mirrors.ustc.edu.cn/simple/ 中国科学技术大学 https://pypi.tuna.tsinghua.edu.cn/simple 清华 然后在安装模块时，使用如下的命令：
pip install xxxx -i https://pypi.douban.com/simple 网友还介绍了把镜像地址写入到配置文件的方法，但尝试没有成功，不明白其中的原因，待跟进。
参考：
Python pip 国内镜像大全及使用办法</content></entry><entry><title>使用Hexo重新构建个人博客站点</title><url>https://lisenhui.cn/2017/08/02/use-hexo-rebuild-blog-site.html</url><categories><category>Hexo</category></categories><tags><tag>Hexo</tag><tag>学习</tag><tag>博客</tag></tags><content type="html"> 其实在Github Page上面也是混迹许久啦，虽然现在各种Blog网站层出不穷，但是作为IT界的程序猿还是喜欢自己动手捣鼓捣鼓，成功固然是欣喜失败也会不气妥。 Github Page刚出道时使用的是Jekyll，简单的解释其实就是一个静态化网站的工具，这不现在又兴起一个名为Hexo(**Nodejs**实现)的工具。两者的目标皆是一致的，只不过对比下来发现Hexo上手确实要容易些，加者它能轻松的在本地实现调试，故有想法想再次折腾一翻，构建个Hexo版本的个人博客。
介绍另一款静态网站工具Gor，它是鄙人一直崇拜的大拿Wendal的杰作，熟悉GO语言的朋友有可以关注下。
动手前先对Pages服务做了个简单的调查，别无它意，就是现在Github用户越来越多且服务器又在国外的，生活在天朝的我们你懂的啦。惊喜的发现目前国内的Git服务商都提供了Pages实现，最后选择了Gitee和Coding作为新博客落脚点，其中Coding作为首先/默认服务，Gitee为备选的服务，作此选择的原因很简单：Coding不但提供了自定义域名，而且还附带了https免费证书，真是漂亮。
对于Hexo环境的搭建在此就不在累述啦，官方文档给出了详细的说明(操作也是相当的简单)请移步：https://hexo.io/zh-cn/docs/index.html。搭建好后可以在官方网站提供的主题页面中选择自己所喜爱的风格，个人选择的是较热门的NexT，喜欢它的简单，轻爽。
NexT配置使用也是很简易的，下面就个人在搭建过程中遇到的问题做个简单的归纳：
1.插件的的安装 Hexo相当的灵活提供丰富的插件支持，根据个人的需要可自行安装，个人的安装记录如下：
# 生成RSS npm install hexo-generator-feed --save # 生成Site map为爬虫服务准备 npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save # 压缩站点文件 npm install hexo-all-minifier --save # 发布至Git服务器 npm install hexo-deployer-git --save 2.第三方服务集成 作为博客网站肯定是少不了互动的环节，现在的互联网世界早就已提供了此功能，在此主要用到的功能有：文章阅读，文章数字统计，站点PV/UV，评论回复。其它的功能集成应该都没难度，只要在对应的服务商站点注册好，填写对应的ID，KEY即可。主要提及下文章数字统计的功能：
登录LeanCloud找到你的应用，点击其右上角的设置按钮，如下图所示: 接着点击左侧菜单中的存储，然后在中间的列表中点击创建Class，输入名称点击创建即可，如下图所示： 此时先别设置安全域名，直接在本地启动Hexo服务，不停的刷新页面，便可以看到你想结果啦，就是这么的简单。
搭建过程中发现NexT的jiathis代码模板已过且没有uid的概念，另外统计代码的存放位置也是有问题的，fork后提交的pull请求，如有兴趣可以关注下：pull-1796
3.同时发布到多个Git服务器 因为选择了Gitee和Coding为博客的运行服务器，所以在发布时需要同时推送，参考如下：
# Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: coding: git@git.coding.net:lisenhui/lisenhui.git,master oschina: git@git.oschina.net:lisenhui/lisenhui.git,master 4.自定义域名绑定 除了在Git Pages服务商那里绑定自定义的域名外，我们还需要在站点中添加个名为CNAME的文件，内容为你想指向的域名。在此建议使用DNSPod做域名的解析，可精细指定不来源访问不同的服务(是不是有点分发的味道)，具体的操作可以参考官方/网上教程。
到此个人的博客站点便是搭建完成，效果演示如本站, 若是懒的配置，直接clone鄙人的博客项目即可(记得要把名字改掉呀,哈), 如下：
git clone https://git.oschina.net/lisenhui/my-hexo-blog.git 欢迎各位拍砖和鲜花实际上Hexo博客的搭建只需要如下几步：
npm install -g hexo-cli mkdir hexo-blog hexo init hexo-blog cd hexo-blog git clone https://github.com/iissnan/hexo-theme-next themes/next vi _config.yml (change theme: next) hexo g &amp;&amp; hexo s (打开浏览器输入: http://127.0.0.1:4000) 参考文章：
Hexo常用命令 leanCloud,实现文章阅读量统计 Hexo+Next主题博客提交百度谷歌收录 使用Hexo + Next搭建静态博客</content></entry><entry><title>Hexo blog Hello World</title><url>https://lisenhui.cn/2017/07/31/hexo-hello-world.html</url><categories><category>Hexo</category></categories><tags><tag>测试</tag><tag>学习</tag></tags><content type="html"> Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick Start Create a new post $ hexo new "My New Post" More info: Writing
Run server $ hexo server More info: Server
Generate static files $ hexo generate More info: Generating
Deploy to remote sites $ hexo deploy More info: Deployment</content></entry><entry><title>APIDoc自动生成接口文档</title><url>https://lisenhui.cn/2017/07/18/nodejs-apidoc-generator.html</url><categories><category>工具</category></categories><tags><tag>API</tag><tag>学习</tag></tags><content type="html"> 对于项目开发常见的前后端分离模式来说，中间在后端完成接口开发交付对接时，前端人员往往苦于没有接口文档会经常"跑去"骚扰后端人员，真是苦不堪言哪。要是此时有个文档化的说明那就轻松多啦，现在后端流行的文档生成利器有Swagger，它虽然方便，但是也有弊端得写在的后台的代码中，而且启动整个后台项目才能访问。或许有时还真不太方便的，另外就是项目初期要对接口做个规划也无法用这个方法，难道就没有别的办法了嘛？
最后在浩瀚的网络中还是找到个不错的工具——Nodejs APIDoc，非常的强大，支持当前流行的开发语言，如Java,PHP,JavaScript,Python,Ruby等等，下面就来简单的介绍下它的使用方法。
安装模块 前面的介绍中已经说了它是基于NodeJS环境，所以你必须先有个NodeJS环境，然后就是安装下APIDoc模块，参考命令如下：
npm install apidoc -g 工程配置文件 接下来创建个工程文件夹，并入个工程的配置文件，参考如下：
{ "name": "XXXX开放接口平台", "version": "1.0.1", "description": "XXXX开放接口平台，设计所有与第三方服务对接的接口服务。请注意所有的接口数据交互格式为JSON格式。", "title": "XXXX开放接口平台", "generator": { "name": "XXXX", "time": "2017-07-18 15:46:55", "url": "https://xxxx.com", "version": "1.0.1" } } 接口文档 所有相关的准备工作完成后，那么此时我们就需要来写关于接口描述的文档，这个具体要看你今后实际项目的开发语言，建议尽量选择相同的，在此我就以Java为示例，不需要具体的代码，只需填充代码注释部分的内容，参考如下：
hello-api.java
/** * @apiDefine xxxxx * * XXX 当前接口文档名称(一般就对接客户的名称) */ /** * @apiDefine Err400 * * @apiError {String} tranDate 发生交易的日期 * @apiError {String} tranTime 发生交易的时间 * @apiError {String} serviceId 机构代码(东吴提供) * @apiError {Number} resultCode 1,表示成功,0表示失败 * @apiError {String} resultComment 失败原因描述 * * @apiErrorExample Error400-Response: * HTTP/1.1 400 * { * "tranDate": "20170718", * "tranTime": "131223", * "serviceId": "xxxx", * "resultCode": 0, * "resultComment": "请求数据语法格式有误." * } */ /** * @apiDefine Suc200 * * @apiSuccess {String} tranDate 发生交易的日期 * @apiSuccess {String} tranTime 发生交易的时间 * @apiSuccess {String} serviceId 机构代码(东吴提供) * @apiSuccess {Number} resultCode 1,表示成功,0表示失败 * @apiSuccess {String} resultComment 失败原因描述 * * @apiSuccessExample Success-Response: * HTTP/1.1 200 * { * "tranDate": "20170718", * "tranTime": "131223", * "serviceId": "xxxx", * "resultCode": 1, * "resultComment": "Success" * } */ /** * @apiDefine AccessKey * * @apiHeader {String} access-key 加密密钥: 当前日期+指定字符串的32位MD5加密字符串. * * @apiHeaderExample {json} Header-Example: * { * "access-key": "cfa1fd55a89f45c9800120d6cbff0b33" * } */ /** * @api {PUT} /dwhealath/synccustomerinfo.do 同步客户基础信息 * @apiDescription 批量次同步客户的基础信息，建议每个批次不要大于1000条记录。 * * @apiVersion 1.0.1 * @apiName customer * @apiGroup dwHealth * * @apiUse AccessKey * * @apiParam {String} cusName 姓名 * @apiParam {String} cusSex 性别 * @apiParam {String} cusBirthday 生日 * @apiParam {String} cusIdType 证件类型 * @apiParam {String} cusIdNo 证件号码 * @apiParam {String} cusCompanyId 工作单位 * @apiParam {String} cusServItemNo 计划编号 * * @apiParamExample {json} Request-Example: * { * "serviceId": "xxxx", * "data": [ * { * "cusName": "张三", * "cusSex": "男", * "cusBirthday": "2017-07-18", * "cusIdType": "身份证", * "cusIdNo": "4419381788902217652", * "cusCompanyId": "1024", * "cusServItemNo": "201707181313132", * } * ...... * ] * } * * @apiUse Suc200 * * @apiUse Err400 * */ 生成接口文档 最后我们生成接口文档只需要一句简单的命令即可，如下：
apidoc -i apidoc/ -o apidoc/ i 工程所在的文件夹 o 接口文档输出文件夹 文档效果如下图所示：
常见问题 提示 error: Can not read: package.json, please check the format (e.g. missing comma). 解决方案：把文件另存为UTF-8格式，或是检查其它格式问题</content></entry><entry><title>Kylin集成Zeppelin展示数据</title><url>https://lisenhui.cn/2017/06/02/kylin-integrate-with-zeppelin.html</url><categories><category>Kylin</category></categories><tags><tag>大数据</tag><tag>Kylin</tag><tag>Zeppelin</tag></tags><content type="html"> 实际上kylin自带的WEB UI已经集成了建议的图形报表，有常见的线形，柱形及饼图，用于数据的初步展示是完全够用的。如果要更加丰富的展示，那可以考虑使用别的工具，现在就试试官方推荐的Apache Zeppelin。
打开Apache Zeppelin官方网站，选择下载**zeppelin-0.7.1-bin-netinst.tgz**，版本其它的插件可以后续再安装。下载并解压到你想要运行的目录，然后拷贝conf/zeppelin-site.xml.template为conf/zeppelin-site.xml 修改对应的绑定地址和商口号。接着就是安装kylin插件， 命令如下：
bin/install-interpreter.sh --name kylin --artifact org.apache.zeppelin:zeppelin-kylin:0.7.1 安装完成后使用如下命令启动zeppelin：
bin/zeppelin-daemon.sh start # stop 停止 至此就可以打开浏览器然后访问zeppelin的WEB UI， 如下图所示：
OK, 接下来就是创建与Kylin的连接，在Zeppelin中叫做Interpreter, 点击页面右上角的anonymous选择它如下图所示：
同样的点击右上角的Create按钮，参考下图填写的数据填写你的真实数据：
保存好后，点击左上角的Notebook&ndash;> + Create new note如下图所示：
把下面的SQL语句写入到notebook中：
select fact.part_dt, lookup.categ_lvl2_name, count(distinct seller_id) as sellers from kylin_sales fact inner join kylin_category_groupings lookup on fact.leaf_categ_id = lookup.leaf_categ_id and fact.lstg_site_id = lookup.site_id group by fact.part_dt, lookup.categ_lvl2_name order by fact.part_dt desc 点击右边的开始按钮即可完成查询，出来一个表格数据 ，然后选取你所需要的图形报表形式，数据便会自动的渲染，点击settings可以有更多的调整。
关于Zeppelin其它应用还需要慢慢了解，后续再跟进。
参考：
interpreter-installation kylin</content></entry><entry><title>Sqoop工具导入数据到Hive小记</title><url>https://lisenhui.cn/2017/05/24/sqoop-import-data-to-hive.html</url><categories><category>大数据</category></categories><tags><tag>Sqoop</tag><tag>Hive</tag><tag>大数据</tag></tags><content type="html"> 最近正在捣鼓构建数据仓库的事宜，正好有部分维度表的数据需要来自于RDBMS的数据，在HADOOP环境最流行的莫过于Apache的Sqoop工具，按官方的文档操作下来也很顺畅的，不过当要应用到业务场景上时问题便出现了。
在Hive上面创建了一个Dimension表并用ORC格式储存（关于Hive ORC存储的介绍参考Hive:ORC File Format存储格式详解），然后在执行Sqoop导入便会抛出下面的异常：
FAILED: SemanticException Unable to load data to destination table. Error: The file that you are trying to load does not match the file format of the destination table. 经过几番测试后发现，Sqoop默认导入的数据格式为TXTFILE，所以当建表时使用TXTFILE存储格式就能正常的导入数据，但这不是我们所想要的，又查看了一下文档，发现其在1.4.5版本后提供了一个hcatalog命令是可以支持ORC File Format，参考命令如下：
sqoop import --connect jdbc:mysql://master01:3306/data_pipeline --username dw --password-file hdfs:///user/hdfs/dw.txt --table dim_calendar --split-by ek_cal_id --compress --fields-terminated-by "," --lines-terminated-by "\n" --hcatalog-database default --hcatalog-table dim_calendar --map-column-hive cal_date=DATE,ts=TIMESTAMP --hcatalog-storage-stanza 'stored as orc tblproperties ("orc.compress"="SNAPPY")' 从上面命令可以看出后续可以自由的定义存储格式及压缩格式，不过这边还有个问题会有个告警，如下：
WARN hcat.SqoopHCatUtilities: Column cal_date had to be cast to a less precise type DATE in hcatalog WARN hcat.SqoopHCatUtilities: Column ts had to be cast to a less precise type TIMESTAMP in hcatalog 这个问题暂时没有办法解决，HIVE好像还支持这两种类型的数据格式，后面再跟进一下看看。
执行Sqoop命令时一下要记得切换到同时安装有Sqoop Client与Hive Client的集群机器上，不然就会出现数据导入失败的情况。
参考：
Sqoop使用手册 Hive:ORC File Format存储格式详解 Hive创建表时添加中文注释后乱码问题 SQOOP Import to Snappy ORC qoop Hive table import, Table dataType doesn&rsquo;t match with database</content></entry><entry><title>Supervisor介绍与使用</title><url>https://lisenhui.cn/2017/05/18/linux-daemon-supervisor.html</url><categories><category>Supervisor</category></categories><tags><tag>Supervisor</tag><tag>工具</tag><tag>Linux</tag></tags><content type="html"> 很多时候我们自己开发的或别的服务都没有后台的守护进程，那么进程很容易就会被不小心的杀死，此时就需要有个程序去监控和维护这些程序服务。网上搜罗了一番后发现Supervisor组件正好能实现我们想要的，同时还支持对这些程序的统一管理，Nice!
Supervisor is a client/server system that allows its users to monitor and control a number of processes on UNIX-like operating systems. 看完官方网站对Supervisor的定义描述，便立马觉得要实验一下。好在Linux系统中天生就是支持Python的，那么只要安装好PIP就可以得到你想要的一切。
1.安装 pip：
easy_install pip 2.安装 Supervisor:
pip install supervisor 3.配置文件
echo_supervisord_conf>/etc/supervisord.conf 3.1 配置文件详解
[unix_http_server] file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用 ;chmod=0700 ; socket 文件的 mode，默认是 0700 ;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=0.0.0.0:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 [supervisord] logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log logfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MB logfile_backups=10 ; 日志文件保留备份数量默认 10 loglevel=info ; 日志级别，默认 info，其它: debug,warn,trace pidfile=/tmp/supervisord.pid ; pid 文件 nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动 minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024 minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致 ;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件 [include] files = /etc/supervisor/*.conf ; 可以是 *.conf 或 *.ini 4.守护进程配置说明
[program:kafka] directory = /root/kafka_2.10-0.10.1.1/bin/ ; 程序的启动目录 command = kafka-server-start.sh /root/kafka_2.10-0.10.1.1/config/server.properties ; 启动命令，可以看出与手动在命令行启动的命令是一样的 autostart = true ; 在 supervisord 启动的时候也自动启动 startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了 autorestart = true ; 程序异常退出后自动重启 startretries = 3 ; 启动失败自动重试次数，默认是 3 user = root ; 用哪个用户启动 redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 false stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数 ; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile = /var/log/kafka-server.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH ; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 5.启动服务
supervisord -c /etc/supervisord.conf 6.用supervisorctl管理守护的进程
# all 可换成具体的进程名称 supervisorctl status all supervisorctl start all # 重新加载配置 supervisorctl reload 7.启用WEB界面
;[inet_http_server] ; HTTP 服务器，提供 web 管理界面 ;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性 ;username=user ; 登录管理后台的用户名 ;password=123 ; 登录管理后台的密码 然后在浏览器中输入： http://127.0.0.1:9001， 输入登录信息， 界面展现如下：
现在你可以尝试下杀死守护进程，看看它是不是又自动重启， 当然如果要是supervisord服务被杀死那么也就没戏啦。</content></entry><entry><title>发布jar到Maven时遭遇gpg签名失败</title><url>https://lisenhui.cn/2017/05/17/maven-deploy-center-sign-failed.html</url><categories><category>Maven</category></categories><tags><tag>Maven</tag><tag>工具</tag><tag>Mac</tag></tags><content type="html"> 有许久没维护自己开源的项目了，此次在修复BUG发布时遭遇失败，检查后发现原因是因为gpg签名失败，没办法换了MAC电脑有些操作不熟悉是有点郁闷的。
关于如何将自己的JAR共享到Maven中央仓库，网上有很多的资源，大家可以自行尝试一下，其实也不难的，完全没必要担心英语的问题。
分享一个别人整理的GitBook: 发布到中央仓库
[INFO] --- maven-gpg-plugin:1.6:sign (sign-artifacts) @ mpsdk4j --- gpg: 签名时失败： Inappropriate ioctl for device gpg: signing failed: Inappropriate ioctl for device 上面就是GPG在签名时遇到的问题，单纯从字面上来看是说对于此设备有个不适合的ioctl，不明白是何东西。最后一步步探究下来发现是因为管理GPG的服务器不能用的缘故，在网上找了个新的服务器重新上传如下：
gpg --keyserver hkp://pgp.mit.edu --send-keys DAB131AA5564DCF176 #如果不放心的话，可以使用下面的命令检查一下 gpg --keyserver hkp://pgp.mit.edu --recv-keys DAB131AA5564DCF176 好啦，重新打包release jar包， 很开心的看到了SUCCESS的结果，收工。</content></entry><entry><title>Github push失败：Could not resolve hostname</title><url>https://lisenhui.cn/2017/05/16/github-push-failed.html</url><categories><category>Git</category></categories><tags><tag>Git</tag><tag>GitHub</tag><tag>Mac</tag></tags><content type="html"> 平时最常用的git push命令突然间居然不可以用（错误日志如下），脑子首先蹦出的想法就是：难道Github又被墙了么！以前出现过类似这样的现象，需要通过指定hosts来加速访问。
git push 执行后返回的错误日志：
ssh: Could not resolve hostname github.com:elkan1788: nodename nor servname provided, or not known fatal: Could not read from remote repository. Please make sure you have the correct access rights 首先用最简单的SSH命令检测一下，结果如下：
ssh -T git@github.com Hi elkan1788! You've successfully authenticated, but GitHub does not provide shell access. ssh -T git@git.oschina.net Welcome to Git@OSC, 凡梦星尘! 那说明git sever都是正常的，那为何push会失败呢？ 网友方法都一一试过，像指定hosts, 更新ssh key，添加DNS: 8.8.8.8等等。最后没有办法暂时把ssh更换成https模式， 执行git push输入用户与密码提交成功。 可是根本的问题并没有解决，最后想要不重新clone项目试试，于是乎重新创建目录，clone项目修改文件提交，结果是成功了。
此时只能说是太诡异了，仔细回想下是否改动过配置呢？但确定是没有的，不过想起了上次编绎源码安装时更新了软件，难道是这个问题，输出git的版本如下：
git --version git version 2.11.0 (Apple Git-81) 果不其然git是被更新了，但目前没有找到问题的确切的根源，主要的解决办法就是重新clone项目，问题自行解决， 后续有更新再跟进下。</content></entry><entry><title>Zookeeper崩溃后无法加载事务日志</title><url>https://lisenhui.cn/2017/05/15/zookeeper-unload-data-exception.html</url><categories><category>Zookeeper</category></categories><tags><tag>Zookeeper</tag><tag>大数据</tag></tags><content type="html"> 今天在生产的HDP环境中，遇到一件非常诡异的事情。明明搭建了2台zookeeper集群，却是莫明其妙的不见了，而且HDP服务还不报错，认真的检查过环境还是没有找到异常的信息，真是说不明白了。
言归正传， 还是说说后面遇的问题吧： 生产环境zookeeper崩溃，查看日志发现是磁盘空间已经写满。起初以为是很简单的操作，删除无用的日志文件释放磁盘空间（这是不得不吐槽下HDP的日志文件是超多的，奈何生产环境又不敢不预留长些的时间），然后重启zookeeper满心欢喜的等待着服务恢复正常。然而这次没有看到成功的提示，异常不断各服务连接zookeeper都失败了。这时真的是郁闷了，空间明明已经是充足的。异常信息如下：
2017-05-15 11:02:24,421 - INFO [main:FileSnap@83] - Reading snapshot /hadoop/zookeeper/version-2/snapshot.5ff3bc 2017-05-15 11:02:26,492 - ERROR [main:Util@239] - Last transaction was partial. 2017-05-15 11:02:26,494 - ERROR [main:QuorumPeer@530] - Unable to load database on disk 网上一阵搜索，期待可以找到相关的案例分享，案例倒是找到了不过，那些只是遇到问题并没有完全解决， 案例如下：
ZOOKEEPER-1621 数据文件读取异常 此时真是有点无语了，在着手查看zookeeper的源码时，同时切换成百度搜索引擎查找案例(大家都比较喜欢用Google，你懂的)，没想到还真的找到解决办法了，网友分享的案例：
ZooKeeper启动报错Last transaction was partial. 解决方法 原文如下： ZooKeeper 在硬盘满后，无法再次启动，抛出Last transaction was partial. Bug见：https://issues.apache.org/jira/browse/ZOOKEEPER-1621 首先我的环境是单节点，ZooKeeper的版本是3.4.8。 因为是单节点，ZooKeeper无法启动影响非常大，多节点也有可能出现同时硬盘都写满的情况，如果问题在线上发生，后果不堪设想。 折腾了一下，发现，把ZooKeeper安装目录下的data/log/version-2下的，大小为0（异常的）日志，删除掉后，再重启 ，问题解决！ 检查了一下对应的目录就真的发现了一个大小为0的log文件，删除然后启动zookeeper， OK输出日志正常，通过zookeeper client连接查看数据恢复正常。终于悬着的心可以放下来了，不过之前那个zookeeper莫名的消失问题还是没有找到原因。此次的经验教训就是以后类似这些重要的目录一定要做热备份，在大数据环境中zookeeper的生要性可想而知，还好此次是有惊无险。</content></entry><entry><title>离线安装HDP2.6(1)-Ambari Server</title><url>https://lisenhui.cn/2017/04/17/offline-install-hdp-ambari-notes.html</url><categories><category>大数据</category></categories><tags><tag>大数据</tag><tag>HDP</tag></tags><content type="html"> 1.参考文档 FYI: HDP Install Documents
HDP Install Manual
2. 硬件环境 首先是要准备3台机器,安装最新的CentOS7.2，机器的配置参考要求如下：
CPU Memory Disk Remark 4核 26G 200G 主节点/1台 4核 16G 200G 从节点/2台 3. HDP安装文件 下载离线安装的文件：
File Name Download Link ambari-2.5.0.3 http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3/ambari-2.5.0.3-centos7.tar.gz HDP-2.6.0.3 http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/HDP-2.6.0.3-centos7-rpm.tar.gz HDP-UTILS-1.1.0.21 http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz 4. SSH免密登录 配置免密码登录，注意这里主要是指master机器登录到其它cluster机器。所以最好先给机器指定好特定的hostname标识分开，参考如下：
IP Host Name 192.168.1.1 test-hdp-master01 192.168.1.2 test-hdp-cluster01 192.168.1.3 test-hdp-cluster02 需要注意一点是，在CentOS7中过修改 /etc/hosts 文件已经无法实现机器名称的修改，需要使用新的命令： hostnamectl set-hostname test-hdp-master01
然后在master机器上使用ssh-keygen -t RSA 密令生成SSH密钥，再使用命令 ssh-copy-id -i ~/.ssh/id_rsa.pub root@test-hdp-cluster01 拷贝到其它两台cluster机器，最后使用SSH登录命令检查是否安装成功，同时把hostname，IP地址写入到每台机器的/etc/hosts文件里面。
5. 时间同步 安装NTP服务 （参考)
在Master机器上执行以下的命令安装并启动ntpd服务：
yum install ntp -y systemctl start ntpd 修改配置文件，允许同网段下面的机器同步时间。
vi /etc/ntp.conf # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # 找到这段配置，改写成如下的配置 restrict 192.168.51.0 mask 255.255.255.0 nomodify 在其它两台Cluster机器安装NTP客户端，执行命令如下：
yum install ntpdate -y crontab -e # 每分钟同步一次 */1 * * * * ntpdate -u 192.168.51.21 &amp;&amp; hwclock -w systemctl start crond.service 6. 配置YUM镜像 6.1 解压文件 将第2步中下载的三个文件解压
注意 HDP-UTIL是没根目录的，所以最好创建一个目录，解压好的目录结构如下：
[root@test-hdp-master01 hdp-download]# ll total 8676352 drwxr-xr-x 3 root root 20 Apr 25 16:03 ambari -rw-r--r-- 1 root root 1657013486 Apr 6 11:14 ambari-2.5.0.3-centos7.tar.gz drwxr-xr-x 3 1001 users 20 Apr 3 08:58 HDP -rw-r--r-- 1 root root 6356134913 Apr 3 09:25 HDP-2.6.0.3-centos7-rpm.tar.gz drwxr-xr-x 21 root root 4096 Apr 25 16:16 HDP-UTILS -rw-r--r-- 1 root root 871424874 Mar 31 03:11 HDP-UTILS-1.1.0.21-centos7.tar.gz 6.2 启动HTTP服务 启动HTTPServer服务，这里不用安装Apache直接用下面的Python命令启动即可：
python -m SimpleHTTPServer 88 6.3 修改Repo文件 找到6.1解压目录下面的ambari.repo与hdp.repo文件，将里面的baseurl,gpgkey更新为本地HTTP服务地址即可，如下：
ambari.repo
#VERSION_NUMBER=2.5.0.3-7 [ambari-2.5.0.3] name=ambari Version - ambari-2.5.0.3 # baseurl=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3 baseurl=http://192.168.51.21:88/ambari/centos7 gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.51.21:88/ambari/centos7/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 hdp.repo
#VERSION_NUMBER=2.6.0.3-8 [HDP-2.6.0.3] name=HDP Version - HDP-2.6.0.3 # baseurl=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3 baseurl=http://192.168.1.1:88/HDP/centos7 gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.1.1:88/HDP/centos7/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 [HDP-UTILS-1.1.0.21] name=HDP-UTILS Version - HDP-UTILS-1.1.0.21 # baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7 baseurl=http://192.168.1.1:88/HDP-UTILS gpgcheck=1 # gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.0.3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins gpgkey=http://192.168.1.1:88/HDP-UTILS/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 6.3 安装ambari-server 在Master机器上安装ambari-server服务
yum install ambari-server 7. 配置JDK环境 将下载好的JDK压缩包解压到/user/share/jdk目录下，然后再编辑/etc/profile文件在末尾加入下面的代码：
export JAVA_HOME=/usr/share/jdk/jdk1.8.0_131 export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar export PATH=$JAVA_HOME/bin:$PATH 最后命令source /etc/profile编绎一下文件即可，在其它两台Cluster上面重复此操作，记得用java -version验证是否安装成功。
8. 安装MySQL数据库 参考
下载mysql源安装包并安装
wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm yum localinstall mysql57-community-release-el7-8.noarch.rpm #检查mysql源是否安装成功 yum repolist enabled | grep "mysql.*-community.*" mysql-connectors-community/x86_64 MySQL Connectors Community 33 mysql-tools-community/x86_64 MySQL Tools Community 47 mysql57-community/x86_64 MySQL 5.7 Community Server 187 yum install mysql-community-server -y 在安装日志找到默认密码并修改
grep 'temporary password' /var/log/mysqld.log 2017-04-25T23:51:03.380340Z 1 [Note] A temporary password is generated for root@localhost: dCAdHOM+H4z% ALTER USER 'root'@'localhost' IDENTIFIED BY 'dCAdHOM+H4zz%'; UPDATE user SET host='%' WHERE user='root'; CREATE USER 'ambari'@'192.168.51.%' IDENTIFIED BY '1wVhZ7nd@T'; GRANT ALL PRIVILEGES ON hive.* TO 'hive'@'192.168.51.%' IDENTIFIED BY '1wVhZ7nd@T' FLUSH PRIVILEGES; 修改默认字符集
vi /etc/my.cnf # 在mysqld选项下面增加 character_set_server=utf8 init_connect='SET NAMES utf8' 设置开机启动
systemctl enable mysqld systemctl daemon-reload #启动mysql systemctl start mysqld 9. 安装mysql connector jar文件 yum install yum-utils yumdownloader mysql-connector-java rpm -ivh mysql-connector-java-5.1.25-3.el7.noarch.rpm --force --nodeps ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 10. 设置Ambari Server Setup [root@test-hdp-master01 hdp-download]# ambari-server setup -j /usr/share/jdk/jdk1.8.0_131 Using python /usr/bin/python Setup ambari-server Checking SELinux... SELinux status is 'disabled' Customize user account for ambari-server daemon [y/n](n)? y Enter user account for ambari-server daemon (root): Adjusting ambari-server permissions and ownership... Checking firewall status... Checking JDK... WARNING: JAVA_HOME /usr/share/jdk/jdk1.8.0_131 must be valid on ALL hosts WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts. Completing setup... Configuring database... Enter advanced database configuration [y/n](n)? y Configuring database... ============================================================================== Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL / MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere [7] - BDB ============================================================================== Enter choice (3): 3 Hostname (localhost): test-hdp-master01 Port (3306): Database name (ambari): Username (ambari): Enter Database Password (sDgu-5H1sW): Configuring ambari database... Copying JDBC drivers to server resources... Configuring remote database connection properties... WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql Proceed with configuring remote database connection properties [y/n](y)? y Extracting system views... ............ Adjusting ambari-server permissions and ownership... Ambari Server 'setup' completed successfully. 注意在选择数据库会要输入数据库名，用户名，密码等信息，请保存好这些信息，后面在创建数据库时有用的
11. 创建元数据库 CREATEDATABASE`ambari`CHARACTERSETutf8COLLATEutf8_general_ci;CREATEUSER'ambari'@'localhost'IDENTIFIEDBY'sDgu-5H1sW'GRANTUSAGEON`ambari`.*TO'ambari'@'localhost'IDENTIFIEDBY'sDgu-5H1sW'FLUSHPRIVILEGES;USE'ambari'GO;source/var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql12. 启动Ambari Server 使用命令ambari-server start启动，然后打开浏览器输入http://192.168.1.1:8080/，便可以看到Ambari的登录界面，输入默认用户密码登录，接着就可以安装Hadoop组件服务啦。
13. 安装过程中的问题记录 13.1 HostName指定问题 在这个过程中，如果会出现ambari-server的hostname无法指定，目前通过直接改写代码实现。
vi /usr/lib/python2.6/site-packages/ambari_server/setupAgent.py # 把315行代码更新如下 # hostname = args[2] hostname = "test-hdp-master01" 13.2 MySQL连接失败 在安装时测试MySQL连接失败，与上次面的问题差不多，也只能是修改下代码：
# 注意这里指你安装Hive, oozie服务的机器 vi /var/lib/ambari-agent/cache/custom_actions/scripts/check_host.py # 把279行代码更新如下 # jdk_location = config['commandParams']['jdk_location'] jdk_location = 'http://' + ambari_server_hostname + ':8080/resources/' 在安装各个服务时如果提示无法下载文件，那么也要修改代码，这边主要是发现Hive的安装会出现：
# 注意这里指你安装Hive服务的机器 vi /usr/lib/python2.6/site-packages/resource_management/core/source.py # 把169行的代码更新如下： # self.url = self.name self.url = self.name.replace('localhost','test-hdp-master01') 14. 卸载HDP服务 参考官方文档： Uninstall</content></entry><entry><title>Linux使用SSH免密码登录</title><url>https://lisenhui.cn/2016/05/29/ssh-login-without-password.html</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>SSH</tag></tags><content type="html"> 现在分布式集群非常的流行, 经常在不同的机器上面切换来回那是家常便饭. 如果每次切换都需要输入用户名与密码, 那就是要崩溃的节奏啊. 好在SSH-KEY给我们提供了便利, 只要在master生成一个PUB_KEY, 然后拷贝到clusters中, 以后便可以直接使用ssh hostname即能快速,方便的切换到需要操作的机器上面.
先说下机器的环境:
2台服务器均为Centos 6.7 x86_64 系统
主节点master, IP地址: 192.168.8.200
从节点cluster01, IP地址: 192.168.8.201
下面首先在主节点上生成一个SSH-KEY, 在终端输入ssh-keygen -t rsa, 这里使用默认的存放的目录, 无密码, 连续按2次回车键即可, 如下图所示:
然后将生成的PUB_KEY文件, 使用cat管道命令输出名称为authorized_keys的文件, 再用scp命令拷贝一份到节点服务器上面(此时是要输入密码的), 如下图所示:
如无法执行scp命令, 请执行安装命令: yum install -y openssh-clients
登录节点服务器, 在用户根目录下执行下面的命令:
chmod 700 .ssh/ chmod 600 .ssh/authorized_keys 那么到这一步我们便可以实现SSH免密码登录的功能. 回到主节点服务器, 用ssh hostname就可以切换到想到操作的节点机器上面, Good Luck.
注意:
authorized_keys 文件一定要在主节点服务器上生成, 不然是无效的, 即拷贝了PUB_KEY文件到节点服务器也仍是需要密码登录.
如果是比较新的sshd, 可以用ssh-copy-id hostname的命令快捷的实现上面的步骤, 不过记得要先安装openssh-clients.
参考:
Linux下SSH免密码登录 Linux教程:SSH免密码登录的方法 ssh设置免密码登陆仍然需要密码 SSH免密码登录详解 原理:
为了更好的理解SSH免密码登录原理，我们先来说说SSH的安全验证，SSH采用的是”非对称密钥系统”，即耳熟能详的公钥私钥加密系统，其安全验证又分为两种级别。
基于口令的安全验证 这种方式使用用户名密码进行联机登录，一般情况下我们使用的都是这种方式。整个过程大致如下：&raquo; （1）客户端发起连接请求。
（2）远程主机收到用户的登录请求，把自己的公钥发给客户端。
（3）客户端接收远程主机的公钥，然后使用远程主机的公钥加密登录密码，紧接着将加密后的登录密码连同自己的公钥一并发送给远程主机。
（4）远程主机接收客户端的公钥及加密后的登录密码，用自己的私钥解密收到的登录密码，如果密码正确则允许登录，到此为止双方彼此拥有了对方的公钥，开始双向加密解密。
PS：当网络中有另一台冒牌服务器冒充远程主机时，客户端的连接请求被服务器B拦截，服务器B将自己的公钥发送给客户端，客户端就会将密码加密后发送给冒牌服务器，冒牌服务器就可以拿自己的私钥获取到密码，然后为所欲为。因此当第一次链接远程主机时，在上述步骤的第（3）步中，会提示您当前远程主机的”公钥指纹”，以确认远程主机是否是正版的远程主机，如果选择继续后就可以输入密码进行登录了，当远程的主机接受以后，该台服务器的公钥就会保存到 ~/.ssh/known_hosts文件中。
基于密匙的安全验证 这种方式你需要在当前用户家目录下为自己创建一对密匙，并把公匙放在需要登录的服务器上。当你要连接到服务器上时，客户端就会向服务器请求使用密匙进行安全验证。服务器收到请求之后，会在该服务器上你所请求登录的用户的家目录下寻找你的公匙，然后与你发送过来的公匙进行比较。如果两个密匙一致，服务器就用该公匙加密“质询”并把它发送给客户端。客户端收到“质询”之后用自己的私匙解密再把它发送给服务器。与第一种级别相比，第二种级别不需要在网络上传送口令。
PS：简单来说，就是将客户端的公钥放到服务器上，那么客户端就可以免密码登录服务器了，那么客户端的公钥应该放到服务器上哪个地方呢？默认为你要登录的用户的家目录下的 .ssh 目录下的 authorized_keys 文件中（即：~/.ssh/authorized_keys）。</content></entry><entry><title>Git 操作命令收集</title><url>https://lisenhui.cn/2016/01/29/git-commands-collect.html</url><categories><category>Git</category></categories><tags><tag>Linux</tag><tag>Git</tag></tags><content type="html"> 都说好性不如烂笔头, 一点也没有错呀. 虽然学习Git已经有1个多年头, 但是有些时候那比较少用的命令总是一时想不起来.所以还是决定把它写到blog里面, 不仅把经验分享出去, 而且也便于自己查找, 此博文会持续累加.
Git命令别名(非常实用) git config --global alias.co checkout 解读: 用co替代checkout, 除此之外, 还可以把一些组合的命令用别名设置, 例如:
Alias Name Description co checkout ci commit br brach l log &ndash;oneline 回退到首次提交(估计很少人会遇到) git update-ref -d HEAD Tag操作
查看标签
git tag -l 创建标签 git tag -a 1.0.1-Release -m "Release 1.0.1 version" 删除标签 git tag -d 1.0.1-Release 远程推送 git push --tag 远程删除 git push origin :refs/tags/1.0.1-Release Git学习推荐:
廖雪峰-Git教程</content></entry><entry><title>mpsdk4j的点滴记录--MPAccount</title><url>https://lisenhui.cn/2016/01/23/mpsdk4j-intro-mapaccount.html</url><categories><category>MPSDK4J</category></categories><tags><tag>MPSDK4J</tag><tag>微信</tag></tags><content type="html"> mpsdk4j是在实际的生产项目中抽离出来的开源分享项目,它的成长至今也算是有不少的经历吧, 最近一直忙于工作与生活上的事情疏忽了对它的关心. 自去年下决心对它重构并建立了QQ交流群(486192816)后, 逐渐的有不业界朋友前来关注, 在此非常感谢他们的支持. 都说用过方知其好, 可实际情况确不是这么乐观呀,在大家的使用过程中发现mpsdk4j有不少欠缺与不足的地方. 之前一直想在元旦发布的2.b.1版本也拖延至今还没有交工, 在此对大家说声抱歉, 以后定会嘉勉.下面还是先进入此次的主题&ndash;初识mpsdk4j之MPAccount. (注: 对于有微信开发基础与项目经验的可略过)
mpsdk4j自发布之时起的目标就是要做到原生态,简单易用. 不过在实际的交流过程中发现一个普遍的现象, 就是对初次接触微信开发的朋友来说,mpsdk4j的使用还是有点难(这也是为何要写这一篇博文的原因之一). 那么接下来我们就先简单的认识下微信公众平台开的所需要的元素, 以及它们与mpsdk4j之的映射关系.
微信公众号属性 序号 属性 示例 备注 1 公众号原始ID gh_20e50b3b4r9u 以gh_开头的(不明白其含义) 2 公众号昵称 mpsdk4j 用户自定义的公众号别名 3 用户唯一凭证(应用ID) wxa822bd879532187 以字母wx开头的,其含义大概是微信的拼音首字母 4 用户唯一凭证密钥(应用密钥) 613d3ce897hgf71a875d1342c8325f3d 32位的随机字符串 5 AES 加解密密钥 JwAsfZH4p9iuuvfxjry6cLtlOgZAd853kJQ5hNv5OI4 43位的随机字符串 6 开发者服务令牌 weixindev 用户接入微信开发者服务时的自定义令牌 7 公众号类型 S D: 订阅号, S: 服务号, E: 企业号 (预留字段) 8 是否认证 true true: 通过认证, false: 未通过认证 (同上也是预留字段) mpsdk4j中的代码映射关系 那么在mpsdk4j中我设计了一个对象, 位于io.github.elkan1788.mpsdk4j.vo包中其名字叫MPAccount, 直译过来是微信公众号的意思. 它将上面的8个公众号属性对应的代码如下:
/** * 微信公众号信息 * * @author 凡梦星尘(elkan1788@gmail.com) * @since 2.0 */ public class MPAccount { /** * 公众号原始ID */ private String mpId; /** * 公众号昵称 */ private String nickName; /** * 应用Id */ private String appId; /** * 应用密钥 */ private String appSecret; /** * 令牌 */ private String token; /** * AES安全加密密钥 */ private String AESKey; /** * 公众号类型 * D:订阅号 * E:企业号 * S:服务号 */ private String mpType; /** * 是否认证 */ private boolean pass; ...... } 有过微信开发经验的朋友, 都不难看出这些属性都是微信公众号必备的, 前面6个属性是可以微信公众号管理平台上直观的看到, 后面2个属性是从中经验中吸取提炼出来的, 在后面的许多开发中有使用的需求. 比如在调用微信的语音识别接口时就是得先了解当前公众号是否通过认证, 只有认证成功的公众号才有权限使用语音识别接口. 在实际的项目经验中, 你直接把此类设计成一个数据库表用来管理微信公众号信息.
或许你会觉得看完这些文章并没有太大的收获, 那不要紧, 你可以把它收藏起来, 当作是文档工具使用. 哪天你在开发的时候不记得了其中某个属性的含义, 可以倒回头来再拾起. 如有更好的建议或是意见, 可以在下面回复.
参考:
接入指南 消息加密</content></entry><entry><title>MapDB 同步读写示例</title><url>https://lisenhui.cn/2016/01/19/mapdb-write-read-sync.html</url><categories><category>内存数据库</category></categories><tags><tag>Java</tag><tag>MapDB</tag><tag>内存数据库</tag></tags><content type="html"> MapDB 是一个快速、易用的嵌入式Java数据库引擎. 最主要的特点之一就是支持磁盘存储,直接把内存中的Hash Map同步写入到磁盘. 另外特别惊喜的是它支持ACID事务,MVCC隔离, 且有全职的开发者支持.
看完官方的文档与示例后,基本上可以确定它符合业务场景的使用要求.另外发现官方正在重构3.x的版本, 但应该不会这么快发布吧.用google搜索了下关于MapDB的使用案例, 也不是很多. 可能是本来官方的文档就齐全有关吧,API也不复杂,跟着官方的文档走一遍就可以上手了.
动手测试了简单的示例后, 突然冒出一个疑问, 如何实现同时操作磁盘上的一个数据库, 以及同一个HashMap呢? 这里需要明白的, MapDB存储到磁盘上的数据库文件,并非只是存放了一个HashMap, 这有点类似数据库里可以有多张表的概念相同. 那么数据库是可以支持多连接的, MapDB是否也同样支持呢?(理想确实很丰满,但现实太骨感了!)
初步检验的结果是, MapDB并不支持同时访问磁盘上的同一文件. 那么也就是只能创建一个长连接, 直到业务功能处理完成再关闭它. 幸运的是它支持对已经存在或是运行中的同一个HashMap进行读写操作. 下面来看看简单的示例代码:
import org.mapdb.BTreeMap; import org.mapdb.DB; import org.mapdb.DBMaker; import org.testng.annotations.AfterTest; import org.testng.annotations.BeforeTest; import org.testng.annotations.Test; import java.io.File; import java.util.Map; import java.util.Random; import java.util.SortedMap; import static org.testng.Assert.*; /** * MapDB 测试 * * @author 凡梦星尘(elkan1788@gmail.com) * @since 2016.1.19 */ public class MapDBTest { private DB diskDB; Map&lt;Integer, String> data; @BeforeTest public void init() { // 文件名字可以自己定义 File dbFile = new File("D:/mapdb.data"); // DB有且只打开一次连接 diskDB = DBMaker.fileDB(dbFile) // 很是好奇,关闭锁定,还是不支持多事务访问同一个数据库文件 .fileLockDisable() // 最好开启,在程度异常或JVM关闭可正常关闭数据库 // 有过一次无法访问未关闭数据库文件的异常 .closeOnJvmShutdown() // 如果不需要回滚的可以关闭,提高读写效率 .transactionDisable() // 这里测试所没不保留磁盘文件 .deleteFilesAfterClose() // 这里没有找到读取的API,或者就是不支持多连接的吧 .make(); } @AfterTest public void destroy() { assertTrue(!data.isEmpty()); // 本应该是99才对,但会合并内存中其它数据 Map&lt;Integer, String> temp = diskDB.treeMap("sort_mapdb"); assertEquals(temp.size(), 100); // 这里需要注意下,有可能make成功的数据库也是关闭的 // 如果不做检查的话,可能抛出:IllegalAccessError("DB was already closed") if (diskDB.isClosed()) { diskDB.isClosed(); } } @Test(invocationCount = 10) public void testSyncWrite() throws Exception { // 支持多种类型Map,如B+ tree, sort等等 // 但value貌似支持引用类型, 不支持Object, 可能是 // 跟序列化到磁盘存储有关 data = diskDB.treeMapCreate("nice_mapdb") // 开启快速计数器 .counterEnable() // 这步很关键,如果不带get,那么就只是make,无法支持多连接 .makeOrGet(); int len = 99; int ran = new Random().nextInt(100)+1; while (--len >= 0) { data.put(len * ran, "value-"+len * ran); } assertFalse(data.isEmpty()); } @Test(invocationCount = 10) public void testReadAndDel() throws Exception { data = diskDB.treeMapCreate("nice_mapdb") .counterEnable() .makeOrGet(); if (!data.isEmpty()) { for (Integer key : data.keySet()) { if (key % 2 == 0 || key % 5 == 0) { data.remove(key); } } assertTrue(data.size() > 0); } } @Test public void testOtherMap() throws Exception { SortedMap&lt;Integer, String> data = diskDB.treeMapCreate("sort_mapdb") .counterEnable() .makeOrGet(); int len = 99; while (--len >= 0) { data.put(len, "sorted-"+len); } assertNotNull(data); // 创建另一个map BTreeMap&lt;Integer, String> btree = diskDB.treeMapCreate("sort_mapdb2") .counterEnable() .makeOrGet(); // 很是奇怪, 为何这里的name没有效果, 会自动合并到同时一时内存所有treeMap中 SortedMap&lt;Integer, String> tree = diskDB.treeMap("sort_mapdb1"); tree.put(100, "sorted-100"); btree.put(100, "sorted-101"); assertEquals(tree.get(100), "sorted-100"); assertEquals(data.get(100), "sorted-100"); } } 在这里没有详细的探讨关于MapDB是如何实现与磁盘持久化同步, 直接使用官方默认的值, 当然你也可以自己配置读写同步的心跳时间间隔. 在测试的过程观察发现, MapDB在创建磁盘的数据库文件时, 初始化大小写为2MB, 然后在同步内存数据时, 会先产生出一个临时文件, 当这个临时文件达到一定大小时就会合并到主体数据库文件. 至于其它的功能和代码中的疑问, 有待继续观察, 欢迎共同交流.
参考资料:
MapDB 官网 官方示例 MapDB实现分析</content></entry><entry><title>Redis 安装与配置</title><url>https://lisenhui.cn/2015/06/29/redis-install-settings.html</url><categories><category>Redis</category></categories><tags><tag>缓存</tag><tag>Redis</tag></tags><content type="html"> Redis 是一款依据BSD开源协议发行的高性能Key-Value存储系统（cache and store）。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。 更多介绍
系统环境: Linux 3.10.0-229.el7.x86_64 x86_64 x86_64 x86_64 GNU/Linux(Centos7.1)
1.下载
$ wget http://download.redis.io/releases/redis-3.0.1.tar.gz 解压安装 $ tar -zxf redis-3.0.1.tar.gz $ cd ./redis-3.0.1 $ make &amp;&amp; make install 配置Redis服务 $ cp ./redis-3.0.1/utils/redis_init_script /etc/rc.d/init.d/redis $ mkdir P /etc/redis $ cp ./redis-3.0.1/redis.conf /etc/reddis/6379.conf 启动Redis $ service redis start $ ps -ef|grep redis $ root 8687 1 0 12:06 ? 00:00:00 /usr/local/bin/redis-server *:6379 redis.conf参数说明 daemonize：是否以后台daemon方式运行
pidfile：pid文件位置
port：监听的端口号
timeout：请求超时时间
loglevel：log信息级别
logfile：log文件位置
databases：开启数据库的数量
save * ：保存快照的频率，第一个表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。
rdbcompression：是否使用压缩
dbfilename：数据快照文件名（只是文件名，不包括目录）
dir：数据快照的保存目录（这个是目录）
appendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。
appendfsync：appendonlylog如何同步到磁盘（三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步）</content></entry><entry><title>Nutz源码Jdoc在IDE中补全提示时出现乱码解决办法</title><url>https://lisenhui.cn/2012/04/20/nutz-jdoc-chinese.html</url><categories><category>Nutz</category></categories><tags><tag>Java</tag><tag>Nutz</tag></tags><content type="html"> 接触Nutz也有一段时间，随着对它使用的不断深入了解，才越发觉它的强悍与作者的设计巧妙，特别喜欢它那个JUnit测试报告，而且更新的速度也挺快的，到现在的1.b.44版本，ssh所拥有的功能可以说它也已经完全具备了。对于程序员来说学习一种新技术最快捷的办法就是Demo+API，这两样也是必备之需哪。Nutz在这方面做的也是相当的不错，比如在Demo方面有人贡献出了整个CMS的源码(非常感谢作者的分享哪，从里面学习了不少知识)，API方面提供了常见的CHM格式和JAR包。不过这个JAR的API在实现应用中却是出了点小问题，下面就来详细说说。
我的开发环境：
操作系统：Window7
Java虚拟机：JDK1.7
IDE工具：Netbeans7.1
项目编码格式：UTF-8
用Netbeans创建一个简单的WEB工程，把从GOOGLE CODE下载来的Nutz相关文件里面抽取出开发所必须的创建了一个新的库引用，这些操作和显示都正常，但当用代码自动补全时，发现了个问题，代码补全出来的JDOC居然是乱码的，如下图所示：
咦，这是怎么回事呢？？重新检查了自己的工程编码属性，确定是UTF-8没有错哪，如下图所示：
试着打开源码查看，却是得到提示信息说“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？”
难道说Nutz生成JDOC时使用的是GBK编码来的，看来只好连接GitHub库下载个库看看。下载下来查看工程的编码格式也是UTF-8，这就奇怪了&ndash;乱码从何产生呢？？看来只好自己生成个JDOC看看了，在UTF-8环境中生成JDOC要注意编码格式的设置，如下图所示，
生成好JDOC后，直接修改Netbeans库的源码和JDOC连接，打开创建的工程使用代码自动补全提示一切正常.
问题算是解决了，不过引起这个问题的原因还真得思考下，编码格式的不同所造成的影响还真是郁闷哪。上面提到在没有修改前打开源码提示信息“无法使用GBK编码格式安全地打开该文件，是否要继续打开它？” 按照信息所描述是不是将Nutz的源码修改成GBK编码格式也可以呢？于是写了个编码格式轮换输出小程序测试了下，结果说明猜想是正确的，呵~
其实这个小程序不单只是可以转换Nutz的源码，它还可以转换任何项目的编码格式(仅支持JAVA文件)，注意是由UTF-8转换成GBK编码格式哦，那么接下来就慢慢体验下Nutz给你所带来的“美妙体验”吧，呵~
PS: 示例源下载</content></entry><entry><title>Java程序与RSR232串口通讯小练手</title><url>https://lisenhui.cn/2012/03/24/java-hard-rsr232.html</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>RSR232</tag></tags><content type="html"> 一直以来都是在学习J2EE方面的应用系统开发，从未想过用JAVA来编写硬件交互程序，不过自己就是喜欢尝试一些未曾接触的新东西。在网上搜索了些资源，了解到JAVA写串口通讯的还是蛮多的，那么便着手准备开发调试环境。软件程序开发环境搭建不成问题，可这硬件环境就有点犯难啦。更何况自己用的是笔记本哪来的串口呀，再说要是真拿这串口硬件来自己也不会弄，随即想到了虚拟机，觉得这东西应该也有虚拟的吧，果真跟自己的猜测一样还真有这东西，顺便也下载了个串口小助手做为调试之用。
下面就先看看软件环境的搭建：
下载comm.jar、win32com.dll和javax.comm.properties。 (附件提供下载) 介绍：comm.jar提供了通讯用的java API，win32com.dll提供了供comm.jar调用的本地驱动接口，javax.comm.properties是这个驱动的类配置文件 拷贝javacomm.jar到X:\jre\lib\ext目录下面; 拷贝javax.comm.properties到X:\jre\lib目录下面; 拷贝win32com.dll到X:\jre\bin目录下面; 更新下IDE里面的JDK环境，如下图： 接着是硬件虚拟环境安装虚拟串口，这里我用的是VSPD6.0(附件提供下载)，安装好后启动VSPD添加我们所需要的端口，注意这里是按组的方式添加的，例如COM1和COM2是一组同时添加，以此类推。
所有环境都准备好后，先来简单认识下comm.jar的内容。单从comm API的javadoc来看，SUM提供给我们的只有区区以下13个类或接口，具体如下：
javax.comm.CommDriver javax.comm.CommPort javax.comm.ParallelPort javax.comm.SerialPort javax.comm.CommPortIdentifier javax.comm.CommPortOwnershipListener javax.comm.ParallelPortEvent javax.comm.SerialPortEvent javax.comm.ParallelPortEventListener (extends java.util.EventListener) javax.comm.SerialPortEventListener (extends java.util.EventListener) javax.comm.NoSuchPortException javax.comm.PortInUseException javax.comm.UnsupportedCommOperationException 这些类和接口命名一看便知其意，就不做一一介绍啦，可以到官网或网上找到更详细的信息。下面先测试下所搭建的环境是否可用，主要代码如下：
Enumeration&lt;?> en = CommPortIdentifier.getPortIdentifiers(); CommPortIdentifier portId; while (en.hasMoreElements()) { portId = (CommPortIdentifier) en.nextElement(); // 如果端口类型是串口，则打印出其端口信息 if (portId.getPortType() == CommPortIdentifier.PORT_SERIAL) { System.out.println(portId.getName()); } } 运行代码后，控制台有输出正确的端口(如下图)，说明所有环境正常可进行下步工作，否则请检查。
最后要解决的就是与串口数据交互的问题。在这个问题上，最主要的难点就是数据读取，因为我们不知道端口什么时候会有数据到来，也不知数据长度如何。通常，串口通信应用程序有两种模式，一种是实现SerialPortEventListener接口，监听各种串口事件并作相应处理；另一种就是建立一个独立的接收线程专门负责数据的接收。参考众多老前辈的代码后，下面就采用第一种方式写了个简单的助手程序，具体的实现请看详细代码，如下：
package com.elkan1788.view; import java.awt.BorderLayout; import java.awt.Button; import java.awt.Color; import java.awt.Font; import java.awt.GridLayout; import java.awt.Image; import java.awt.TextArea; import java.awt.TextField; import java.awt.event.ActionEvent; import java.awt.event.ActionListener; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.util.ArrayList; import java.util.Enumeration; import java.util.List; import java.util.TooManyListenersException; import javax.comm.CommPortIdentifier; import javax.comm.NoSuchPortException; import javax.comm.PortInUseException; import javax.comm.SerialPort; import javax.comm.SerialPortEvent; import javax.comm.SerialPortEventListener; import javax.comm.UnsupportedCommOperationException; import javax.imageio.ImageIO; import javax.swing.JComboBox; import javax.swing.JFrame; import javax.swing.JLabel; import javax.swing.JOptionPane; import javax.swing.JPanel; import javax.swing.SwingConstants; import javax.swing.border.EmptyBorder; public class JavaRs232 extends JFrame implements ActionListener, SerialPortEventListener { /** * JDK Serial Version UID */ private static final long serialVersionUID = -7270865686330790103L; protected int WIN_WIDTH = 380; protected int WIN_HEIGHT = 300; private JComboBox&lt;?> portCombox, rateCombox, dataCombox, stopCombox, parityCombox; private Button openPortBtn, closePortBtn, sendMsgBtn; private TextField sendTf; private TextArea readTa; private JLabel statusLb; private String portname, rate, data, stop, parity; protected CommPortIdentifier portId; protected Enumeration&lt;?> ports; protected List&lt;String> portList; protected SerialPort serialPort; protected OutputStream outputStream = null; protected InputStream inputStream = null; protected String mesg; protected int sendCount, reciveCount; /** * 默认构造函数 */ public JavaRs232() { super("Java RS-232串口通信测试程序 凡梦星尘"); setSize(WIN_WIDTH, WIN_HEIGHT); setLocationRelativeTo(null); Image icon = null; try { icon = ImageIO.read(JavaRs232.class.getResourceAsStream("/res/rs232.png")); } catch (IOException e) { showErrMesgbox(e.getMessage()); } setIconImage(icon); setResizable(false); scanPorts(); initComponents(); setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); setVisible(true); } /** * 初始化各UI组件 * @since 2012-3-22 下午11:56:39 */ public void initComponents() { // 共用常量 Font lbFont = new Font("微软雅黑", Font.TRUETYPE_FONT, 14); // 创建左边面板 JPanel northPane = new JPanel(); northPane.setLayout(new GridLayout(1, 1)); // 设置左边面板各组件 JPanel leftPane = new JPanel(); leftPane.setOpaque(false); leftPane.setLayout(new GridLayout(3,2)); JLabel portnameLb = new JLabel("串口号："); portnameLb.setFont(lbFont); portnameLb.setHorizontalAlignment(SwingConstants.RIGHT); portCombox = new JComboBox&lt;String>((String [])portList.toArray(new String[0])); portCombox.addActionListener(this); JLabel databitsLb = new JLabel("数据位："); databitsLb.setFont(lbFont); databitsLb.setHorizontalAlignment(SwingConstants.RIGHT); dataCombox = new JComboBox&lt;Integer>(new Integer[]{5, 6, 7, 8}); dataCombox.setSelectedIndex(3); dataCombox.addActionListener(this); JLabel parityLb = new JLabel("校验位："); parityLb.setFont(lbFont); parityLb.setHorizontalAlignment(SwingConstants.RIGHT); parityCombox = new JComboBox&lt;String>(new String[]{"NONE","ODD","EVEN","MARK","SPACE"}); parityCombox.addActionListener(this); // 添加组件至面板 leftPane.add(portnameLb); leftPane.add(portCombox); leftPane.add(databitsLb); leftPane.add(dataCombox); leftPane.add(parityLb); leftPane.add(parityCombox); //创建右边面板 JPanel rightPane = new JPanel(); rightPane.setLayout(new GridLayout(3,2)); // 设置右边面板各组件 JLabel baudrateLb = new JLabel("波特率："); baudrateLb.setFont(lbFont); baudrateLb.setHorizontalAlignment(SwingConstants.RIGHT); rateCombox = new JComboBox&lt;Integer>(new Integer[]{2400,4800,9600,14400,19200,38400,56000}); rateCombox.setSelectedIndex(2); rateCombox.addActionListener(this); JLabel stopbitsLb = new JLabel("停止位："); stopbitsLb.setFont(lbFont); stopbitsLb.setHorizontalAlignment(SwingConstants.RIGHT); stopCombox = new JComboBox&lt;String>(new String[]{"1","2","1.5"}); stopCombox.addActionListener(this); openPortBtn = new Button("打开端口"); openPortBtn.addActionListener(this); closePortBtn = new Button("关闭端口"); closePortBtn.addActionListener(this); // 添加组件至面板 rightPane.add(baudrateLb); rightPane.add(rateCombox); rightPane.add(stopbitsLb); rightPane.add(stopCombox); rightPane.add(openPortBtn); rightPane.add(closePortBtn); // 将左右面板组合添加到北边的面板 northPane.add(leftPane); northPane.add(rightPane); // 创建中间面板 JPanel centerPane = new JPanel(); // 设置中间面板各组件 sendTf = new TextField(42); readTa = new TextArea(8,50); readTa.setEditable(false); readTa.setBackground(new Color(225,242,250)); centerPane.add(sendTf); sendMsgBtn = new Button(" 发送 "); sendMsgBtn.addActionListener(this); // 添加组件至面板 centerPane.add(sendTf); centerPane.add(sendMsgBtn); centerPane.add(readTa); // 设置南边组件 statusLb = new JLabel(); statusLb.setText(initStatus()); statusLb.setOpaque(true); // 获取主窗体的容器,并将以上三面板以北、中、南的布局整合 JPanel contentPane = (JPanel)getContentPane(); contentPane.setLayout(new BorderLayout()); contentPane.setBorder(new EmptyBorder(0, 0, 0, 0)); contentPane.setOpaque(false); contentPane.add(northPane, BorderLayout.NORTH); contentPane.add(centerPane, BorderLayout.CENTER); contentPane.add(statusLb, BorderLayout.SOUTH); } /** * 初始化状态标签显示文本 * @return String * @since 2012-3-23 上午12:01:53 */ public String initStatus() { portname = portCombox.getSelectedItem().toString(); rate = rateCombox.getSelectedItem().toString(); data = dataCombox.getSelectedItem().toString(); stop = stopCombox.getSelectedItem().toString(); parity = parityCombox.getSelectedItem().toString(); StringBuffer str = new StringBuffer("当前串口号:"); str.append(portname).append(" 波特率:"); str.append(rate).append(" 数据位:"); str.append(data).append(" 停止位:"); str.append(stop).append(" 校验位:"); str.append(parity); return str.toString(); } /** * 扫描本机的所有COM端口 * @since 2012-3-23 上午12:02:42 */ public void scanPorts() { portList = new ArrayList&lt;String>(); Enumeration&lt;?> en = CommPortIdentifier.getPortIdentifiers(); CommPortIdentifier portId; while(en.hasMoreElements()){ portId = (CommPortIdentifier) en.nextElement(); if(portId.getPortType() == CommPortIdentifier.PORT_SERIAL){ String name = portId.getName(); if(!portList.contains(name)) { portList.add(name); } } } if(null == portList || portList.isEmpty()) { showErrMesgbox("未找到可用的串行端口号,程序无法启动!"); System.exit(0); } } /** * 打开串行端口 * @since 2012-3-23 上午12:03:07 */ public void openSerialPort() { // 获取要打开的端口 try { portId = CommPortIdentifier.getPortIdentifier(portname); } catch (NoSuchPortException e) { showErrMesgbox("抱歉,没有找到"+portname+"串行端口号!"); setComponentsEnabled(true); return ; } // 打开端口 try { serialPort = (SerialPort) portId.open("JavaRs232", 2000); statusLb.setText(portname+"串口已经打开!"); } catch (PortInUseException e) { showErrMesgbox(portname+"端口已被占用,请检查!"); setComponentsEnabled(true); return ; } // 设置端口参数 try { int rate = Integer.parseInt(this.rate); int data = Integer.parseInt(this.data); int stop = stopCombox.getSelectedIndex()+1; int parity = parityCombox.getSelectedIndex(); serialPort.setSerialPortParams(rate,data,stop,parity); } catch (UnsupportedCommOperationException e) { showErrMesgbox(e.getMessage()); } // 打开端口的IO流管道 try { outputStream = serialPort.getOutputStream(); inputStream = serialPort.getInputStream(); } catch (IOException e) { showErrMesgbox(e.getMessage()); } // 给端口添加监听器 try { serialPort.addEventListener(this); } catch (TooManyListenersException e) { showErrMesgbox(e.getMessage()); } serialPort.notifyOnDataAvailable(true); } /** * 给串行端口发送数据 * @since 2012-3-23 上午12:05:00 */ public void sendDataToSeriaPort() { try { sendCount++; outputStream.write(mesg.getBytes()); outputStream.flush(); } catch (IOException e) { showErrMesgbox(e.getMessage()); } statusLb.setText(" 发送: "+sendCount+" 接收: "+reciveCount); } /** * 关闭串行端口 * @since 2012-3-23 上午12:05:28 */ public void closeSerialPort() { try { if(outputStream != null) outputStream.close(); if(serialPort != null) serialPort.close(); serialPort = null; statusLb.setText(portname+"串口已经关闭!"); sendCount = 0; reciveCount = 0; sendTf.setText(""); readTa.setText(""); } catch (Exception e) { showErrMesgbox(e.getMessage()); } } /** * 显示错误或警告信息 * @param msg 信息 * @since 2012-3-23 上午12:05:47 */ public void showErrMesgbox(String msg) { JOptionPane.showMessageDialog(this, msg); } /** * 各组件行为事件监听 */ public void actionPerformed(ActionEvent e) { if(e.getSource() == portCombox || e.getSource() == rateCombox || e.getSource() == dataCombox || e.getSource() == stopCombox || e.getSource() == parityCombox){ statusLb.setText(initStatus()); } if(e.getSource() == openPortBtn){ setComponentsEnabled(false); openSerialPort(); } if(e.getSource() == closePortBtn){ if(serialPort != null){ closeSerialPort(); } setComponentsEnabled(true); } if(e.getSource() == sendMsgBtn){ if(serialPort == null){ showErrMesgbox("请先打开串行端口!"); return ; } mesg = sendTf.getText(); if(null == mesg || mesg.isEmpty()){ showErrMesgbox("请输入你要发送的内容!"); return ; } sendDataToSeriaPort(); } } /** * 端口事件监听 */ public void serialEvent(SerialPortEvent event) { switch (event.getEventType()) { case SerialPortEvent.BI: case SerialPortEvent.OE: case SerialPortEvent.FE: case SerialPortEvent.PE: case SerialPortEvent.CD: case SerialPortEvent.CTS: case SerialPortEvent.DSR: case SerialPortEvent.RI: case SerialPortEvent.OUTPUT_BUFFER_EMPTY: break; case SerialPortEvent.DATA_AVAILABLE: byte[] readBuffer = new byte[50]; try { while (inputStream.available() > 0) { inputStream.read(readBuffer); } StringBuilder receivedMsg = new StringBuilder("/-- "); receivedMsg.append(new String(readBuffer).trim()).append(" --/\n"); readTa.append(receivedMsg.toString()); reciveCount++; statusLb.setText(" 发送: "+sendCount+" 接收: "+reciveCount); } catch (IOException e) { showErrMesgbox(e.getMessage()); } } } /** * 设置各组件的开关状态 * @param enabled 状态 * @since 2012-3-23 上午12:06:24 */ public void setComponentsEnabled(boolean enabled) { openPortBtn.setEnabled(enabled); openPortBtn.setEnabled(enabled); portCombox.setEnabled(enabled); rateCombox.setEnabled(enabled); dataCombox.setEnabled(enabled); stopCombox.setEnabled(enabled); parityCombox.setEnabled(enabled); } /** * 运行主函数 * @param args * @since 2012-3-23 上午12:06:45 */ public static void main(String[] args) { new JavaRs232(); } } 代码编写完成，按下F11键进入调试状态，一切运行正常良好，请看图：
启动界面 端口检测 通讯测试 最后再抽空来美化程序下，效果更漂亮 PS: 示例源下载</content></entry><entry><title>国内技术强强联手之Nutz+KindEditor+LHGDialog+My97DatePicker</title><url>https://lisenhui.cn/2012/01/13/nutz-ke-lhg-my97.html</url><categories><category>Nutz</category></categories><tags><tag>Nutz</tag><tag>KindEditor</tag></tags><content type="html"> 有段时间没关注过国内IT技术发展情况了，前些天在学习国内的一个开源技术Nutz时想练个手，但一时又不知写些什么好，想了一会还是选择了自己的“老友”KindEditor。对它虽不敢说是透彻的了解(个人的JS水平有限，呵~)，但至少也能很熟练的运用。官网很早便推出了大家期待已久的KE4，不过我一起都没有更新，正好这次拿它来历练下，嘻~。可是想到前面写的那些KE应用示例都是单调的，上次的那个还好有EasyUI做衬托，不过这个UI框架对于小小于的练手项目来说还是庞大了点。于是又便开始寻思着找别的UI看看，突然间起了以前用过的LHGDialog弹出窗口组件还蛮不错的，便去它官网逛了一圈。没有想到还真是让人喜出望外呀，LHG现也更新为4的版本了，那效果的炫丽真是让人颇然心动。下面就先来欣赏下花费2个多小时的劳动成果吧（现在是真相时间），呵呵……
在此不得不称赞下Nutz的高效简约之美，和以前的KE版本一样还是把上传部分的JSP页面翻译成后台JAVA代码，唯一不同的就是那些相同功能的实现代码精简了好多呀，官网示例中的两个JSP文件被有压缩成了一个只有不到400行的JAVA后台代码，源码如下：
package org.nutz.kindeditor4.plugin; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.Comparator; import java.util.Date; import java.util.HashMap; import java.util.List; import java.util.Map; import javax.servlet.ServletContext; import org.nutz.ioc.loader.annotation.IocBean; import org.nutz.log.Log; import org.nutz.log.Logs; import org.nutz.mvc.annotation.AdaptBy; import org.nutz.mvc.annotation.At; import org.nutz.mvc.annotation.Param; import org.nutz.mvc.upload.UploadAdaptor; /** * KindEditor在线编辑器文件上传,管理模块 * @author Elkan(elkan1788@gmail.com) */ @At("/nutz/ke4plugin") @AdaptBy(type = UploadAdaptor.class) @IocBean public class KindEditor4Module { // 日志输出对象 private static Log log = Logs.get(); // 文件目录名称 private String fileDir; // 文件后缀名称 private String fileExt; // 当前站点上下文 private String pageCtx; // 站点真实路径 private String relPath; // 上传文件保存路径 private String savePath; // 允许上传文件后缀MAP数组 private static final HashMap&lt;String, String> extMap = new HashMap&lt;String, String>(); // 允许上传文件大小MAP数组 private static final HashMap&lt;String,Long> sizeMap = new HashMap&lt;String, Long>(); // 上传文件存放根目录 private String filePath = "/attached/"; static { // 初始后缀名称MAP数组 extMap.put("image", "gif,jpg,jpeg,png,bmp"); extMap.put("flash", "swf,flv"); extMap.put("media", "swf,flv,mp3,wav,wma,wmv,mid,avi,mpg,asf,rm,rmvb"); extMap.put("file", "doc,docx,xls,xlsx,ppt,txt,zip,rar"); // 初始文件大小MAP数组 sizeMap.put("image", 100 * 1024l); sizeMap.put("flash", 10 * 1024 * 1024l); sizeMap.put("media", 10 * 1024 * 1024l); sizeMap.put("file", 10 * 1024 * 1024l); } @At public Map&lt;String, Object> upload(@Param("imgFile") File tempFile, @Param("dir") String dir, ServletContext context) { // 初始相关变量 Map&lt;String, Object> execute = new HashMap&lt;String, Object>(); pageCtx = context.getContextPath().concat(filePath); relPath = context.getRealPath(filePath); fileDir = dir; if (null == dir || dir.isEmpty()) { fileDir = "file"; } // 检查是否有上传文件 if (null == tempFile) { execute.put("error", 1); execute.put("message", "请选择上传文件."); return execute; } // 检查上传文件保存目录是否存在或可写 if (!isExistOrRwFolder()) { execute.put("error", 1); execute.put("message", "上传文件保存目录不存在或\n是没有写入权限,请检查."); return execute; } // 检查目录名称是否正确 if (!extMap.containsKey(fileDir)) { execute.put("error", 1); execute.put("message", "目录名不正确,请检查."); return execute; } // 计算出文件后缀名 String tempFileName = tempFile.getName(); fileExt = tempFileName.substring(tempFileName.lastIndexOf(".") + 1); // 检查上传文件类型 if(!Arrays.&lt;String>asList(extMap.get(fileDir).split(",")).contains(fileExt)){ execute.put("error", 1); execute.put("message", "上传文件的格式被拒绝,\n只允许" + extMap.get(fileDir) + "格式的文件."); return execute; } // 检查上传文件的大小 long maxSize = sizeMap.get(fileDir); if (tempFile.length() > maxSize) { execute.put("error", 1); String size = null; if(maxSize &lt; 1024) { size = maxSize + "B"; } if(maxSize > 1024 &amp;&amp; maxSize &lt; 1024 * 1024){ size = maxSize/1024 + "KB"; } if(maxSize > 1024 * 1024){ size = maxSize/(1024 * 1024) + "MB"; } execute.put("message", "上传文件大小超过限制,只允\n许上传小于 " + size + " 的文件."); return execute; } // 生成新的文件名,并按日期分类 newSavePath(); // 拷贝上传文件至指定存放目录 copy(tempFile, savePath); // 计算出文件输出路径 int point = savePath.lastIndexOf("/") - 8; StringBuilder url = new StringBuilder(pageCtx); url.append(fileDir).append("/"); url.append(savePath.substring(point)); // 返回上传文件的输出路径至前端 execute.put("error", 0); execute.put("url", url.toString()); return execute; } @At public Map&lt;String, Object> manager(@Param("dir") String dir, @Param("path") String path, @Param("order") String order, ServletContext context) { // 初始相关变量 Map&lt;String, Object> execute = new HashMap&lt;String, Object>(); pageCtx = context.getContextPath().concat(filePath); relPath = context.getRealPath(filePath); fileDir = dir; if (null == dir || dir.isEmpty()) { fileDir = "file"; } if (!extMap.containsKey(fileDir)) { execute.put("error", 1); execute.put("message", "目录名不正确,请检查."); return execute; } String tempPath = null == path ? fileDir.concat("/") : fileDir.concat("/"+path); String curPath = pageCtx.concat(tempPath); String curFileDir = relPath.concat("/"+tempPath); String curDir = path; String moveupDir = ""; // 检查当前目录是否为根目录 if (!"".equals(path)) { String str = curDir.substring(0, curDir.length() - 1); moveupDir = str.lastIndexOf("/") >= 0 ? str.substring(0, str.lastIndexOf("/") + 1) : ""; } // 检查..命令 if(path.indexOf("..") >= 0){ execute.put("error", 1); execute.put("message", "不允许使用..命令返回上一层."); return execute; } //最后一个字符不是/ if (!"".equals(path) &amp;&amp; !path.endsWith("/")) { execute.put("error", 1); execute.put("message", "文件路径不合法."); return execute; } // 检查当前目录 File curPathFile = new File(curFileDir); if (!curPathFile.isDirectory()) { execute.put("error", 1); execute.put("message", "当前目录不存在."); return execute; } //遍历目录取的文件信息 List&lt;HashMap> fileList = new ArrayList&lt;HashMap>(); if (curPathFile.listFiles() != null) { for (File file : curPathFile.listFiles()) { HashMap&lt;String, Object> hash = new HashMap&lt;String, Object>(); String fileName = file.getName(); if (file.isDirectory()) { hash.put("is_dir", true); hash.put("has_file", (file.listFiles() != null)); hash.put("filesize", 0L); hash.put("is_photo", false); hash.put("filetype", ""); } else if (file.isFile()) { fileExt = fileName.substring(fileName.lastIndexOf(".") + 1).toLowerCase(); hash.put("is_dir", false); hash.put("has_file", false); hash.put("filesize", file.length()); hash.put("is_photo", Arrays.&lt;String>asList(extMap.get("image").split(",")).contains(fileExt)); hash.put("filetype", fileExt); } hash.put("filename", fileName); hash.put("datetime", new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(file.lastModified())); fileList.add(hash); } } // 文件排序方式 String tempOrder = order != null ? order.toLowerCase() : "name"; if ("size".equals(tempOrder)) { Collections.sort(fileList, new SizeComparator()); } else if ("type".equals(tempOrder)) { Collections.sort(fileList, new TypeComparator()); } else { Collections.sort(fileList, new NameComparator()); } // 输出遍历后的文件信息数据 execute.put("moveup_dir_path", moveupDir); execute.put("current_dir_path", curDir); execute.put("current_url", curPath); execute.put("total_count", fileList.size()); execute.put("file_list", fileList); return execute; } /** * 判断文件上传保存的文件夹是否存在或可写 * @return 如果存在且可写返回"true",否则返回"false" */ public boolean isExistOrRwFolder(){ if(null == relPath || relPath.isEmpty()) { return false; } File folder = new File(relPath); if(!folder.exists()) return false; if(!folder.isDirectory()) return false; if(!folder.canWrite()) return false; return true; } /** * 生成新的文件名,且按日期分类管理 */ public void newSavePath() { StringBuilder tempPath = new StringBuilder(relPath); tempPath.append("/").append(fileDir).append("/"); SimpleDateFormat folderNameFormat = new SimpleDateFormat("yyyyMMdd"); tempPath.append(folderNameFormat.format(new Date())); File temp = new File(tempPath.toString()); if(!temp.exists()) temp.mkdirs(); SimpleDateFormat fileNameFormat = new SimpleDateFormat("yyyyMMddkkmmss_S"); tempPath.append("/").append(fileNameFormat.format(new Date())); tempPath.append(".").append(fileExt); savePath = tempPath.toString().replaceAll("\\\\", "/"); } /** * 拷贝文件 * @param src 源文件 * @param tar 目标路径 */ public void copy(File src, String tar) { // 判断源文件或目标路径是否为空 if (null == src || null == tar || tar.isEmpty()) { return; } InputStream srcIs = null; OutputStream tarOs = null; try { srcIs = new FileInputStream(src); File tarFile = new File(tar); tarOs = new FileOutputStream(tarFile); byte[] buffer = new byte[4096]; int n = 0; while (-1 != (n = srcIs.read(buffer))) { tarOs.write(buffer, 0, n); } } catch (IOException e) { log.error("Copy File is Fali, Because "+e); } finally { try { if (null != srcIs) { srcIs.close(); } if (null != tarOs) { tarOs.close(); } } catch (IOException e) { log.error("Close Stream is Fail, Because "+e); } } } /** * 根据文件名称排序 */ public class NameComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { return ((String) hashA.get("filename")).compareTo((String) hashB.get("filename")); } } } /** * 根据文件大小排序 */ public class SizeComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { if (((Long) hashA.get("filesize")) > ((Long) hashB.get("filesize"))) { return 1; } else if (((Long) hashA.get("filesize")) &lt; ((Long) hashB.get("filesize"))) { return -1; } else { return 0; } } } } /** * 根据文件类型排序 */ public class TypeComparator implements Comparator { @Override public int compare(Object a, Object b) { HashMap hashA = (HashMap) a; HashMap hashB = (HashMap) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { return ((String) hashA.get("filetype")).compareTo((String) hashB.get("filetype")); } } } } 虽说代码精简了，但是功能却是一个没有含糊呀，接着欣赏效果图吧。
Nutz对于JAVA程序员来说，是除SSH外的另一个选择，一个美好的开始，如果你有使用相信你定会深学的爱上它，嘻~，别的就不多说了，下面直接把源码给奉上吧，因为时间紧迫(待会就要坐车回家了，嘎~，终于放假了)就只是随笔写了下，写的不好还望大家见谅。
PS: 示例源下载</content></entry><entry><title>IP地址查询Web接口调用</title><url>https://lisenhui.cn/2011/11/18/whosip-tool.html</url><categories><category>接口</category></categories><tags><tag>接口</tag></tags><content type="html"> 今天刚好有个站点上要用到一个IP地址显示的功能，随即便想想应该有免费的接口可用吧，百度一下找到了太平洋网站提供的API，那么接下来便是Code Time。
看完了它的参数说明和调用方式后，选择了其中的jsFunction方式，现在把经验分享出来给大家参考，具体的代码和效果如下：：
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"> &lt;html> &lt;head> &lt;title>ip查询&lt;/title> &lt;script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.0/jquery.min.js">&lt;/script> &lt;script type="text/javascript"> $(function(){ $("&lt;span id='ipShow'>&lt;/span>").appendTo("body"); $.getScript("http://whois.pconline.com.cn/jsFunction.jsp?callback=jsShow&amp;ip=61.235.82.163"); }); function jsShow(location){ $("#ipShow").html(location); } &lt;/script> &lt;/head> &lt;body> &lt;/body> &lt;/html> 效果如下：
具体参数如下：
有不明白的地方，可以留言讨论。</content></entry><entry><title>JSP版本的KindEidtor在线编辑器第二季：Servlet+Struts2集成版</title><url>https://lisenhui.cn/2011/10/17/kindeditor-jsp-struts2-servlet.html</url><categories><category>KindEditor</category></categories><tags><tag>KindEditor</tag><tag>Struts2</tag><tag>Servlet</tag></tags><content type="html"> 前段时间我在论坛上发布了一篇名为《JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)》得到了大家的积极响应，不过令我觉得有点遗憾的是，有很多人都不是真的讨论技术问题，而是向我索取源码，说实在的自已的劳动成果就这样白白奉献出来，觉得有点对不起自己了，要知道我们国内的技术员都是没有金钱后盾啊。唉，最近都太忙了就没有怎么太在意这件事，今晚刚好有空过来看看。看了那么多人留下的印记后，觉得自己也应该要无私一下才是吧，咱老毛说的对：要像雷锋同志学习，呵呵…… 其实在上面我已经说过了，这个JAR里面的功能我只是把官网的JSP代码改编而已，废话就先不多说了，下面直接上码吧，可要接稳了哦。
图片上传功能代码 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; import java.util.Iterator; import java.util.List; import java.util.Random; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.apache.commons.fileupload.FileItem; import org.apache.commons.fileupload.FileItemFactory; import org.apache.commons.fileupload.FileUploadException; import org.apache.commons.fileupload.disk.DiskFileItemFactory; import org.apache.commons.fileupload.servlet.ServletFileUpload; import com.elkan.utils.ImageUtil; /** * 实现KindEditor图片上传的Servlet * * @author SENHUI * * @since 2011/03/21 20:20:23 */ public class UploadImage extends HttpServlet { private static final long serialVersionUID = 5121794650920770832L; // 上传图片的最大宽度 protected int MAX_WIDTH = -1; // 上传图片的最大高度 protected int MAX_HEIGHT = -1; // 上传图片的大小 protected long MAX_SIZE = 1000000; // 定义允许上传的图片的扩展名 protected String[] IMAGETYPES = new String[] { "gif", "jpg", "jpeg", "png", "bmp" }; // 定义上传图片保存目录路径 protected String UPLOAD_PATH = ""; // 上传图片设置信息 protected String id = ""; // 上传图片的TITLE属性值 protected String imgTitle = ""; protected int imgWidth = -1; protected int imgHeight = -1; protected String imgBorder = ""; protected String resizeImg = ""; protected boolean isFlag = false; protected String tempTitle = ""; @SuppressWarnings("deprecation") @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType("text/html; charset=UTF-8"); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter("UPLOAD_PATH"); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg("你还没设置上传图片保存的目录路径!")); return; } //判断是否设置了上传图片的大小 if(this.getInitParameter("MAX_SIZE") != null){ MAX_SIZE = Integer.parseInt(this.getInitParameter("MAX_SIZE")); } //判断是否设置了上传图片的类型 if(this.getInitParameter("IMAGETYPES") != null){ IMAGETYPES = toArray(this.getInitParameter("IMAGETYPES")); } // 图片保存目录路径 String uploadPath = new StringBuffer(request.getSession().getServletContext().getRealPath("/")).append(savePath).toString(); // 图片保存目录URL String saveUrl = new StringBuffer(request.getContextPath()).append("/").append(savePath).toString(); // 检查上传图片是否存在 if (!ServletFileUpload.isMultipartContent(request)) { out.println(alertMsg("请选择你要上传的图片!")); return; } // 检查目录 File uploadDir = new File(uploadPath); if (!uploadDir.isDirectory()) { out.println(alertMsg("上传图片保存的目录不存在。")); return; } // 检查目录写权限 if (!uploadDir.canWrite()) { out.println(alertMsg("上传图片保存的目录没有写权限。")); return; } // 准备上传图片 FileItemFactory factory = new DiskFileItemFactory(); ServletFileUpload upload = new ServletFileUpload(factory); upload.setHeaderEncoding("UTF-8"); List&lt;?> items = null; String temp = null; try { items = upload.parseRequest(request); Iterator&lt;?> itr = items.iterator(); while (itr.hasNext()) { FileItem item = (FileItem) itr.next(); // 上传图片的原文件名 String fileName = item.getName(); temp = (String) item.getName(); if(temp != null &amp;&amp; !isFlag){ temp = temp.substring(temp.lastIndexOf("\\")+1); tempTitle = temp; isFlag = true; } // KindEditor编辑器的ID if(((String)item.getFieldName()).equals("id")){ id = item.getString(); } // 上传图片的重新提示 if(((String)item.getFieldName()).equals("imgTitle")){ imgTitle = item.getString(); if(imgTitle != null){ imgTitle = new String(imgTitle.getBytes("ISO8859-1"),"UTF-8"); } } // 设置图片的宽度 if(((String)item.getFieldName()).equals("imgWidth")){ String imgWidth = item.getString(); if(imgWidth != null &amp;&amp; !imgWidth.isEmpty()){ this.imgWidth = Integer.parseInt(imgWidth); } } // 设置图片的高度 if(((String)item.getFieldName()).equals("imgHeight")){ String imgHeight = item.getString(); if(imgHeight != null &amp;&amp; !imgHeight.isEmpty()){ this.imgHeight = Integer.parseInt(imgHeight); } } // 设置图片的边框 if(((String)item.getFieldName()).equals("imgBorder")){ imgBorder = item.getString(); } long fileSize = item.getSize(); if (!item.isFormField()) { // 检查文件大小 if (fileSize > MAX_SIZE) { out.println(alertMsg("上传文件大小超过限制。")); return; } // 检查扩展名 String fileExt = fileName.substring(fileName.lastIndexOf(".") + 1).toLowerCase(); if (!Arrays.&lt;String> asList(IMAGETYPES).contains(fileExt)) { out.println(alertMsg("上传图片扩展名是不允许的扩展名。")); return; } // 根据时间创建文件夹 SimpleDateFormat folderNameFormat = new SimpleDateFormat("yyyyMMdd"); String realPath = uploadPath + folderNameFormat.format(new Date()); File folder = new File(realPath); boolean flag = folder.exists(); // 确认文件夹是否已经存在 if(!flag){ flag = folder.mkdir(); } // 创建文件夹并上传图片 if(flag){ SimpleDateFormat fileNameFormat = new SimpleDateFormat("yyyyMMddHHmmss"); String newFileName = fileNameFormat.format(new Date()) + "_"+ new Random().nextInt(1000) + "." + fileExt; File uploadedFile = new File(realPath, newFileName); item.write(uploadedFile); resizeImg = uploadedFile.getPath(); resizeImg = resizeImg.replaceAll("\\\\", "/"); saveUrl += folderNameFormat.format(new Date()) + "/" + newFileName; }else{ System.out.println(" 文件夹创建失败，请确认磁盘没有写保护并且空件足够"); } } } // 判断是否设置图片的最大宽度与高度 String max_width = this.getInitParameter("MAX_WIDTH"); String max_height = this.getInitParameter("MAX_HEIGHT"); if((max_width != null &amp;&amp; !max_width.isEmpty())){ MAX_WIDTH = Integer.parseInt(max_width); } if(max_height != null &amp;&amp; !max_height.isEmpty()){ MAX_HEIGHT = Integer.parseInt(max_height); } if(imgTitle == null || imgTitle.isEmpty()){ imgTitle = tempTitle; } // 判断是否要压缩图片 if(MAX_WIDTH != -1 || MAX_HEIGHT != -1) { // 压缩图片 ImageUtil.resizeImg(resizeImg, resizeImg, MAX_WIDTH, MAX_HEIGHT); if(this.imgWidth > ImageUtil.ImgWidth){ this.imgWidth = ImageUtil.ImgWidth; } if(this.imgHeight > ImageUtil.ImgHeight){ this.imgHeight = ImageUtil.ImgHeight; } // 返回编辑器 out.println(insertEditor(id, saveUrl, imgTitle, imgWidth, imgHeight, imgBorder)); }else{ // 返回编辑器 out.println(insertEditor(id, saveUrl, imgTitle, imgWidth, imgHeight, imgBorder)); } } catch (FileUploadException e) { e.printStackTrace(); } catch (Exception e) { e.printStackTrace(); }finally{ out.flush(); out.close(); isFlag = false; } } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } /** * 输出打印上传失败的JSON语句 * * @param message 失败信息 * * @return 页面上传失败的JSON语句 */ public String alertMsg(String message) { StringBuffer sb = new StringBuffer("{\"error\":\"1\",\"message\":\""); sb.append(message).append("\"}"); return sb.toString(); } /** * 输出插入图片至编辑器语句的脚本 * * @param id 编辑器ID * * @param saveUrl 上传图片的浏览地址 * * @param imgTitle 图片的提示信息 * * @param imgWidth 设置图片的宽度 * * @param imgHeight 设置图片的宽度 * * @param imgBorder 设置图片的边框 * * @return 插入图片至编辑器的脚本语句 */ public String insertEditor(String id, String saveUrl, String imgTitle, int imgWidth, int imgHeight, String imgBorder){ StringBuffer sb = new StringBuffer("&lt;script type\"text/javascript\">"); sb.append("parent.KE.plugin[\"image\"].insert(\"").append(id).append("\",\""); sb.append(saveUrl).append("\",\"").append(imgTitle).append("\",\""); sb.append(imgWidth).append("\",\"").append(imgHeight).append("\",\""); sb.append(imgBorder).append("\");"); sb.append("&lt;/script>"); return sb.toString(); } /** * 输出允许上传图片类型的数组 * * @param filesType 允许上传的图片类型 * * @return 允许上传图片类型 */ public String[] toArray(String filesType){ if(filesType == null){ return null; } String[] types = filesType.split(","); String[] allowTypes = new String[types.length]; int i = 0; for(String type : types){ allowTypes[i] = type; i++; } return allowTypes; } } 上传图片管理代码 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.Comparator; import java.util.Hashtable; import java.util.List; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class UploadImageManager extends HttpServlet { private static final long serialVersionUID = -8359652838938248988L; // 定义允许上传的图片的扩展名 protected String[] FILETYPES = new String[] { "gif", "jpg", "jpeg", "png", "bmp" }; // 定义上传图片保存目录路径 protected String UPLOAD_PATH = ""; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType("text/html; charset=UTF-8"); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter("UPLOAD_PATH"); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg("你还没设置读取上传图片保存的目录路径!")); return; } // 图片保存目录路径 String rootPath = new StringBuffer(request.getSession().getServletContext().getRealPath("/")).append(savePath).toString(); // 图片保存目录URL String rootUrl = new StringBuffer(request.getContextPath()).append("/").append(savePath).toString(); //根据path参数，设置各路径和URL String path = request.getParameter("path") != null ? request.getParameter("path") : ""; String currentPath = rootPath + path; String currentUrl = rootUrl + path; String currentDirPath = path; String moveupDirPath = ""; if (!"".equals(path)) { String str = currentDirPath.substring(0, currentDirPath.length() - 1); moveupDirPath = str.lastIndexOf("/") >= 0 ? str.substring(0, str.lastIndexOf("/") + 1) : ""; } //排序形式，name or size or type String order = request.getParameter("order") != null ? request.getParameter("order").toLowerCase() : "name"; //不允许使用..移动到上一级目录 if (path.indexOf("..") >= 0) { out.println(alertMsg("不允许使用移动到上一级目录")); return; } //最后一个字符不是/ if (!"".equals(path) &amp;&amp; !path.endsWith("/")) { out.println("Parameter is not valid."); return; } //目录不存在或不是目录 File currentPathFile = new File(currentPath); if(!currentPathFile.isDirectory()){ out.println("Directory does not exist."); return; } //遍历目录取的文件信息 List&lt;Hashtable&lt;?,?>> fileList = new ArrayList&lt;Hashtable&lt;?,?>>(); if(currentPathFile.listFiles() != null) { for (File file : currentPathFile.listFiles()) { Hashtable&lt;String, Object> hash = new Hashtable&lt;String, Object>(); String fileName = file.getName(); if(file.isDirectory()) { hash.put("is_dir", true); hash.put("has_file", (file.listFiles() != null)); hash.put("filesize", 0L); hash.put("is_photo", false); hash.put("filetype", ""); } else if(file.isFile()){ String fileExt = fileName.substring(fileName.lastIndexOf(".") + 1).toLowerCase(); hash.put("is_dir", false); hash.put("has_file", false); hash.put("filesize", file.length()); hash.put("is_photo", Arrays.&lt;String>asList(FILETYPES).contains(fileExt)); hash.put("filetype", fileExt); } hash.put("filename", fileName); hash.put("datetime", new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(file.lastModified())); fileList.add(hash); } } if ("size".equals(order)) { Collections.sort(fileList, new SizeComparator()); } else if ("type".equals(order)) { Collections.sort(fileList, new TypeComparator()); } else { Collections.sort(fileList, new NameComparator()); } out.println(toJSONString(currentUrl, currentDirPath, moveupDirPath, fileList)); out.flush(); out.close(); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } /** * 输出打印上传失败语句的脚本 * * @param message 失败信息 * * @return 页面打印的脚本语句 */ public String alertMsg(String message) { StringBuffer sb = new StringBuffer("&lt;script type\"text/javascript\">"); sb.append("alert(\"").append(message).append("\");"); sb.append("&lt;/script>"); return sb.toString(); } public String toJSONString(String currentUrl, String currentDirPath, String moveupDirPath, List&lt;Hashtable&lt;?, ?>> fileList){ StringBuilder sb = new StringBuilder("{\"current_url\":\""); sb.append(currentUrl).append("\",").append("\"current_dir_path\":\""); sb.append(currentDirPath).append("\",\"moveup_dir_path\":\"").append(moveupDirPath).append("\","); sb.append("\"file_list\":["); int i = 0; sb.append("{"); for(Hashtable&lt;?,?> he : fileList){ if(i != (fileList.size() - 1)){ sb.append("\"filename\":\"").append(he.get("filename")).append("\","); sb.append("\"filesize\":").append(he.get("filesize")).append(","); sb.append("\"filetype\":\"").append(he.get("filetype")).append("\","); sb.append("\"has_file\":").append(he.get("has_file")).append(","); sb.append("\"is_dir\":").append(he.get("is_dir")).append(","); sb.append("\"is_photo\":").append(he.get("is_photo")).append(","); sb.append("\"datetime\":\"").append(he.get("datetime")).append("\""); sb.append("},{"); }else{ sb.append("\"filename\":\"").append(he.get("filename")).append("\","); sb.append("\"filesize\":").append(he.get("filesize")).append(","); sb.append("\"filetype\":\"").append(he.get("filetype")).append("\","); sb.append("\"has_file\":").append(he.get("has_file")).append(","); sb.append("\"is_dir\":").append(he.get("is_dir")).append(","); sb.append("\"is_photo\":").append(he.get("is_photo")).append(","); sb.append("\"datetime\":\"").append(he.get("datetime")).append("\""); sb.append("}"); } i++; } i = 0; sb.append("],\"total_count\":").append(fileList.size()).append("}"); return sb.toString(); } public class NameComparator implements Comparator&lt;Object> { public int compare(Object a, Object b) { Hashtable&lt;?, ?> hashA = (Hashtable&lt;?, ?>) a; Hashtable&lt;?, ?> hashB = (Hashtable&lt;?, ?>) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { return ((String) hashA.get("filename")).compareTo((String) hashB.get("filename")); } } } public class SizeComparator implements Comparator&lt;Object> { public int compare(Object a, Object b) { Hashtable&lt;?, ?> hashA = (Hashtable&lt;?, ?>) a; Hashtable&lt;?, ?> hashB = (Hashtable&lt;?, ?>) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { if (((Long) hashA.get("filesize")) > ((Long) hashB.get("filesize"))) { return 1; } else if (((Long) hashA.get("filesize")) &lt; ((Long) hashB.get("filesize"))) { return -1; } else { return 0; } } } } public class TypeComparator implements Comparator&lt;Object> { public int compare(Object a, Object b) { Hashtable&lt;?, ?> hashA = (Hashtable&lt;?, ?>) a; Hashtable&lt;?, ?> hashB = (Hashtable&lt;?, ?>) b; if (((Boolean) hashA.get("is_dir")) &amp;&amp; !((Boolean) hashB.get("is_dir"))) { return -1; } else if (!((Boolean) hashA.get("is_dir")) &amp;&amp; ((Boolean) hashB.get("is_dir"))) { return 1; } else { return ((String) hashA.get("filetype")).compareTo((String) hashB.get("filetype")); } } } } 附件上传代码 package com.elkan.kindeditor.upload; import java.io.File; import java.io.IOException; import java.io.PrintWriter; import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; import java.util.Iterator; import java.util.List; import java.util.Random; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.apache.commons.fileupload.FileItem; import org.apache.commons.fileupload.FileItemFactory; import org.apache.commons.fileupload.disk.DiskFileItemFactory; import org.apache.commons.fileupload.servlet.ServletFileUpload; public class UploadAccessory extends HttpServlet { private static final long serialVersionUID = 1L; // 上传文件的大小 protected long MAX_SIZE = 1000000; // 定义允许上传的文件的扩展名 protected String[] FILETYPES = new String[]{"doc", "xls", "ppt", "pdf", "txt", "rar" , "zip"}; // 定义上传文件保存目录路径 protected String UPLOAD_PATH = ""; protected String id = ""; protected String attachTitle = ""; protected boolean isFlag = false; protected String tempTitle = ""; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType("text/html; charset=UTF-8"); PrintWriter out = response.getWriter(); String savePath = this.getInitParameter("UPLOAD_PATH"); if (savePath == null || savePath.isEmpty()) { out.println(alertMsg("你还没设置上传文件保存的目录路径!")); return; } //判断是否设置了上传文件的大小 if(this.getInitParameter("MAX_SIZE") != null){ MAX_SIZE = Integer.parseInt(this.getInitParameter("MAX_SIZE")); } //判断是否设置了上传文件的类型 if(this.getInitParameter("FILETYPES") != null){ FILETYPES = toArray(this.getInitParameter("FILETYPES")); } // 文件保存目录路径 String uploadPath = new StringBuffer(request.getSession().getServletContext().getRealPath("/")).append(savePath).toString(); // 文件保存目录URL String saveUrl = new StringBuffer(request.getContextPath()).append("/").append(savePath).toString(); if(!ServletFileUpload.isMultipartContent(request)){ out.println(alertMsg("请选择要上传的文件。")); return; } //检查目录 File uploadDir = new File(uploadPath); if(!uploadDir.isDirectory()){ out.println(alertMsg("上传目录不存在。")); return; } //检查目录写权限 if(!uploadDir.canWrite()){ out.println(alertMsg("当前角色对上传目录没有写权限。")); return; } FileItemFactory factory = new DiskFileItemFactory(); ServletFileUpload upload = new ServletFileUpload(factory); upload.setHeaderEncoding("UTF-8"); String temp = null; String ext = null; try{ List&lt;?> items = upload.parseRequest(request); Iterator&lt;?> itr = items.iterator(); while (itr.hasNext()) { FileItem item = (FileItem) itr.next(); String fileName = item.getName(); temp = (String) item.getName(); if(temp != null &amp;&amp; !isFlag){ temp = temp.substring(temp.lastIndexOf("\\")+1); tempTitle = temp; isFlag = true; } // KindEditor编辑器的ID if(((String)item.getFieldName()).equals("id")){ id = item.getString(); } // 上传图片的重新提示 if(((String)item.getFieldName()).equals("attachTitle")){ attachTitle = item.getString(); if(attachTitle != null){ attachTitle = new String(attachTitle.getBytes("ISO8859-1"),"UTF-8"); } } if (!item.isFormField()) { //检查文件大小 if(item.getSize() > MAX_SIZE){ out.println(alertMsg("上传文件大小超过限制。")); return; } //检查扩展名 String fileExt = fileName.substring(fileName.lastIndexOf(".") + 1).toLowerCase(); if(!Arrays.&lt;String>asList(FILETYPES).contains(fileExt)){ out.println(alertMsg("上传文件扩展名是不允许的扩展名。")); return; } // 根据时间创建文件夹 SimpleDateFormat folderNameFormat = new SimpleDateFormat("yyyyMMdd"); String realPath = uploadPath + folderNameFormat.format(new Date()); File folder = new File(realPath); boolean flag = folder.exists(); // 确认文件夹是否已经存在 if(!flag){ flag = folder.mkdir(); } // 创建文件夹并上传图片 if(flag){ SimpleDateFormat fileNameFormat = new SimpleDateFormat("yyyyMMddHHmmss"); String newFileName = fileNameFormat.format(new Date()) + "_"+ new Random().nextInt(1000) + "." + fileExt; File uploadedFile = new File(realPath, newFileName); item.write(uploadedFile); saveUrl += folderNameFormat.format(new Date()) + "/" + newFileName; ext = fileExt; }else{ System.out.println(" 文件夹创建失败，请确认磁盘没有写保护并且空件足够"); } } } if(attachTitle == null || attachTitle.isEmpty()){ attachTitle = tempTitle; } out.println(insertAttach(id, saveUrl, attachTitle, ext)); }catch(Exception e){ e.printStackTrace(); }finally{ out.flush(); out.close(); isFlag = false; } } /** * 输出打印上传失败语句的脚本 * * @param message 失败信息 * * @return 页面打印的脚本语句 */ public String alertMsg(String message){ StringBuilder sb = new StringBuilder("&lt;html>"); sb.append("&lt;head>").append("&lt;title>error&lt;/title>"); sb.append("&lt;meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">"); sb.append("&lt;/head>"); sb.append("&lt;body>"); sb.append("&lt;script type=\"text/javascript\">"); sb.append("alert(\"").append(message).append("\");history.back();&lt;/script>"); sb.append("&lt;/body>").append("&lt;/html>"); return sb.toString(); } /** * 输出插入附件至编辑器语句的脚本 * * @param id 编辑器ID * * @param url 上传附件的地址 * * @param title 上传时设置的title属性 * * @param ext 上传文件的后缀名 * * @return 插入附件至编辑器的脚本语句 */ public String insertAttach(String id, String url, String title, String ext){ StringBuilder sb = new StringBuilder("&lt;html>"); sb.append("&lt;head>").append("&lt;title>Insert Accessory&lt;/title>"); sb.append("&lt;meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">"); sb.append("&lt;/head>"); sb.append("&lt;body>"); sb.append("&lt;script type=\"text/javascript\">"); sb.append("parent.KE.plugin[\"accessory\"].insert(\"").append(id).append("\",\""); sb.append(url).append("\",\"").append(title).append("\",\"").append(ext).append("\");&lt;/script>"); sb.append("&lt;/body>").append("&lt;/html>"); return sb.toString(); } /** * 输出允许上传图片类型的数组 * * @param filesType 允许上传的图片类型 * * @return 允许上传图片类型 */ public String[] toArray(String filesType){ if(filesType == null){ return null; } String[] types = filesType.split(","); String[] allowTypes = new String[types.length]; int i = 0; for(String type : types){ allowTypes[i] = type; i++; } return allowTypes; } } 图像压缩代码 package com.elkan.utils; import java.awt.Image; import java.awt.image.BufferedImage; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import javax.imageio.ImageIO; import com.sun.image.codec.jpeg.JPEGCodec; import com.sun.image.codec.jpeg.JPEGImageEncoder; /** * 对图片进行处理的方法 * * @author SENHUI */ public class ImageUtil { public static int ImgWidth = -1; public static int ImgHeight = -1; /** * 压缩图片 * * @param imgsrc * 源文件 * @param imgdist * 目标文件 * @param widthdist * 宽 * @param heightdist * 高 */ public static void resizeImg(String imgsrc, String imgdist, int widthdist, int heightdist) { try { File srcfile = new File(imgsrc); if (!srcfile.exists()) { return; } Image src = ImageIO.read(srcfile); ImgWidth = src.getWidth(null); ImgHeight = src.getHeight(null); if(ImgWidth &lt; widthdist){ widthdist = ImgWidth; }else{ ImgWidth = widthdist; } if(ImgHeight &lt; heightdist){ heightdist = ImgHeight; }else{ ImgHeight = heightdist; } BufferedImage tag = new BufferedImage(widthdist, heightdist,BufferedImage.TYPE_INT_RGB); tag.getGraphics().drawImage(src.getScaledInstance(widthdist, heightdist,Image.SCALE_SMOOTH), 0, 0, null); FileOutputStream out = new FileOutputStream(imgdist); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(tag); out.close(); } catch (IOException ex) { ex.printStackTrace(); } } } 呵，源码发布就到此了，上面有都有比较详细的注释文档了，相信各位可以看个明白吧。现在大家有什么自定义的功能要开发的就拿去用吧，别忘记把你开发出来的东东分享下哦，我在此恭候你的大驾光临啊，嘻嘻…… 不管你对此文章满意与否都留下个印记吧，下次用得上时好来取呀，呵。对了最后再给大家留道作业吧，怎么样把上传的附件进行分类管理呢？比如：word放到word文件夹目录………(此功能已经实现，不过公布的代码里没有，大家思考下吧，看看谁的方法最优化，呵)
PS: 对一些提问的回答
为何在Struts2里面不能使用？ 答：在项目开发中一般配置Struts2的过滤映射是全部站资源，修改成只要过滤你的Struts2访问资源便可。 (现在源码公布了，你们可以把那些上传方法写到Action里面)
到处都是定义上传类型, 是不是很累赘啊？ 答：在web.xml配置上传类型是当初发布时考虑到重用性的问题，再说默认的上传文件类型应该够用了吧，只要限定大小与保存路径便可了；在JSP页面初始化编辑器定义上传文件类型是为了上传前的JS脚验证，如果说这都很麻烦，那我也没办法了。
能否添加代码高亮功能？ 答：当初改版这个编辑器时的出发点是为适合我们的项目，所以这个功能没有考虑，不过网上有没有代码高亮插件，可自行参考设计下。
能否粘贴word文档里面的图片？ 答：这个功能还真是没有哦，我对WEB前端不是很熟悉，不过我倒是开发出表格合并的功能，目前还在测试阶段。如能开发这个图片粘贴的话就好了，不过好像要插件支持才行吧，唉，windows的东西不太好玩呀。</content></entry><entry><title>MyEclipse6.5+ IDE汉化软件</title><url>https://lisenhui.cn/2011/05/16/myeclipse-chinese-tool.html</url><categories><category>工具</category></categories><tags><tag>MyEclipse</tag><tag>IDE</tag></tags><content type="html"> 世界上的语言与文字都有千百万种，但始终还是觉得我们的方块汉字比较好看且比较有内涵。而在计算机领域一直都是被国外主宰，所以很多计算机上的程序都是英文版的，有时候用起来还真是不太方便的，于是便出现了一大批汉化版的程序，这些程序都受到了国人的偏爱。
在JAVA界的开发工具中使用最多的IDE莫过于Eclipse与MyEclisep，而这两款IDE的开发者均为外国人，所以IDE的界面为英文也就不足为奇了。作为另个一款后起之秀Netbeans开发工具我想是比较受国内编程初学者的喜爱，为何？很简单它的界面支持中文。
还是先转回我们今天的主题MyEclisep汉化程序吧，Eclipse的汉化就不用多说了，自己直接去官网下载个语言包便可以实现中文界面，但MyEclipse就没有那么简单了，以前曾在网上找到一个牛人写的汉化包，试用了下效果还不错，不过就是步骤有点麻烦，昨晚突发奇想能不能把它做个傻瓜化的汉化程序呢？想了想觉得可行度有70%左右，最终衡量下还是决定CODE，最终在大约3个小时后便成功做出这个汉化程序，界面效果如下：
如果你觉得有需要就下载个回去用用看吧，下面来说说这个软件的使用方法：
直接解压下载下来的压缩包，记得不要破坏目录结构不然就无法汉化了，双击MyEclipse汉化软件(透明).exe(这个需要最新版本JDK)或MyEclipse汉化软件(无透明).exe；
浏览并选取MyEclipse安装根目录下的Common目录，这个要视你的安装位置而定；
浏览并选取bundles.info(插件指定)文件，此文件目录下\MyEclipse ...\configuration\org.eclipse.equinox.simpleconfigurator目录下；
浏览并选取myeclipse.ini文件，些文件在\MyEclipse ...目录下；
点击开始汉化按钮后，如果成功便会出现下面的成功提示，现在你重启下MyEclipse程序看看，最好用-clean命令；
看看汉化后的MyEclipse界面吧：
可能是因为汉化包有点旧的原故吧，所以并不是完全汉化的，如果说你有比较好的汉化包，希望你能与大家分享下。最后要说的是，如果你觉得汉化的效果不理想又想还原英文界面的话，只要恢复对应文件夹目录下的bundles_backup.info与myeclipse_backup.ini文件重启下MyEclipse软件就可以了。
好了汉化工作就到此结束了，现在大家想说些什么就跟帖拍砖吧。</content></entry><entry><title>开放JSP版KindEditor的附件JAR包源码</title><url>https://lisenhui.cn/2011/05/05/kindeditor-jsp-source.html</url><categories><category>KindEditor</category></categories><tags><tag>Java</tag><tag>KindEditor</tag></tags><content type="html"> 3月份的时候写了个JSP版本的kindeditor编辑器的帖子，没有想到大家的响应会这么强烈。不过随着日月的增长，此版本的插件也就暴露出一些BUG，如：Struts2如何集成，web.xml文件中配置上传属性不便修改且繁琐，上传图片(附件)不能保存于其它盘…………。现在平时开发的项目中都是使用KE作为在线编辑器，为了能更好、更方便的使用此编辑器，在休息的时间对原先的代码进行重构再封装，除对上个版本出现的BUG进行外，还统一整体的命名规范，新增了一些功能。
当前新版本插件的版本号为：kindeditor-plugin0.4RELEASE，JAR包中类的列表如下：
此次重构所完成的功能主要有以下几点：
重构上传附件页面的选择按，仿图片上传的选择按钮； 增加Struts2环境集成； 增加上传属性配置功能，方便站点布署修改(暂未开放)； 增加其它盘存储功能，可自由选择存放位置方便备份(暂未开放)； 增加上传图片的文字水印功能(暂未开放)； 更Kindeditor编辑版本为3.5.6； 上传附件分类管理 如果你要把这个KE插件应用到你的项目中，很简单，如是Servlet环境只须一个步骤即可，Struts2环境则需要两个步骤，具体如下：
Servlet环境：只需要在web.xml中配置如下的参数 &lt;?xml version="1.0" encoding="UTF-8"?> &lt;web-app version="2.5" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"> &lt;servlet> &lt;servlet-name>KEUploadImgServlet&lt;/servlet-name> &lt;servlet-class>com.elkan.kindeditor.servlet.plugin.KEUploadImgServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>IMGSAVEPATH&lt;/param-name> &lt;param-value>/upload/image/&lt;/param-value> &lt;/init-param> &lt;!-- 缺省上传图片大小 &lt;init-param> &lt;param-name>MAXSIZE&lt;/param-name> &lt;param-value>1048576&lt;/param-value> &lt;/init-param> 缺省上传图片类型 &lt;init-param> &lt;param-name>IMGTYPES&lt;/param-name> &lt;param-value>jpg,jpeg,png,gif,bmp&lt;/param-value> &lt;/init-param> 缺省不压缩图片 &lt;init-param> &lt;param-name>MAXWIDTH&lt;/param-name> &lt;param-value>&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>MAXHEIGHT&lt;/param-name> &lt;param-value>&lt;/param-value> &lt;/init-param> --> &lt;/servlet> &lt;servlet> &lt;servlet-name>KEManageImgServlet&lt;/servlet-name> &lt;servlet-class>com.elkan.kindeditor.servlet.plugin.KEManageImgServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>IMGSAVEPATH&lt;/param-name> &lt;param-value>/upload/image/&lt;/param-value> &lt;/init-param> &lt;/servlet> &lt;servlet> &lt;servlet-name>KEUploadAttachServlet&lt;/servlet-name> &lt;servlet-class>com.elkan.kindeditor.servlet.plugin.KEUploadAttachServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>ATTACHSAVEPATH&lt;/param-name> &lt;param-value>/upload/attach/&lt;/param-value> &lt;/init-param> &lt;!-- 缺省上传附件大小 &lt;init-param> &lt;param-name>MAXSIZE&lt;/param-name> &lt;param-value>10485760&lt;/param-value> &lt;/init-param> 缺省上传附件类型 &lt;init-param> &lt;param-name>ATTACHTYPES&lt;/param-name> &lt;param-value>**&lt;/param-value> &lt;/init-param> --> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>KEUploadImgServlet&lt;/servlet-name> &lt;url-pattern>/keplugin/KEUploadImg.servlet&lt;/url-pattern> &lt;/servlet-mapping> &lt;servlet-mapping> &lt;servlet-name>KEManageImgServlet&lt;/servlet-name> &lt;url-pattern>/keplugin/KEManageImages.servlet&lt;/url-pattern> &lt;/servlet-mapping> &lt;servlet-mapping> &lt;servlet-name>KEUploadAttachServlet&lt;/servlet-name> &lt;url-pattern>/keplugin/KEUploadAttach.servlet&lt;/url-pattern> &lt;/servlet-mapping> &lt;welcome-file-list> &lt;welcome-file>index.jsp&lt;/welcome-file> &lt;/welcome-file-list> &lt;login-config> &lt;auth-method>BASIC&lt;/auth-method> &lt;/login-config> &lt;/web-app> Jsp页面上KindEditor JS脚本配置[Servlet版本]：
KE.show({ id: "editorServlet", resizeMode: 0, allowFileManager : true, imageUploadJson: "/KEPlugin/keplugin/KEUploadImg.servlet", fileManagerJson: "/KEPlugin/keplugin/KEManageImages.servlet", //缺省为 *.*表示所有类型文件 //accessoryTypes: "doc|docx", accessoryUploadJson: "/KEPlugin/keplugin/KEUploadAttach.servlet" }); Struts2环境：先在web.xml中配置Struts2，如下： &lt;?xml version="1.0" encoding="UTF-8"?> &lt;web-app version="2.5" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemalocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"> &lt;filter> &lt;filter-name>struts2&lt;/filter-name> &lt;filter-class>org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class> &lt;/filter> &lt;filter-mapping> &lt;filter-name>struts2&lt;/filter-name> &lt;url-pattern>*.action&lt;/url-pattern> &lt;/filter-mapping> &lt;welcome-file-list> &lt;welcome-file>index.jsp&lt;/welcome-file> &lt;/welcome-file-list> &lt;/web-app> struts.xml文件配置，如下：（如设置了拦截器，请设置拦截器允许通过类型为KEStruts2Plugin的ACTION）
&lt;!--?xml version="1.0" encoding="UTF-8" ?--> &lt;struts> &lt;constant name="struts.i18n.encoding" value="UTF-8">&lt;/constant> &lt;constant name="struts.action.extension" value="action">&lt;/constant> &lt;constant name="struts.configuration.xml.reload" value="true">&lt;/constant> &lt;constant name="struts.multipart.saveDir" value="\temp">&lt;/constant> &lt;constant name="struts.multipart.maxSize" value="104857600">&lt;/constant> &lt;package name="KEPlugin" extends="struts-default" namespace="/keplugin"> &lt;action name="keUploadImg" class="com.elkan.kindeditor.struts2.plugin.KEUploadImgAction"> &lt;!-- 缺省不压缩图片 --> &lt;!--&lt;param name="maxWidth">&lt;/param>--> &lt;!--&lt;param name="maxHeight">&lt;/param>--> &lt;!-- 缺省上传图片大小 --> &lt;!--&lt;param name="maxSize">102400&lt;/param>--> &lt;!-- 缺省为jpg,jpeg,png,gif,bmp类型图片 --> &lt;!--&lt;param name="imgTypes">jpg,jpeg,png,gif,bmp&lt;/param>--> &lt;param name="imgSavePath">/upload/image/&lt;/param> &lt;/action> &lt;action name="keUploadAttach" class="com.elkan.kindeditor.struts2.plugin.KEUploadAttachAction"> &lt;param name="attachSavePath">/upload/attach/&lt;/param> &lt;!-- 缺省上传附件大小 --> &lt;!--&lt;param name="maxSize">10485760&lt;/param>--> &lt;!-- 缺省上传附件类型 --> &lt;!--&lt;param name="attachTypes">*.*&lt;/param>--> &lt;/action> &lt;action name="keManagerImages" class="com.elkan.kindeditor.struts2.plugin.KEManageImgAction"> &lt;param name="imgSavePath">/upload/image/&lt;/param> &lt;/action> &lt;/package> &lt;/struts> Jsp页面上KindEditor JS脚本配置[Struts2版本]：
KE.show({ id: "editorStruts2", resizeMode: 0, allowFileManager : true, imageUploadJson: "/KEPlugin/keplugin/keUploadImg.action", fileManagerJson : "/KEPlugin/keplugin/keManagerImages.action", //缺省为 *.*表示所有类型文件 //accessoryTypes: "doc|docx", accessoryUploadJson: "/KEPlugin/keplugin/keUploadAttach.action" }); 此次还借助JQuery EasyUI和SyntaxHighlighter语法高亮插件写了应用示例，下面我们就先来预览下Kindeditor在EasyUI模式下的清爽身影吧，闪亮登场……
应用示例首页 Servlet版本的KE Struts2版本的KE 附件上传页面 上传图片管理 KE编辑器预览效果 其它更多详细的应用功能，详细请见附件下载。最后要记得要支持国产技术发展呀，有意见请你拍砖吐槽。
PS：下载KindEditor应用示例下载
把下载的压缩包上解压到Tomcat服务器的webapps目录下，启动Tomcat服务器，打开浏览器在地址栏输入：http://localhost:端口号/KEPlugin/index.jsp 就可以看到上面截图的应用示例了，Congratulation!</content></entry><entry><title>JSP版的完善KindEditor在线编辑器(带附件上传与图片按日期分类管理功能)</title><url>https://lisenhui.cn/2011/03/24/kindeditor-jsp-complete.html</url><categories><category>KindEditor</category></categories><tags><tag>KindEditor</tag><tag>前端</tag></tags><content type="html"> 在此之前我一直都是在用FCKEditor在线编辑器，当然也有用过其它在线编辑器如eWebEditor,tinyMCE,CuteEditor，jHtmlArea等等，但在最终项目发布的时候并没有采用它们，因为它们要不是皮肤呆板，就是配置太烦琐，或是功能太少、浏览器兼容性不好等等。去年一个偶然的机会让我认识了KindEditor这款在线编辑器，正如它的名字那样这是款友好的编辑器，它不仅体积小配置简单，而且功能与皮肤也是令人相当的振憾。还有个很重要的因素，它是我们国人的开发的免费工具，从产品发布至今更新脚步未曾停止哦。下面就会大家介绍下经过我完善后的KindEditor吧。
目前官方网站已经将KindEditor更新到了3.5.2版，从3.4的版本开始官方就去除了一些不常用的功能改用plugin形式来丰富KindEidtor，这就为我们打造个性的插件奠定了基础。其实只要是你的JS基础够扎实，花点时间看看KindEditor的源码，你就完全可以在其原有的基础上完善出你所想要的功能。下面是我的完善记录：
集合了日期、时间、在线预览和特殊字符插件,采用3.0皮肤；
将图片上传与管理的JSP页面改写成SERVLET，同时去除JSON包；
添加图片压缩功能，对超出的宽高压缩成指定的值；
添加上传附件功能；
添加图片、附件按日期文件夹分类管理的功能；
添加上传图片、附件的title属性，缺省为原文件名；
添加上传附件相关的初始属性
修改从word粘贴样式，减少样式。
关于如何使用我就不多说了，官方网站上有详细的API，文章最后我也会给出经我完善的KindEditor还有Demo，先来看看效果吧。
完善后的KE目录 完整功能示 浏览服务目录 附件展示效果 与Extjs整合效果 最后要说的是这款编辑器真的很不错，相信你用过它后一定会喜欢上它的，呵呵，多多支持国内软件事业的发展吧。
PS: 示例源码下载</content></entry><entry><title>关于Struts2与Jquery实现无刷新分页的不解问题</title><url>https://lisenhui.cn/2010/11/03/jquery-ajax-struts2.html</url><categories><category>前端</category></categories><tags><tag>Juqery</tag><tag>前端</tag><tag>Struts</tag></tags><content type="html"> 我最近正在做一个无刷新的网站管理后台，并把它作为我的毕业设计主题，不过在代码实现上遇到了点小问题，想向大家请教一二。我的设计思路大概是这样的：将后台所生成的数据用JSON的格式输出，在前台借助JQUERY的AJAX功能将传过来的数据写出。这样的方式在实现数据的增、改、删功能上并不会很难，不过在数据的查询方面便麻烦了，如何实现数据的无刷新分页呢？我查阅网上一些网友的做法，不过普遍发现他们的代码有点繁琐也不符合我设计初衷。通过查看JQUERY的API我自己想出了一种可行的方案(目前已经实现部分功能)：在查询的页面中先创建一个无数据的表格样式，通过JQUERY的CLONE功 能在查询数据时复制这个表格的样式同时将后台传过的数据填充其中和移除那行无数据的样式表格。
前台的JS相关代码如下：
// 显示所查询的数据 function dataSource(){ $.ajax({ url:"${pageContext.request.contextPath}/jsonservlet", type:"post", data:{}, dataType:"json", error:function(){alert("服务器通讯失败，请稍后再刷新页面。 ^_^");}, success:function(data){ insertTr(data); } }); } // 查询数据的分页跳转 function goPage(thePage){ $.ajax({ url:"${pageContext.request.contextPath}/jsonservlet", type:"post", data:{page:thePage}, dataType:"json", error:function(){alert("服务器通讯失败，请稍后再刷新页面。 ^_^");}, success:function(data){ insertTr(data); } }); } // 填充表格中的每行数据 function insertTr(data) { //读取tr里数量 var r = $("#datasource tr").size(); var list = data.dataSource; $.each(list, function(i, r) { //克隆已有的表格样式及属性 var row = $("#source").clone(); //将数值填充至表格中 row.find("#id").text(r.id) row.find("#name").text(r.name); row.find("#time").text(r.time); //将此行添加到表格中 row.appendTo("#datasource"); }); // 移除第一行，因为它只有样式没有数据 $("#datasource").children("tr:first").remove(); } 通过实践发现这个方案是可行的，不过出现了一个问题：在数据翻页时如何将当前的数据移除并将新数据填充到页面中呢？（即：在转到第2页时把当前第1页的数据移除并填充第2页的数据）我尝试了很多方法可仍是未能实现我想要的无刷新的分页效果，希望大家能帮我看看是哪里出问题了。谢谢。
PS: (最后自行解决了，解决方案如下)
var r = $("#datasource tr").size(); 只要在上面的代码后面增加如下的代码:
if(r > 1){ $("#datasource").find("tr:not(:first)").remove(); } &ldquo;代码下载&rdquo;</content></entry><entry><title>JQuery+Strusts1.x实现Ajax无刷新登录</title><url>https://lisenhui.cn/2010/09/05/jquery-ajax-struts1.html</url><categories><category>前端</category></categories><tags><tag>Juqery</tag><tag>前端</tag><tag>Struts</tag></tags><content type="html"> 在当今技术发展日益成熟，人们除了追求技术创新与发展外，更多也关注到了与用户交互的便利性方面上。当程序员还在为前后数据交互刷新问题困惑时，AJAX 问世了，它以方便快捷的优越性博得了广大程序员的追捧。经过几年的发展，它也渐渐成为我们开发中必不可少的一件利器，下面我就来讲个Struts1 + Ajax的登录示例。
所用的JS插件： JQuery1.3.2汉化版、JQuery.form2.43
下面我们先来看看页面中核心的JS代码：
function submitForm() { // 用jquery.form插件实现对表单数据系列化 var form = $("form[name=AdminLoginForm]"); // 配置jquery.form中ajaxForm的参数 // success 操作成功时的回调函数 // resetForm 是否刷新表单 // dataType 接收服务器返回数据的类型, 有script, xml, json等 var options = { success: showResponse, resetForm: false, dataType: "script" }; // ajax发送表单数据到服务器 form.ajaxForm(options); return false; } //回调函数 function showResponse(responseText, statusText) { if (statusText == "success") { alert(responseText); } else { alert("由于通讯问题，请稍后再登录！"); } } 在上面的代码中我们可以发现通过JQuery和JQuery.form两款插件，我们只要短短的三行代码就可以实现与后台的数据交互。JQuery是一款功能很强大的JS插件，我个人也很喜欢，调用很方便，代码风格也不错。有空可以研究一下哦，呵呵……
下面继续来看看struts的action的代码：
public ActionForward execute(ActionMapping mapping, ActionForm form, HttpServletRequest request, HttpServletResponse response) throws Exception { // 输出的方式与编码格式 response.setContentType("text/html; charset=utf-8"); PrintWriter out = response.getWriter(); // 获取表单数据 AdminLoginForm adminLogin = (AdminLoginForm) form; // 获取服务器产生的验证码 String validateCode = request.getSession().getAttribute("validateCode").toString(); try { // 判断用户输入的验证码是否正确 if (adminLogin.getVerifycode().equalsIgnoreCase(validateCode)) { // 用户名的状态 boolean isUser = false; // 验证用户名是否存在 if(!adminLogin.getUsername().equalsIgnoreCase("elkan")){ out.print("你输入的用户名不存在，请重新输入！"); return null; }else{ isUser = true; } // 验证密码是否正解 if(adminLogin.getUserpswd().equalsIgnoreCase("lisenhui2010") &amp;&amp; isUser){ out.print("登录成功！"); }else{ out.print("密码错误，请重新输入！"); return null; } } else { out.print("验证码输入错误请重新输入！"); return null; } } catch (Exception e) { out.print(e.toString()); } return null; } 最后还有下面的struts-config.xml的配置文件：
&lt;action-mappings> &lt;action input="/webstage/adminLogin.jsp" name="AdminLoginForm" path="/AdminLogin" scope="request" type="com.elkan.struts.actions.AdminLogin" validate="false"/> &lt;/action-mappings> 说了那么多，下面先来看看通上面的代码所实现的效果吧：
看到上面的效果，你是不是也想展示一下自己的身手呢，那就赶紧动手吧，相信有了上面的那些代码的提示做个DEMO应该不会很难吧，如果有什么问题的话可以留言给我。谢谢支持。</content></entry></search>