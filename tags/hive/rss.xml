<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hive on 热爱生活与梦想</title><link>https://lisenhui.cn/tags/hive/</link><description>Recent content in Hive on 热爱生活与梦想</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Thu, 21 Mar 2019 19:04:51 +0000</lastBuildDate><atom:link href="https://lisenhui.cn/tags/hive/rss.xml" rel="self" type="application/rss+xml"/><item><title>不能在HDFS Data节点上创建临时文件</title><link>https://lisenhui.cn/tech/unable-create-tmp-file-in-hdfs-nodes.html</link><pubDate>Thu, 21 Mar 2019 19:04:51 +0000</pubDate><guid>https://lisenhui.cn/tech/unable-create-tmp-file-in-hdfs-nodes.html</guid><description>&lt;p>在新创建的&lt;code>Hadoop&lt;/code>边缘节点上，尝试通过&lt;code>Hive CLI&lt;/code>模式进行数据插入操作，结果没有出现意想中的成功信息，反倒是捕获到如下的异常：&lt;/p>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>FAILED: SemanticException &lt;span style="color:#f92672">[&lt;/span>Error 10293&lt;span style="color:#f92672">]&lt;/span>: Unable to create temp file &lt;span style="color:#66d9ef">for&lt;/span> insert values File &lt;span style="color:#f92672">/&lt;/span>tmp&lt;span style="color:#f92672">/&lt;/span>hive&lt;span style="color:#f92672">/&lt;/span>kylin&lt;span style="color:#f92672">/&lt;/span>9c84de0a&lt;span style="color:#f92672">-&lt;/span>fca2&lt;span style="color:#f92672">-&lt;/span>4d3c&lt;span style="color:#f92672">-&lt;/span>8f72&lt;span style="color:#f92672">-&lt;/span>47436a4adb83&lt;span style="color:#f92672">/&lt;/span>_tmp_space.&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">/&lt;/span>Values__Tmp__Table__1&lt;span style="color:#f92672">/&lt;/span>data_file could only be replicated to 0 nodes instead of &lt;span style="color:#a6e22e">minReplication&lt;/span> (&lt;span style="color:#f92672">=&lt;/span>1). There are 1 &lt;span style="color:#a6e22e">datanode&lt;/span>(s) running and 1 &lt;span style="color:#a6e22e">node&lt;/span>(s) are excluded in &lt;span style="color:#66d9ef">this&lt;/span> operation.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">blockmanagement&lt;/span>.&lt;span style="color:#a6e22e">BlockManager&lt;/span>.&lt;span style="color:#a6e22e">chooseTarget4NewBlock&lt;/span>(BlockManager.&lt;span style="color:#a6e22e">java&lt;/span>:1720)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">namenode&lt;/span>.&lt;span style="color:#a6e22e">FSNamesystem&lt;/span>.&lt;span style="color:#a6e22e">getAdditionalBlock&lt;/span>(FSNamesystem.&lt;span style="color:#a6e22e">java&lt;/span>:3440)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">namenode&lt;/span>.&lt;span style="color:#a6e22e">NameNodeRpcServer&lt;/span>.&lt;span style="color:#a6e22e">addBlock&lt;/span>(NameNodeRpcServer.&lt;span style="color:#a6e22e">java&lt;/span>:686)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">namenode&lt;/span>.&lt;span style="color:#a6e22e">AuthorizationProviderProxyClientProtocol&lt;/span>.&lt;span style="color:#a6e22e">addBlock&lt;/span>(AuthorizationProviderProxyClientProtocol.&lt;span style="color:#a6e22e">java&lt;/span>:217)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">protocolPB&lt;/span>.&lt;span style="color:#a6e22e">ClientNamenodeProtocolServerSideTranslatorPB&lt;/span>.&lt;span style="color:#a6e22e">addBlock&lt;/span>(ClientNamenodeProtocolServerSideTranslatorPB.&lt;span style="color:#a6e22e">java&lt;/span>:506)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">hdfs&lt;/span>.&lt;span style="color:#a6e22e">protocol&lt;/span>.&lt;span style="color:#a6e22e">proto&lt;/span>.&lt;span style="color:#a6e22e">ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2&lt;/span>.&lt;span style="color:#a6e22e">callBlockingMethod&lt;/span>(ClientNamenodeProtocolProtos.&lt;span style="color:#a6e22e">java&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">ipc&lt;/span>.&lt;span style="color:#a6e22e">ProtobufRpcEngine$Server$ProtoBufRpcInvoker&lt;/span>.&lt;span style="color:#a6e22e">call&lt;/span>(ProtobufRpcEngine.&lt;span style="color:#a6e22e">java&lt;/span>:617)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">ipc&lt;/span>.&lt;span style="color:#a6e22e">RPC$Server&lt;/span>.&lt;span style="color:#a6e22e">call&lt;/span>(RPC.&lt;span style="color:#a6e22e">java&lt;/span>:1073)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">ipc&lt;/span>.&lt;span style="color:#a6e22e">Server$Handler$1&lt;/span>.&lt;span style="color:#a6e22e">run&lt;/span>(Server.&lt;span style="color:#a6e22e">java&lt;/span>:2226)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">ipc&lt;/span>.&lt;span style="color:#a6e22e">Server$Handler$1&lt;/span>.&lt;span style="color:#a6e22e">run&lt;/span>(Server.&lt;span style="color:#a6e22e">java&lt;/span>:2222)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at java.&lt;span style="color:#a6e22e">security&lt;/span>.&lt;span style="color:#a6e22e">AccessController&lt;/span>.&lt;span style="color:#a6e22e">doPrivileged&lt;/span>(Native Method)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at javax.&lt;span style="color:#a6e22e">security&lt;/span>.&lt;span style="color:#a6e22e">auth&lt;/span>.&lt;span style="color:#a6e22e">Subject&lt;/span>.&lt;span style="color:#a6e22e">doAs&lt;/span>(Subject.&lt;span style="color:#a6e22e">java&lt;/span>:415)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">security&lt;/span>.&lt;span style="color:#a6e22e">UserGroupInformation&lt;/span>.&lt;span style="color:#a6e22e">doAs&lt;/span>(UserGroupInformation.&lt;span style="color:#a6e22e">java&lt;/span>:1917)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>	at org.&lt;span style="color:#a6e22e">apache&lt;/span>.&lt;span style="color:#a6e22e">hadoop&lt;/span>.&lt;span style="color:#a6e22e">ipc&lt;/span>.&lt;span style="color:#a6e22e">Server$Handler&lt;/span>.&lt;span style="color:#a6e22e">run&lt;/span>(Server.&lt;span style="color:#a6e22e">java&lt;/span>:2220)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ERROR: Current user has no permission to create Hive table in working directory: &lt;span style="color:#f92672">/&lt;/span>user&lt;span style="color:#f92672">/&lt;/span>kylin
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HiveServer2因JDBC版本引起的问题</title><link>https://lisenhui.cn/tech/hive2-jdbc-connector-issues.html</link><pubDate>Tue, 17 Oct 2017 17:33:04 +0000</pubDate><guid>https://lisenhui.cn/tech/hive2-jdbc-connector-issues.html</guid><description>&lt;p>之前一直都是用&lt;code>HDP&lt;/code>来搭建和管理&lt;strong>Hadoop&lt;/strong>环境，在安装完成调试时也未曾出现过棘手的问题，但这次在&lt;code>Centos6x&lt;/code>系统上布署好后却是遇到奇怪的问题：&lt;/p>
&lt;blockquote>
&lt;p>表面上看来&lt;strong>Hive&lt;/strong>服务是正常运行的，进程运行正常，页面UI也正常，日志也没错误输出。简单的建表的语句都能执行，可偏偏在导入本地/&lt;strong>HDFS&lt;/strong>数据时，便就抛出异常啦。错误的堆栈信息如下：&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version &lt;span style="color:#66d9ef">for&lt;/span> the right syntax to use near &lt;span style="color:#e6db74">&amp;#39;OPTION SQL_SELECT_LIMIT=DEFAULT&amp;#39;&lt;/span> at line &lt;span style="color:#ae81ff">1&lt;/span> 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>另外一个问题在使用&lt;strong>Ambari&lt;/strong>提供的&lt;code>HiveView&lt;/code> UI进行HDFS数据导入提示文件不存在，错误信息如下：&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code>&lt;span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>org.apache.hive.service.cli.HiveSQLException: Error &lt;span style="color:#66d9ef">while&lt;/span> compiling statement: FAILED: SemanticException Line 1:17 Invalid path &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>/tmp/xxx/xxxxx.csv&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>: No files matching path hdfs:/...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Sqoop工具导入数据到Hive小记</title><link>https://lisenhui.cn/tech/sqoop-import-data-to-hive.html</link><pubDate>Wed, 24 May 2017 20:18:53 +0000</pubDate><guid>https://lisenhui.cn/tech/sqoop-import-data-to-hive.html</guid><description>&lt;p>最近正在捣鼓构建数据仓库的事宜，正好有部分维度表的数据需要来自于RDBMS的数据，在HADOOP环境最流行的莫过于Apache的Sqoop工具，按官方的文档操作下来也很顺畅的，不过当要应用到业务场景上时问题便出现了。&lt;/p></description></item></channel></rss>